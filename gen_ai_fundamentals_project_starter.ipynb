{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Project: Teaching an LLM to Reason\n",
        "\n",
        "In this project, you will teach an LLM to use step-by-step reasoning to answer the question: \"How many X's are there in the word Y?\"\n",
        "\n",
        "Counting letters in a word is a surprisingly complex task for an LLM. Just as human beings would not be able to answer such a question for longer words without breaking down the word into its individual letters and then counting them, LLMs cannot be similarly expected to be able to respond without using smaller reasoning steps.\n",
        "\n",
        "For example, to count the number of o's in the word room, one could use the following reasoning:\n",
        "\n",
        "```\n",
        "Question: How many of the letter \"o\" are there in the word \"room\"\n",
        "Answer: 2\n",
        "Response:\n",
        "\n",
        "<reasoning>\n",
        "Letter-by-letter spelling:\n",
        "1. r - 0 o's so far\n",
        "2. o - 1 o's so far\n",
        "3. o - 2 o's so far\n",
        "4. m - 2 o's so far\n",
        "\n",
        "The letter \"o\" appears 2 times in the word \"room\".\n",
        "</reasoning>\n",
        "<answer>\n",
        "2\n",
        "</answer>\n",
        "```\n",
        "\n",
        "In this project we will use the reinforcement learning method GRPO (Group Relative Policy Optimization, of DeepSeek fame) to take a large language model that has been fine-tuned for following instructions and teach it how to break a word down into its letters and then count the requested letter.\n",
        "\n",
        "We will complete the following steps:\n",
        "\n",
        "* Set up the notebook\n",
        "* Create a letter-counting dataset\n",
        "* Create the reward functions\n",
        "* Train the model\n",
        "* View the results\n",
        "\n",
        "NOTE: This notebook will have you focus on several important aspects of training a GPRO model using LoRA:\n",
        "\n",
        "1. Configuring LoRA adapters for parameter-efficient fine tuning\n",
        "2. Selecting reward functions that help the model efficiently find its way to the correct answer (also called reward shaping)\n",
        "3. Finding hyperparameters that help the model increase the rewards earned more quickly and reliably\n",
        "4. Learning how to start with smaller experiments and to work your way up to longer experiments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set up the notebook\n",
        "\n",
        "We'll install dependencies needed for the project, namely `unsloth` and `vllm`, which are useful for fine-tuning LLMs with even just 15GB of VRAM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 214 Î¼s (started: 2025-12-25 11:49:54 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Load ipython-autotime to see how long each cell take to run\n",
        "# No changes needed in this cell\n",
        "\n",
        "!pip install -q ipython-autotime\n",
        "%load_ext autotime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: accelerate==1.10.1 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 1)) (1.10.1)\n",
            "Requirement already satisfied: aiohappyeyeballs==2.6.1 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 2)) (2.6.1)\n",
            "Requirement already satisfied: aiohttp==3.12.15 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (3.12.15)\n",
            "Requirement already satisfied: aiosignal==1.4.0 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (1.4.0)\n",
            "Requirement already satisfied: annotated-types==0.7.0 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 5)) (0.7.0)\n",
            "Requirement already satisfied: anyio==4.10.0 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 6)) (4.10.0)\n",
            "Requirement already satisfied: astor==0.8.1 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 7)) (0.8.1)\n",
            "Requirement already satisfied: asttokens==3.0.0 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 8)) (3.0.0)\n",
            "Requirement already satisfied: attrs==25.3.0 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 9)) (25.3.0)\n",
            "Requirement already satisfied: bitsandbytes==0.47.0 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 10)) (0.47.0)\n",
            "Requirement already satisfied: blake3==1.0.6 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 11)) (1.0.6)\n",
            "Requirement already satisfied: cachetools==6.2.0 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 12)) (6.2.0)\n",
            "Requirement already satisfied: cbor2==5.7.0 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 13)) (5.7.0)\n",
            "Requirement already satisfied: certifi==2025.8.3 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 14)) (2025.8.3)\n",
            "Requirement already satisfied: cffi==2.0.0 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 15)) (2.0.0)\n",
            "Requirement already satisfied: charset-normalizer==3.4.3 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 16)) (3.4.3)\n",
            "Requirement already satisfied: click==8.3.0 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 17)) (8.3.0)\n",
            "Requirement already satisfied: cloudpickle==3.1.1 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 18)) (3.1.1)\n",
            "Requirement already satisfied: comm==0.2.3 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 19)) (0.2.3)\n",
            "Requirement already satisfied: compressed-tensors==0.10.2 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 20)) (0.10.2)\n",
            "Requirement already satisfied: contourpy==1.3.3 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 21)) (1.3.3)\n",
            "Requirement already satisfied: cupy-cuda12x==13.6.0 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 22)) (13.6.0)\n",
            "Requirement already satisfied: cut-cross-entropy==25.1.1 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 23)) (25.1.1)\n",
            "Requirement already satisfied: cycler==0.12.1 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 24)) (0.12.1)\n",
            "Requirement already satisfied: datasets==3.6.0 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 25)) (3.6.0)\n",
            "Requirement already satisfied: debugpy==1.8.17 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 26)) (1.8.17)\n",
            "Requirement already satisfied: decorator==5.2.1 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 27)) (5.2.1)\n",
            "Requirement already satisfied: depyf==0.19.0 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 28)) (0.19.0)\n",
            "Requirement already satisfied: diffusers==0.35.1 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 29)) (0.35.1)\n",
            "Requirement already satisfied: dill==0.3.8 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 30)) (0.3.8)\n",
            "Requirement already satisfied: diskcache==5.6.3 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 31)) (5.6.3)\n",
            "Requirement already satisfied: distro==1.9.0 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 32)) (1.9.0)\n",
            "Requirement already satisfied: dnspython==2.8.0 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 33)) (2.8.0)\n",
            "Requirement already satisfied: docstring-parser==0.17.0 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 34)) (0.17.0)\n",
            "Requirement already satisfied: einops==0.8.1 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 35)) (0.8.1)\n",
            "Requirement already satisfied: email-validator==2.3.0 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 36)) (2.3.0)\n",
            "Requirement already satisfied: executing==2.2.1 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 37)) (2.2.1)\n",
            "Requirement already satisfied: fastapi==0.117.1 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 38)) (0.117.1)\n",
            "Requirement already satisfied: fastapi-cli==0.0.13 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 39)) (0.0.13)\n",
            "Requirement already satisfied: fastapi-cloud-cli==0.2.0 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 40)) (0.2.0)\n",
            "Requirement already satisfied: fastrlock==0.8.3 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 41)) (0.8.3)\n",
            "Requirement already satisfied: filelock==3.19.1 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 42)) (3.19.1)\n",
            "Requirement already satisfied: fonttools==4.60.0 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 43)) (4.60.0)\n",
            "Requirement already satisfied: frozenlist==1.7.0 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 44)) (1.7.0)\n",
            "Requirement already satisfied: fsspec==2025.3.0 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 45)) (2025.3.0)\n",
            "Requirement already satisfied: gguf==0.17.1 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 46)) (0.17.1)\n",
            "Requirement already satisfied: h11==0.16.0 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 47)) (0.16.0)\n",
            "Requirement already satisfied: hf-transfer==0.1.9 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 48)) (0.1.9)\n",
            "Requirement already satisfied: hf-xet==1.1.10 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 49)) (1.1.10)\n",
            "Requirement already satisfied: httpcore==1.0.9 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 50)) (1.0.9)\n",
            "Requirement already satisfied: httptools==0.6.4 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 51)) (0.6.4)\n",
            "Requirement already satisfied: httpx==0.28.1 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 52)) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub==0.35.0 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 53)) (0.35.0)\n",
            "Requirement already satisfied: idna==3.10 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 54)) (3.10)\n",
            "Requirement already satisfied: importlib-metadata==8.7.0 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 55)) (8.7.0)\n",
            "Requirement already satisfied: interegular==0.3.3 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 56)) (0.3.3)\n",
            "Requirement already satisfied: ipykernel==6.30.1 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 57)) (6.30.1)\n",
            "Requirement already satisfied: ipython==9.5.0 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 58)) (9.5.0)\n",
            "Requirement already satisfied: ipython-autotime==0.3.2 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 59)) (0.3.2)\n",
            "Requirement already satisfied: ipython-pygments-lexers==1.1.1 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 60)) (1.1.1)\n",
            "Requirement already satisfied: jedi==0.19.2 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 61)) (0.19.2)\n",
            "Requirement already satisfied: jinja2==3.1.6 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 62)) (3.1.6)\n",
            "Requirement already satisfied: jiter==0.11.0 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 63)) (0.11.0)\n",
            "Requirement already satisfied: jsonschema==4.25.1 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 64)) (4.25.1)\n",
            "Requirement already satisfied: jsonschema-specifications==2025.9.1 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 65)) (2025.9.1)\n",
            "Requirement already satisfied: jupyter-client==8.6.3 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 66)) (8.6.3)\n",
            "Requirement already satisfied: jupyter-core==5.8.1 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 67)) (5.8.1)\n",
            "Requirement already satisfied: kiwisolver==1.4.9 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 68)) (1.4.9)\n",
            "Requirement already satisfied: lark==1.2.2 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 69)) (1.2.2)\n",
            "Requirement already satisfied: llguidance==0.7.30 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 70)) (0.7.30)\n",
            "Requirement already satisfied: llvmlite==0.44.0 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 71)) (0.44.0)\n",
            "Requirement already satisfied: lm-format-enforcer==0.10.12 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 72)) (0.10.12)\n",
            "Requirement already satisfied: markdown-it-py==4.0.0 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 73)) (4.0.0)\n",
            "Requirement already satisfied: markupsafe==3.0.2 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 74)) (3.0.2)\n",
            "Requirement already satisfied: matplotlib==3.10.6 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 75)) (3.10.6)\n",
            "Requirement already satisfied: matplotlib-inline==0.1.7 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 76)) (0.1.7)\n",
            "Requirement already satisfied: mdurl==0.1.2 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 77)) (0.1.2)\n",
            "Requirement already satisfied: mistral-common==1.8.5 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 78)) (1.8.5)\n",
            "Requirement already satisfied: mpmath==1.3.0 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 79)) (1.3.0)\n",
            "Requirement already satisfied: msgpack==1.1.1 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 80)) (1.1.1)\n",
            "Requirement already satisfied: msgspec==0.19.0 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 81)) (0.19.0)\n",
            "Requirement already satisfied: multidict==6.6.4 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 82)) (6.6.4)\n",
            "Requirement already satisfied: multiprocess==0.70.16 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 83)) (0.70.16)\n",
            "Requirement already satisfied: nest-asyncio==1.6.0 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 84)) (1.6.0)\n",
            "Requirement already satisfied: networkx==3.5 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 85)) (3.5)\n",
            "Requirement already satisfied: ninja==1.13.0 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 86)) (1.13.0)\n",
            "Requirement already satisfied: numba==0.61.2 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 87)) (0.61.2)\n",
            "Requirement already satisfied: numpy==2.2.6 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 88)) (2.2.6)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 89)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 90)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 91)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 92)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 93)) (9.5.1.17)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 94)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 95)) (1.11.1.6)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 96)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 97)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 98)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 99)) (0.6.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 100)) (2.26.2)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 101)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 102)) (12.6.77)\n",
            "Requirement already satisfied: openai==1.108.1 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 103)) (1.108.1)\n",
            "Requirement already satisfied: openai-harmony==0.0.4 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 104)) (0.0.4)\n",
            "Requirement already satisfied: opencv-python-headless==4.12.0.88 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 105)) (4.12.0.88)\n",
            "Requirement already satisfied: outlines-core==0.2.10 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 106)) (0.2.10)\n",
            "Requirement already satisfied: packaging==25.0 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 107)) (25.0)\n",
            "Requirement already satisfied: pandas==2.3.2 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 108)) (2.3.2)\n",
            "Requirement already satisfied: parso==0.8.5 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 109)) (0.8.5)\n",
            "Requirement already satisfied: partial-json-parser==0.2.1.1.post6 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 110)) (0.2.1.1.post6)\n",
            "Requirement already satisfied: peft==0.17.1 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 111)) (0.17.1)\n",
            "Requirement already satisfied: pexpect==4.9.0 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 112)) (4.9.0)\n",
            "Requirement already satisfied: pillow==11.3.0 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 113)) (11.3.0)\n",
            "Requirement already satisfied: pip==25.2 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 114)) (25.2)\n",
            "Requirement already satisfied: platformdirs==4.4.0 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 115)) (4.4.0)\n",
            "Requirement already satisfied: prometheus-client==0.23.1 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 116)) (0.23.1)\n",
            "Requirement already satisfied: prometheus-fastapi-instrumentator==7.1.0 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 117)) (7.1.0)\n",
            "Requirement already satisfied: prompt-toolkit==3.0.52 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 118)) (3.0.52)\n",
            "Requirement already satisfied: propcache==0.3.2 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 119)) (0.3.2)\n",
            "Requirement already satisfied: protobuf==6.32.1 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 120)) (6.32.1)\n",
            "Requirement already satisfied: psutil==7.1.0 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 121)) (7.1.0)\n",
            "Requirement already satisfied: ptyprocess==0.7.0 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 122)) (0.7.0)\n",
            "Requirement already satisfied: pure-eval==0.2.3 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 123)) (0.2.3)\n",
            "Requirement already satisfied: py-cpuinfo==9.0.0 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 124)) (9.0.0)\n",
            "Requirement already satisfied: pyarrow==21.0.0 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 125)) (21.0.0)\n",
            "Requirement already satisfied: pybase64==1.4.2 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 126)) (1.4.2)\n",
            "Requirement already satisfied: pycountry==24.6.1 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 127)) (24.6.1)\n",
            "Requirement already satisfied: pycparser==2.23 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 128)) (2.23)\n",
            "Requirement already satisfied: pydantic==2.11.9 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 129)) (2.11.9)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 130)) (2.33.2)\n",
            "Requirement already satisfied: pydantic-extra-types==2.10.5 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 131)) (2.10.5)\n",
            "Requirement already satisfied: pygments==2.19.2 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 132)) (2.19.2)\n",
            "Requirement already satisfied: pyparsing==3.2.4 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 133)) (3.2.4)\n",
            "Requirement already satisfied: python-dateutil==2.9.0.post0 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 134)) (2.9.0.post0)\n",
            "Requirement already satisfied: python-dotenv==1.1.1 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 135)) (1.1.1)\n",
            "Requirement already satisfied: python-json-logger==3.3.0 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 136)) (3.3.0)\n",
            "Requirement already satisfied: python-multipart==0.0.20 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 137)) (0.0.20)\n",
            "Requirement already satisfied: pytz==2025.2 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 138)) (2025.2)\n",
            "Requirement already satisfied: pyyaml==6.0.2 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 139)) (6.0.2)\n",
            "Requirement already satisfied: pyzmq==27.1.0 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 140)) (27.1.0)\n",
            "Requirement already satisfied: ray==2.49.2 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 141)) (2.49.2)\n",
            "Requirement already satisfied: referencing==0.36.2 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 142)) (0.36.2)\n",
            "Requirement already satisfied: regex==2025.9.18 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 143)) (2025.9.18)\n",
            "Requirement already satisfied: requests==2.32.5 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 144)) (2.32.5)\n",
            "Requirement already satisfied: rich==14.1.0 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 145)) (14.1.0)\n",
            "Requirement already satisfied: rich-toolkit==0.15.1 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 146)) (0.15.1)\n",
            "Requirement already satisfied: rignore==0.6.4 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 147)) (0.6.4)\n",
            "Requirement already satisfied: rpds-py==0.27.1 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 148)) (0.27.1)\n",
            "Requirement already satisfied: safetensors==0.6.2 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 149)) (0.6.2)\n",
            "Requirement already satisfied: scipy==1.16.2 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 150)) (1.16.2)\n",
            "Requirement already satisfied: sentencepiece==0.2.1 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 151)) (0.2.1)\n",
            "Requirement already satisfied: sentry-sdk==2.38.0 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 152)) (2.38.0)\n",
            "Requirement already satisfied: setproctitle==1.3.7 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 153)) (1.3.7)\n",
            "Requirement already satisfied: setuptools==79.0.1 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 154)) (79.0.1)\n",
            "Requirement already satisfied: shellingham==1.5.4 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 155)) (1.5.4)\n",
            "Requirement already satisfied: shtab==1.7.2 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 156)) (1.7.2)\n",
            "Requirement already satisfied: six==1.17.0 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 157)) (1.17.0)\n",
            "Requirement already satisfied: sniffio==1.3.1 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 158)) (1.3.1)\n",
            "Requirement already satisfied: soundfile==0.13.1 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 159)) (0.13.1)\n",
            "Requirement already satisfied: soxr==1.0.0 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 160)) (1.0.0)\n",
            "Requirement already satisfied: stack-data==0.6.3 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 161)) (0.6.3)\n",
            "Requirement already satisfied: starlette==0.48.0 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 162)) (0.48.0)\n",
            "Requirement already satisfied: sympy==1.14.0 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 163)) (1.14.0)\n",
            "Requirement already satisfied: tiktoken==0.11.0 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 164)) (0.11.0)\n",
            "Requirement already satisfied: tokenizers==0.21.4 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 165)) (0.21.4)\n",
            "Requirement already satisfied: torch==2.7.1 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 166)) (2.7.1)\n",
            "Requirement already satisfied: torchao==0.13.0 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 167)) (0.13.0)\n",
            "Requirement already satisfied: torchaudio==2.7.1 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 168)) (2.7.1)\n",
            "Requirement already satisfied: torchvision==0.22.1 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 169)) (0.22.1)\n",
            "Requirement already satisfied: tornado==6.5.2 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 170)) (6.5.2)\n",
            "Requirement already satisfied: tqdm==4.67.1 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 171)) (4.67.1)\n",
            "Requirement already satisfied: traitlets==5.14.3 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 172)) (5.14.3)\n",
            "Requirement already satisfied: transformers==4.55.4 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 173)) (4.55.4)\n",
            "Requirement already satisfied: triton==3.2.0 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 174)) (3.2.0)\n",
            "Requirement already satisfied: trl==0.22.2 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 175)) (0.22.2)\n",
            "Requirement already satisfied: typeguard==4.4.4 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 176)) (4.4.4)\n",
            "Requirement already satisfied: typer==0.19.1 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 177)) (0.19.1)\n",
            "Requirement already satisfied: typing-extensions==4.15.0 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 178)) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection==0.4.1 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 179)) (0.4.1)\n",
            "Requirement already satisfied: tyro==0.9.32 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 180)) (0.9.32)\n",
            "Requirement already satisfied: tzdata==2025.2 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 181)) (2025.2)\n",
            "Requirement already satisfied: unsloth==2025.9.7 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 182)) (2025.9.7)\n",
            "Requirement already satisfied: unsloth-zoo==2025.9.9 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 183)) (2025.9.9)\n",
            "Requirement already satisfied: urllib3==2.5.0 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 184)) (2.5.0)\n",
            "Requirement already satisfied: uvicorn==0.36.0 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 185)) (0.36.0)\n",
            "Requirement already satisfied: uvloop==0.21.0 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 186)) (0.21.0)\n",
            "Requirement already satisfied: vllm==0.10.1 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 187)) (0.10.1)\n",
            "Requirement already satisfied: watchfiles==1.1.0 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 188)) (1.1.0)\n",
            "Requirement already satisfied: wcwidth==0.2.13 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 189)) (0.2.13)\n",
            "Requirement already satisfied: websockets==15.0.1 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 190)) (15.0.1)\n",
            "Requirement already satisfied: wheel==0.45.1 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 191)) (0.45.1)\n",
            "Requirement already satisfied: xformers==0.0.31 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 192)) (0.0.31)\n",
            "Requirement already satisfied: xgrammar==0.1.21 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 193)) (0.1.21)\n",
            "Requirement already satisfied: xxhash==3.5.0 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 194)) (3.5.0)\n",
            "Requirement already satisfied: yarl==1.20.1 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 195)) (1.20.1)\n",
            "Requirement already satisfied: zipp==3.23.0 in /voc/data/venv2/lib/python3.12/site-packages (from -r requirements.txt (line 196)) (3.23.0)\n",
            "INFO: pip is looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting bitsandbytes==0.47.0 (from -r requirements.txt (line 10))\n",
            "  Using cached bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl.metadata (11 kB)\n",
            "Collecting accelerate==1.10.1 (from -r requirements.txt (line 1))\n",
            "  Using cached accelerate-1.10.1-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting asttokens==3.0.0 (from -r requirements.txt (line 8))\n",
            "  Using cached asttokens-3.0.0-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting astor==0.8.1 (from -r requirements.txt (line 7))\n",
            "  Using cached astor-0.8.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting anyio==4.10.0 (from -r requirements.txt (line 6))\n",
            "  Using cached anyio-4.10.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "INFO: pip is still looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting annotated-types==0.7.0 (from -r requirements.txt (line 5))\n",
            "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting aiosignal==1.4.0 (from -r requirements.txt (line 4))\n",
            "  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting yarl==1.20.1 (from -r requirements.txt (line 195))\n",
            "  Downloading yarl-1.20.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (73 kB)\n",
            "Collecting multidict==6.6.4 (from -r requirements.txt (line 82))\n",
            "  Downloading multidict-6.6.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
            "Collecting aiohttp==3.12.15 (from -r requirements.txt (line 3))\n",
            "  Downloading aiohttp-3.12.15-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "Collecting aiohappyeyeballs==2.6.1 (from -r requirements.txt (line 2))\n",
            "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting numpy==2.2.6 (from -r requirements.txt (line 88))\n",
            "  Downloading numpy-2.2.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[31mERROR: Cannot install torch==2.7.1 and triton==3.2.0 because these package versions have conflicting dependencies.\u001b[0m\u001b[31m\n",
            "\u001b[0m\n",
            "The conflict is caused by:\n",
            "    The user requested triton==3.2.0\n",
            "    torch 2.7.1 depends on triton==3.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
            "\n",
            "To fix this you could try to:\n",
            "1. loosen the range of package versions you've specified\n",
            "2. remove package versions to allow pip to attempt to solve the dependency conflict\n",
            "\n",
            "\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\u001b[0m\u001b[31m\n",
            "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
            "time: 5.51 s (started: 2025-12-25 11:49:59 +00:00)\n"
          ]
        }
      ],
      "source": [
        "pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thu Dec 25 11:50:11 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 575.57.08              Driver Version: 575.57.08      CUDA Version: 12.9     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       On  |   00000000:00:1E.0 Off |                    0 |\n",
            "| N/A   24C    P8             13W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 335 ms (started: 2025-12-25 11:50:11 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Verify we have enough GPU memory to run this project (at least 15360MiB)\n",
        "# No changes needed in this cell\n",
        "\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO 12-25 11:55:33 [vllm_utils.py:688] Unsloth: Patching vLLM v1 graph capture\n",
            "INFO 12-25 11:55:33 [vllm_utils.py:716] Unsloth: Patching vLLM v0 graph capture\n",
            "==((====))==  Unsloth 2025.9.7: Fast Qwen2 patching. Transformers: 4.55.4. vLLM: 0.10.1.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.563 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.7.1+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.31. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "Unsloth: vLLM loading unsloth/qwen2.5-3b-instruct-unsloth-bnb-4bit with actual GPU utilization = 26.19%\n",
            "Unsloth: Your GPU has CUDA compute capability 7.5 with VRAM = 14.56 GB.\n",
            "Unsloth: Using conservativeness = 1.0. Chunked prefill tokens = 384. Num Sequences = 128.\n",
            "Unsloth: vLLM's KV Cache can use up to 1.51 GB. Also swap space = 0 GB.\n",
            "WARNING 12-25 11:55:34 [compilation.py:453] full_cuda_graph is deprecated, use cudagraph_mode=FULL instead.\n",
            "Unsloth: Not an error, but `device` is not supported in vLLM. Skipping.\n",
            "INFO 12-25 11:55:34 [utils.py:326] non-default args: {'model': 'unsloth/qwen2.5-3b-instruct-unsloth-bnb-4bit', 'load_format': 'bitsandbytes', 'dtype': torch.float16, 'seed': 0, 'max_model_len': 384, 'enable_prefix_caching': True, 'swap_space': 0, 'gpu_memory_utilization': 0.2619162374320524, 'max_num_batched_tokens': 2048, 'max_num_seqs': 128, 'max_logprobs': 0, 'disable_log_stats': True, 'quantization': 'bitsandbytes', 'enable_lora': True, 'max_lora_rank': 32, 'enable_chunked_prefill': True, 'compilation_config': {\"level\":3,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"inductor\",\"custom_ops\":[],\"splitting_ops\":null,\"use_inductor\":true,\"compile_sizes\":null,\"inductor_compile_config\":{\"epilogue_fusion\":true,\"max_autotune\":false,\"shape_padding\":true,\"trace.enabled\":false,\"triton.cudagraphs\":true,\"debug\":false,\"dce\":true,\"memory_planning\":true,\"coordinate_descent_tuning\":false,\"trace.graph_diagram\":false,\"compile_threads\":4,\"group_fusion\":true,\"disable_progress\":false,\"verbose_progress\":true,\"triton.multi_kernel\":0,\"triton.use_block_ptr\":true,\"triton.enable_persistent_tma_matmul\":true,\"triton.autotune_at_compile_time\":false,\"triton.cooperative_reductions\":false,\"cuda.compile_opt_level\":\"-O2\",\"cuda.enable_cuda_lto\":true,\"combo_kernels\":false,\"benchmark_combo_kernel\":true,\"combo_kernel_foreach_dynamic_shapes\":true,\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"cudagraph_mode\":2,\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":null,\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":true,\"pass_config\":{},\"max_capture_size\":null,\"local_cache_dir\":null}}\n",
            "INFO 12-25 11:55:35 [__init__.py:711] Resolved architecture: Qwen2ForCausalLM\n",
            "WARNING 12-25 11:55:35 [__init__.py:2819] Casting torch.bfloat16 to torch.float16.\n",
            "INFO 12-25 11:55:35 [__init__.py:1750] Using max model len 384\n",
            "INFO 12-25 11:55:35 [scheduler.py:222] Chunked prefill is enabled with max_num_batched_tokens=2048.\n",
            "Unsloth: vLLM Bitsandbytes config using kwargs = {'load_in_8bit': False, 'load_in_4bit': True, 'bnb_4bit_compute_dtype': 'float16', 'bnb_4bit_quant_storage': 'uint8', 'bnb_4bit_quant_type': 'nf4', 'bnb_4bit_use_double_quant': True, 'llm_int8_enable_fp32_cpu_offload': False, 'llm_int8_has_fp16_weight': False, 'llm_int8_skip_modules': ['lm_head', 'multi_modal_projector', 'merger', 'modality_projection', 'model.layers.2.mlp', 'model.layers.3.mlp', 'model.layers.30.mlp'], 'llm_int8_threshold': 6.0}\n",
            "INFO 12-25 11:55:35 [llm_engine.py:222] Initializing a V0 LLM engine (v0.10.1) with config: model='unsloth/qwen2.5-3b-instruct-unsloth-bnb-4bit', speculative_config=None, tokenizer='unsloth/qwen2.5-3b-instruct-unsloth-bnb-4bit', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=384, download_dir=None, load_format=bitsandbytes, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=bitsandbytes, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=unsloth/qwen2.5-3b-instruct-unsloth-bnb-4bit, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={\"level\":0,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"inductor\",\"custom_ops\":[],\"splitting_ops\":null,\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"epilogue_fusion\":true,\"max_autotune\":false,\"shape_padding\":true,\"trace.enabled\":false,\"triton.cudagraphs\":true,\"debug\":false,\"dce\":true,\"memory_planning\":true,\"coordinate_descent_tuning\":false,\"trace.graph_diagram\":false,\"compile_threads\":4,\"group_fusion\":true,\"disable_progress\":false,\"verbose_progress\":true,\"triton.multi_kernel\":0,\"triton.use_block_ptr\":true,\"triton.enable_persistent_tma_matmul\":true,\"triton.autotune_at_compile_time\":false,\"triton.cooperative_reductions\":false,\"cuda.compile_opt_level\":\"-O2\",\"cuda.enable_cuda_lto\":true,\"combo_kernels\":false,\"benchmark_combo_kernel\":true,\"combo_kernel_foreach_dynamic_shapes\":true,\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"cudagraph_mode\":2,\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":true,\"pass_config\":{},\"max_capture_size\":128,\"local_cache_dir\":null}, use_cached_outputs=False, \n",
            "INFO 12-25 11:55:37 [model_runner.py:1080] Starting to load model unsloth/qwen2.5-3b-instruct-unsloth-bnb-4bit...\n",
            "INFO 12-25 11:55:38 [bitsandbytes_loader.py:742] Loading weights with BitsAndBytes quantization. May take a while ...\n",
            "INFO 12-25 11:55:38 [weight_utils.py:296] Using model weights format ['*.safetensors']\n",
            "INFO 12-25 11:55:38 [weight_utils.py:349] No model.safetensors.index.json found in remote.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
            "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00, 17.69it/s]\n",
            "\n",
            "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
            "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:01<00:00,  1.44s/it]\n",
            "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:01<00:00,  1.44s/it]\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO 12-25 11:55:41 [model_runner.py:1112] Model loading took 2.3199 GiB and 2.373516 seconds\n",
            "INFO 12-25 11:55:42 [worker.py:295] Memory profiling takes 1.27 seconds\n",
            "INFO 12-25 11:55:42 [worker.py:295] the current vLLM instance can use total_gpu_memory (14.56GiB) x gpu_memory_utilization (0.26) = 3.81GiB\n",
            "INFO 12-25 11:55:42 [worker.py:295] model weights take 2.32GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 0.70GiB; the rest of the memory reserved for KV Cache is 0.80GiB.\n",
            "INFO 12-25 11:55:43 [executor_base.py:114] # cuda blocks: 1451, # CPU blocks: 0\n",
            "INFO 12-25 11:55:43 [executor_base.py:119] Maximum concurrency for 384 tokens per request: 60.46x\n",
            "INFO 12-25 11:55:43 [vllm_utils.py:721] Unsloth: Running patched vLLM v0 `capture_model`.\n",
            "INFO 12-25 11:55:43 [vllm_utils.py:721] Unsloth: Running patched vLLM v0 `capture_model`.\n",
            "INFO 12-25 11:55:43 [model_runner.py:1383] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Capturing CUDA graph shapes: 100%|ââââââââââ| 19/19 [00:07<00:00,  2.39it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO 12-25 11:55:51 [model_runner.py:1535] Graph capturing finished in 8 secs, took 0.41 GiB\n",
            "INFO 12-25 11:55:51 [vllm_utils.py:728] Unsloth: Patched vLLM v0 graph capture finished in 8 secs.\n",
            "INFO 12-25 11:55:51 [vllm_utils.py:728] Unsloth: Patched vLLM v0 graph capture finished in 8 secs.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO 12-25 11:55:51 [llm_engine.py:417] init engine (profile, create kv cache, warmup model) took 10.81 seconds\n",
            "INFO 12-25 11:55:51 [llm.py:298] Supported_tasks: ['generate']\n",
            "Unsloth: Just some info: will skip parsing ['k_norm', 'post_feedforward_layernorm', 'norm1', 'pre_feedforward_layernorm', 'post_attention_layernorm', 'layer_norm1', 'q_norm', 'input_layernorm', 'post_layernorm', 'norm2', 'layer_norm2']\n",
            "Unsloth: Just some info: will skip parsing ['k_norm', 'post_feedforward_layernorm', 'norm1', 'pre_feedforward_layernorm', 'post_attention_layernorm', 'layer_norm1', 'q_norm', 'cross_attn_input_layernorm', 'cross_attn_post_attention_layernorm', 'input_layernorm', 'post_layernorm', 'norm2', 'layer_norm2']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unsloth 2025.9.7 patched 36 layers with 36 QKV layers, 36 O layers and 36 MLP layers.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 30.8 s (started: 2025-12-25 11:55:32 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Load the `Qwen 2.5 3B Instruct`, and set parameters for the project\n",
        "# The first time unsloth is imported, it will do its magic and patch the modules\n",
        "# it works with. This may 2-5 minutes.\n",
        "# TODO: Fill in the missing parts marked with **********\n",
        "\n",
        "import unsloth\n",
        "\n",
        "\n",
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "max_seq_length = 384  # Increase if you get errors about the sequence length\n",
        "\n",
        "# Set the LoRA rank to an appropriate value\n",
        "# Read about setting LoRA rank:\n",
        "# https://docs.unsloth.ai/get-started/fine-tuning-llms-guide/lora-hyperparameters-guide\n",
        "# lora_rank = ********** # Explain your choice\n",
        "# 32 is a strong default for 3B models, Enough capacity to learn new behaviors, low VRAM overhead\n",
        "lora_rank = 32\n",
        "\n",
        "# Load the Instruct model in 4-bit mode\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name=\"Qwen/Qwen2.5-3B-Instruct\",\n",
        "    max_seq_length=max_seq_length,\n",
        "    load_in_4bit=True,  # We'll use quantization!\n",
        "    fast_inference=True,  # This uses vllm for faster inference\n",
        "    max_lora_rank=lora_rank,\n",
        "    gpu_memory_utilization=0.5,  # You can reduce this if you get an memory error\n",
        ")\n",
        "\n",
        "\"\"\"Target modules: \n",
        "LoRA should be applied to all major linear layers, such as those in the attention mechanism \n",
        "and the feed-forward (MLP) blocks.\n",
        "Research shows that when LoRA is applied broadly across these layers, \n",
        "the modelâs performance becomes very close to that of full fine-tuning, \n",
        "where all model parameters are updated. \n",
        "This is because different layers are responsible for different aspects of learning, \n",
        "such as reasoning, contextual understanding, and language generation. \n",
        "Ignoring some of these layers can limit the modelâs ability to adapt effectively.\n",
        "\"\"\"\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r=lora_rank,\n",
        "    target_modules=[\n",
        "        \"q_proj\",\n",
        "        \"k_proj\",\n",
        "        \"v_proj\",\n",
        "        \"o_proj\", \n",
        "        \"gate_proj\",\n",
        "        \"up_proj\",\n",
        "        \"down_proj\",\n",
        "    ],\n",
        "    lora_alpha=lora_rank,\n",
        "    use_gradient_checkpointing=\"unsloth\",  # Unsloth enables longer contexts\n",
        "    # See: https://github.com/unslothai/unsloth\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Try Prompt Engineering to Count Letters\n",
        "\n",
        "Let's work on the system prompt a little to see if we can get the model to count the number of the letter `g` in `engage`.\n",
        "\n",
        "\n",
        "Here you must:\n",
        "* Write clear instructions\n",
        "* Break the problem down into steps (Chain-of-Thought prompting)\n",
        "* Provide at least one example for the model to follow (Few-shot prompting)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Adding requests: 100%|ââââââââââ| 1/1 [00:00<00:00, 1084.08it/s]\n",
            "Processed prompts: 100%|ââââââââââ| 1/1 [00:06<00:00,  6.04s/it, est. speed input: 4.80 toks/s, output: 2.48 toks/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== TEXT FOR COMPLETION ===\n",
            "<|im_start|>system\n",
            "<|im_end|>\n",
            "<|im_start|>user\n",
            "How many of the letter \"g\" are there in the word \"engage\"<|im_end|>\n",
            "<|im_start|>assistant\n",
            "\n",
            "=== GENERATED OUTPUT ===\n",
            "In the word \"engage\", there is only one letter \"g\".\n",
            "time: 6.05 s (started: 2025-12-25 12:01:19 +00:00)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# First, let's see what happens when we have a blank system prompt\n",
        "# No changes needed in this cell\n",
        "SYSTEM_PROMPT = \"\"\"\"\"\"\n",
        "USER_PROMPT = 'How many of the letter \"g\" are there in the word \"engage\"'\n",
        "\n",
        "# Convert the chat messages to a single string so the model can complete it\n",
        "text_for_completion = tokenizer.apply_chat_template(\n",
        "    conversation=[\n",
        "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": USER_PROMPT,\n",
        "        },\n",
        "    ],\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True,\n",
        ")\n",
        "\n",
        "from vllm import SamplingParams\n",
        "\n",
        "# Set the LLM sampling parameters\n",
        "sampling_params = SamplingParams(\n",
        "    temperature=0.8,\n",
        "    top_p=0.95,\n",
        "    max_tokens=2048,\n",
        ")\n",
        "\n",
        "# Generate the text completion\n",
        "output = (\n",
        "    model.fast_generate(\n",
        "        [text_for_completion],\n",
        "        sampling_params=sampling_params,\n",
        "        lora_request=None,\n",
        "    )[0]\n",
        "    .outputs[0]\n",
        "    .text\n",
        ")\n",
        "\n",
        "# Print the text input for the model and the model's output\n",
        "print(\"=== TEXT FOR COMPLETION ===\")\n",
        "print(text_for_completion)\n",
        "print(\"=== GENERATED OUTPUT ===\")\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Without any prompting the model will generate an output such as this:\n",
        "\n",
        "```\n",
        "=== GENERATED OUTPUT ===\n",
        "There is one letter \"g\" in the word \"engage\".\n",
        "```\n",
        "\n",
        "Now let's work on the system prompt to help the model break this problem down into steps, which might help it get the right answer (2 `g`'s in `engage`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Adding requests: 100%|ââââââââââ| 1/1 [00:00<00:00, 585.63it/s]\n",
            "Processed prompts: 100%|ââââââââââ| 1/1 [00:02<00:00,  2.08s/it, est. speed input: 101.63 toks/s, output: 38.53 toks/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== TEXT FOR COMPLETION ===\n",
            "<|im_start|>system\n",
            "\n",
            "You are a careful and precise language model.\n",
            "\n",
            "Your task is to count how many times a specific letter appears in a given word.\n",
            "Follow these steps exactly:\n",
            "1. Read the word carefully.\n",
            "2. Break the word into individual letters.\n",
            "3. Compare each letter to the target letter.\n",
            "4. Keep a running count of how many times the target letter appears.\n",
            "5. Show your step-by-step reasoning.\n",
            "6.Provide the final count as a number.\n",
            "\n",
            "Examples:\n",
            "\n",
            "Example 1\n",
            "Word: apple\n",
            "Target letter: p\n",
            "\n",
            "Step-by-step reasoning:\n",
            "The letters are a, p, p, l, e.\n",
            "The letter p appears twice.\n",
            "\n",
            "Final answer: 2\n",
            "\n",
            "Example 2\n",
            "Word: banana\n",
            "Target letter: a\n",
            "\n",
            "Step-by-step reasoning:\n",
            "The letters are b, a, n, a, n, a.\n",
            "The letter a appears three times.\n",
            "\n",
            "Final answer: 3\n",
            "<|im_end|>\n",
            "<|im_start|>user\n",
            "How many of the letter \"g\" are there in the word \"engage\"<|im_end|>\n",
            "<|im_start|>assistant\n",
            "\n",
            "=== GENERATED OUTPUT ===\n",
            "Step-by-step reasoning:\n",
            "The letters in the word \"engage\" are: g, a, n, g, e, n, g.\n",
            "The letter \"g\" appears in the following positions: 1st, 4th, 5th, and 6th.\n",
            "Therefore, the letter \"g\" appears 4 times in the word \"engage\".\n",
            "\n",
            "Final answer: 4\n",
            "time: 2.09 s (started: 2025-12-25 12:06:19 +00:00)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Let's work on a new system prompt that will help the model break this problem\n",
        "# down into steps, for example, using \"letter-by-letter\" spelling.\n",
        "# TODO: Fill in the missing parts marked with **********\n",
        "\n",
        "# Use a CoT prompt with at least one example\n",
        "SYSTEM_PROMPT = \"\"\"\n",
        "You are a careful and precise language model.\n",
        "\n",
        "Your task is to count how many times a specific letter appears in a given word.\n",
        "Follow these steps exactly:\n",
        "1. Read the word carefully.\n",
        "2. Break the word into individual letters.\n",
        "3. Compare each letter to the target letter.\n",
        "4. Keep a running count of how many times the target letter appears.\n",
        "5. Show your step-by-step reasoning.\n",
        "6.Provide the final count as a number.\n",
        "\n",
        "Examples:\n",
        "\n",
        "Example 1\n",
        "Word: apple\n",
        "Target letter: p\n",
        "\n",
        "Step-by-step reasoning:\n",
        "The letters are a, p, p, l, e.\n",
        "The letter p appears twice.\n",
        "\n",
        "Final answer: 2\n",
        "\n",
        "Example 2\n",
        "Word: banana\n",
        "Target letter: a\n",
        "\n",
        "Step-by-step reasoning:\n",
        "The letters are b, a, n, a, n, a.\n",
        "The letter a appears three times.\n",
        "\n",
        "Final answer: 3\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "USER_PROMPT = 'How many of the letter \"g\" are there in the word \"engage\"'\n",
        "\n",
        "# Convert the chat messages to a single string so the model can complete it\n",
        "text_for_completion = tokenizer.apply_chat_template(\n",
        "    conversation=[\n",
        "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": USER_PROMPT,\n",
        "        },\n",
        "    ],\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True,\n",
        ")\n",
        "\n",
        "from vllm import SamplingParams\n",
        "\n",
        "# Set the LLM sampling parameters\n",
        "sampling_params = SamplingParams(\n",
        "    temperature=0.8,\n",
        "    top_p=0.95,\n",
        "    max_tokens=2048,\n",
        ")\n",
        "\n",
        "# Generate the text completion\n",
        "output = (\n",
        "    model.fast_generate(\n",
        "        [text_for_completion],\n",
        "        sampling_params=sampling_params,\n",
        "        lora_request=None,\n",
        "    )[0]\n",
        "    .outputs[0]\n",
        "    .text\n",
        ")\n",
        "\n",
        "# Print the text input for the model and the model's output\n",
        "print(\"=== TEXT FOR COMPLETION ===\")\n",
        "print(text_for_completion)\n",
        "print(\"=== GENERATED OUTPUT ===\")\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Did your new prompt get the right answer? Did the model follow all of your instructions?\n",
        "\n",
        "Maybe yes, maybe no. Either way, we'll want the model to reliably complete this challenge. So let's use GRPO to help it!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create a letter-counting dataset\n",
        "\n",
        "To train a model, we'll first need to create a dataset. We'll use the HuggingFace `datasets` package."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "62\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['idea',\n",
              " 'glow',\n",
              " 'rust',\n",
              " 'maze',\n",
              " 'echo',\n",
              " 'wisp',\n",
              " 'veto',\n",
              " 'lush',\n",
              " 'gaze',\n",
              " 'knit']"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 5.34 ms (started: 2025-12-25 12:06:54 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Create a list of words of different lengths\n",
        "# No changes are needed in this cell.\n",
        "\n",
        "ALL_WORDS = [\n",
        "    \"idea\",\n",
        "    \"glow\",\n",
        "    \"rust\",\n",
        "    \"maze\",\n",
        "    \"echo\",\n",
        "    \"wisp\",\n",
        "    \"veto\",\n",
        "    \"lush\",\n",
        "    \"gaze\",\n",
        "    \"knit\",\n",
        "    \"fume\",\n",
        "    \"plow\",\n",
        "    \"void\",\n",
        "    \"oath\",\n",
        "    \"grim\",\n",
        "    \"crisp\",\n",
        "    \"lunar\",\n",
        "    \"fable\",\n",
        "    \"quest\",\n",
        "    \"verge\",\n",
        "    \"brawn\",\n",
        "    \"elude\",\n",
        "    \"aisle\",\n",
        "    \"ember\",\n",
        "    \"crave\",\n",
        "    \"ivory\",\n",
        "    \"mirth\",\n",
        "    \"knack\",\n",
        "    \"wryly\",\n",
        "    \"onset\",\n",
        "    \"mosaic\",\n",
        "    \"velvet\",\n",
        "    \"sphinx\",\n",
        "    \"radius\",\n",
        "    \"summit\",\n",
        "    \"banner\",\n",
        "    \"cipher\",\n",
        "    \"glisten\",\n",
        "    \"mantle\",\n",
        "    \"scarab\",\n",
        "    \"expose\",\n",
        "    \"fathom\",\n",
        "    \"tavern\",\n",
        "    \"fusion\",\n",
        "    \"relish\",\n",
        "    \"lantern\",\n",
        "    \"enchant\",\n",
        "    \"torrent\",\n",
        "    \"capture\",\n",
        "    \"orchard\",\n",
        "    \"eclipse\",\n",
        "    \"frescos\",\n",
        "    \"triumph\",\n",
        "    \"absolve\",\n",
        "    \"gossipy\",\n",
        "    \"prelude\",\n",
        "    \"whistle\",\n",
        "    \"resolve\",\n",
        "    \"zealous\",\n",
        "    \"mirage\",\n",
        "    \"aperture\",\n",
        "    \"sapphire\",\n",
        "]\n",
        "\n",
        "print(len(ALL_WORDS))\n",
        "\n",
        "ALL_WORDS[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating train split: 401 examples [00:00, 5076.32 examples/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'words': 'idea', 'letters': 'a', 'counts': 1}"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 634 ms (started: 2025-12-25 12:07:11 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Create the dataset as a Hugging Face Dataset using Dataset.from_generator\n",
        "# No changes needed in this cell\n",
        "\n",
        "from datasets import Dataset\n",
        "import random\n",
        "\n",
        "\n",
        "# Go through the letters from the words (as well as letters not in the words),\n",
        "# and create a labelled dataset with all the different combinations.\n",
        "# For example for the word gaze:\n",
        "# 1. How many i's are in idea? <-- count should be 1\n",
        "# 2. How many d's are in idea? <-- count should be 1\n",
        "# 3. How many e's are in idea? <-- count should be 1\n",
        "# 4. How many a's are in idea? <-- count should be 1\n",
        "# 5. How many b's are in idea? <-- a letter not in word (count should be zero)\n",
        "def generate_records():\n",
        "    for word in ALL_WORDS:\n",
        "        for letter in sorted(set(word)):\n",
        "            yield {\"words\": word, \"letters\": letter, \"counts\": word.count(letter)}\n",
        "\n",
        "        # pick random letters not in the word\n",
        "        num_letters_not_in_word_left = int(len(word) // 7 + 1)\n",
        "\n",
        "        random.seed(hash(word))\n",
        "\n",
        "        all_letters = list(\"abcdefghijklmnopqrstuvwxyz\")\n",
        "\n",
        "        random.shuffle(all_letters)\n",
        "        for letter in all_letters:\n",
        "            if letter not in word:\n",
        "                yield {\"words\": word, \"letters\": letter, \"counts\": 0}\n",
        "                num_letters_not_in_word_left -= 1\n",
        "            if num_letters_not_in_word_left == 0:\n",
        "                break\n",
        "\n",
        "\n",
        "ds = Dataset.from_generator(generate_records)\n",
        "\n",
        "# Show the first item\n",
        "ds[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|ââââââââââ| 401/401 [00:00<00:00, 3738.88 examples/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'words': 'idea',\n",
              " 'letters': 'a',\n",
              " 'counts': 1,\n",
              " 'prompt': [{'content': \"\\nRespond in the following format:\\n<reasoning>\\nCounting the number of [letter_to_count]'s in the word [word]\\n1. [first letter] - [count of requested letter so far] so far\\n2. [second letter] - [count of requested letter so far] so far\\n...\\n</reasoning>\\n<answer>\\n[number]\\n</answer>\\n\",\n",
              "   'role': 'system'},\n",
              "  {'content': 'How many of the letter \"a\" are there in the word \"idea\"',\n",
              "   'role': 'user'}]}"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 128 ms (started: 2025-12-25 12:07:32 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Add the entire prompt (system + user) and the answer to the dataset\n",
        "# We'll use a prompt that spells out the word letter-by-letter\n",
        "# No changes needed in this cell\n",
        "\n",
        "import re\n",
        "from datasets import load_dataset, Dataset\n",
        "\n",
        "# Simple CoT prompt (zero-shot)\n",
        "SYSTEM_PROMPT = \"\"\"\n",
        "Respond in the following format:\n",
        "<reasoning>\n",
        "Counting the number of [letter_to_count]'s in the word [word]\n",
        "1. [first letter] - [count of requested letter so far] so far\n",
        "2. [second letter] - [count of requested letter so far] so far\n",
        "...\n",
        "</reasoning>\n",
        "<answer>\n",
        "[number]\n",
        "</answer>\n",
        "\"\"\"\n",
        "\n",
        "ds = ds.map(\n",
        "    lambda x: {  # type: ignore\n",
        "        \"prompt\": [\n",
        "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": 'How many of the letter \"{}\" are there in the word \"{}\"'.format(\n",
        "                    x[\"letters\"], x[\"words\"]\n",
        "                ),\n",
        "            },\n",
        "        ],\n",
        "    }\n",
        ")\n",
        "\n",
        "ds[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Adding requests: 100%|ââââââââââ| 1/1 [00:00<00:00, 793.92it/s]\n",
            "Processed prompts: 100%|ââââââââââ| 1/1 [00:01<00:00,  1.69s/it, est. speed input: 62.18 toks/s, output: 38.49 toks/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<reasoning>\n",
            "Counting the number of a's in the word idea\n",
            "1. i - 0 so far\n",
            "2. d - 1 so far\n",
            "3. e - 2 so far\n",
            "4. a - 3 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "3\n",
            "</answer>\n",
            "time: 1.7 s (started: 2025-12-25 12:07:45 +00:00)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Let's see how well the model runs out-of-the-box\n",
        "# No changes needed in this cell\n",
        "\n",
        "text = tokenizer.apply_chat_template(\n",
        "    ds[0][\"prompt\"], tokenize=False, add_generation_prompt=True\n",
        ")\n",
        "\n",
        "from vllm import SamplingParams\n",
        "\n",
        "sampling_params = SamplingParams(\n",
        "    temperature=0.8,\n",
        "    top_p=0.95,\n",
        "    max_tokens=1024,\n",
        ")\n",
        "output = (\n",
        "    model.fast_generate(\n",
        "        [text],\n",
        "        sampling_params=sampling_params,\n",
        "        lora_request=None,\n",
        "    )[0]\n",
        "    .outputs[0]\n",
        "    .text\n",
        ")\n",
        "\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Reward Functions\n",
        "\n",
        "One goal of creating reward functions is to guide the model toward behaviors that help it reach its goal (counting the occurrences of a letter within a word) more easily. Since there is more than one way to carry out any step-by-step task (e.g. whether or not you use bullet points to separate your steps), there's a bit of judgement involved in choosing what behaviors to reward, i.e. how do we provide partial credit or \"shape\" our rewards?\n",
        "\n",
        "In this case we will encourage the model to (whether or not this structure is best):\n",
        "* use numbers for bullet points when spelling out the word\n",
        "* to spell the word correctly\n",
        "* to count the requested letter correctly\n",
        "* to use the requested reasoning format\n",
        "* to get the final answer correct.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Numbering reward function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-0.5, 0.5]\n",
            "time: 2.75 ms (started: 2025-12-25 12:18:26 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Let's work on a function that the numbering in the bullet points is correct\n",
        "# When using GRPO, we lean on reward functions that are relatively easy to\n",
        "# compute, thus removing the need to have a second large model just for\n",
        "# evaluation.\n",
        "# In this case, we'll use regular expressions quite a bit.\n",
        "\n",
        "\n",
        "\n",
        "def extract_letter_numbering(response):\n",
        "    \"\"\"Extract the numbers at the beginning of the line\n",
        "\n",
        "    Example:\n",
        "    1. g - 1 so far\n",
        "    2. o - 1 so far\n",
        "    3. a - 2 so far\n",
        "    4. a - 2 so far\n",
        "    5. l - 2 so far\n",
        "    returns [1, 2, 3, 4, 5]\n",
        "    \"\"\"\n",
        "    import re\n",
        "\n",
        "    # We use a regular expression to find lines of the form:\n",
        "    # '\\n[number]. [letter]'\n",
        "    pattern = r\"\\n(\\d+). [a-z]\"\n",
        "\n",
        "    # Use `re` to find all matches of the pattern in the response\n",
        "    matches = re.findall(pattern, response)\n",
        "    if matches:\n",
        "        return [int(m) for m in matches]\n",
        "    return []\n",
        "\n",
        "\n",
        "assert extract_letter_numbering(\n",
        "    \"\"\"\n",
        "1. g - 1 so far\n",
        "2. o - 1 so far\n",
        "3. a - 2 so far\n",
        "4. a - 2 so far\n",
        "5. l - 2 so far\n",
        "\"\"\"\n",
        ") == [1, 2, 3, 4, 5]\n",
        "\n",
        "\n",
        "def numbering_reward_func(completions, words, **kwargs) -> list[float]:\n",
        "    \"\"\"Provides a reward for getting the numbering at the beginning of the line correct\n",
        "\n",
        "    1. g - 1 so far <-- Good in-order numbering\n",
        "    2. o - 1 so far <-- Good in-order numbering\n",
        "    3. a - 2 so far <-- Good in-order numbering\n",
        "    3. l - 2 so far <-- Bad numbering, out-of-order, 3 should be 4\n",
        "    1. l - 2 so far <-- Bad numbering, extra letter and out-of-order\n",
        "    1. l - 2 so far <-- Bad numbering, extra letter and out-of-order\n",
        "\n",
        "    \"\"\"\n",
        "    responses = [completion[0][\"content\"] for completion in completions]\n",
        "\n",
        "    res = []\n",
        "    for response, word in zip(responses, words):\n",
        "        reward = 0\n",
        "\n",
        "        for ix, spell_number in enumerate(extract_letter_numbering(response)):\n",
        "            line_number = ix + 1\n",
        "\n",
        "            # Get points for in-order numbering\n",
        "            if spell_number == line_number:\n",
        "                # (positive for good behavior, negative for bad)\n",
        "                reward += 1.0\n",
        "            # Otherwise lose points\n",
        "            else:\n",
        "                # (positive for good behavior, negative for bad)\n",
        "                reward -= 1.0\n",
        "\n",
        "            # Lose extra points for continuing beyond the length of the word\n",
        "            if line_number > len(word):  # We use the index of the line\n",
        "                # (positive for good behavior, negative for bad)\n",
        "                reward -= 1.0\n",
        "\n",
        "        res.append(reward / len(word))\n",
        "    return res\n",
        "\n",
        "\n",
        "res = numbering_reward_func(\n",
        "    completions=[\n",
        "        [\n",
        "            {  # Worse response\n",
        "                \"content\": \"\"\"<reasoning>\n",
        "Here is a letter by letter spelling:\n",
        "1. g - 1 so far <-- Good in-order numbering\n",
        "2. o - 1 so far <-- Good in-order numbering\n",
        "3. a - 2 so far <-- Good in-order numbering\n",
        "3. l - 2 so far <-- Bad numbering, out-of-order, 3 should be 4\n",
        "1. l - 2 so far <-- Bad numbering, extra letter and out-of-order\n",
        "1. l - 2 so far <-- Bad numbering, extra letter and out-of-order\n",
        "</reasoning>\n",
        "<answer>2</answer>\"\"\"\n",
        "            },\n",
        "        ],\n",
        "        [\n",
        "            {  # Better response\n",
        "                \"content\": \"\"\"<reasoning>\n",
        "Here is a letter by letter spelling:\n",
        "1. g - 1 so far <-- Good in-order numbering\n",
        "2. o - 1 so far <-- Good in-order numbering\n",
        "3. a - 2 so far <-- Good in-order numbering\n",
        "3. l - 2 so far <-- Bad numbering, out-of-order, 3 should be 4\n",
        "</reasoning>\n",
        "<answer>2</answer>\"\"\"\n",
        "            },\n",
        "        ],\n",
        "    ],\n",
        "    words=[\"goal\", \"goal\"],\n",
        ")\n",
        "print(res)\n",
        "\n",
        "assert res[1] > res[0], \"The better response should have a higher reward\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Spelling reward function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-1.0, 2.0]\n",
            "time: 3.53 ms (started: 2025-12-25 12:21:13 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Reward correct spelling of the word\n",
        "# TODO: Fill in the missing parts marked with **********\n",
        "\n",
        "\n",
        "def extract_spelling(response):\n",
        "    \"\"\"Extract the spelling from the response\n",
        "\n",
        "    Example:\n",
        "    1. g - 1 so far\n",
        "    2. o - 1 so far\n",
        "    3. a - 2 so far\n",
        "    3. l - 2 so far\n",
        "    5. l - 2 so far\n",
        "    Returns \"goall\"\n",
        "    \"\"\"\n",
        "    import re\n",
        "\n",
        "    pattern = r\"\\n\\d+. ([a-z])\"\n",
        "    matches = re.findall(pattern, response, flags=re.IGNORECASE)\n",
        "    if matches:\n",
        "        return \"\".join([m for m in matches])\n",
        "    return \"\"\n",
        "\n",
        "\n",
        "extract_spelling(\n",
        "    \"\"\"Here is a letter by letter spelling:\n",
        "\n",
        "1. g - 1 so far\n",
        "2. o - 1 so far\n",
        "3. a - 2 so far\n",
        "3. l - 2 so far\n",
        "5. l - 2 so far\n",
        "\"\"\"\n",
        ") == \"goall\"\n",
        "\n",
        "\n",
        "def spelling_reward_func(completions, words, **kwargs) -> list[float]:\n",
        "    \"\"\"A spelling reward function.\"\"\"\n",
        "    from collections import Counter\n",
        "\n",
        "    responses = [completion[0][\"content\"] for completion in completions]\n",
        "\n",
        "    res = []\n",
        "\n",
        "    for word, response in zip(words, responses):\n",
        "        reward = 0.0\n",
        "\n",
        "        spelled = extract_spelling(response)\n",
        "\n",
        "        word_counter = Counter(word)\n",
        "        spelled_counter = Counter(spelled)\n",
        "\n",
        "        # 1. Reward exactly correct spelling\n",
        "        if spelled == word:\n",
        "            reward += 2.0\n",
        "\n",
        "        # 2. Penalize difference in length\n",
        "        reward -= abs(len(spelled) - len(word)) * 0.5\n",
        "\n",
        "        # 3. Penalize letters in response but not in the target word\n",
        "        for letter, count in spelled_counter.items():\n",
        "            extra = count - word_counter.get(letter, 0)\n",
        "            if extra > 0:\n",
        "                reward -= extra * 0.5\n",
        "\n",
        "        # 4. Penalize letters missing from the response\n",
        "        for letter, count in word_counter.items():\n",
        "            missing = count - spelled_counter.get(letter, 0)\n",
        "            if missing > 0:\n",
        "                reward -= missing * 0.5\n",
        "\n",
        "        res.append(reward)\n",
        "    return res\n",
        "\n",
        "\n",
        "res = spelling_reward_func(\n",
        "    completions=[\n",
        "        [  # Worse response\n",
        "            {\n",
        "                \"content\": \"\"\"<reasoning>\n",
        "Here is a letter by letter spelling:\n",
        "1. g - 1 so far\n",
        "2. o - 1 so far\n",
        "3. a - 2 so far\n",
        "4. l - 2 so far\n",
        "5. l - 2 so far\n",
        "</reasoning>\n",
        "<answer>2</answer>\"\"\"\n",
        "            }\n",
        "        ],\n",
        "        [  # Better Response\n",
        "            {\n",
        "                \"content\": \"\"\"<reasoning>\n",
        "Here is a letter by letter spelling:\n",
        "1. g - 1 so far\n",
        "2. o - 1 so far\n",
        "3. a - 2 so far\n",
        "4. l - 2 so far\n",
        "</reasoning>\n",
        "<answer>2</answer>\"\"\"\n",
        "            }\n",
        "        ],\n",
        "    ],\n",
        "    words=[\"goal\", \"goal\"],\n",
        ")\n",
        "\n",
        "print(res)\n",
        "\n",
        "assert res[1] > res[0], \"The better response should have a higher reward\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Counting reward function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-0.6, 1.0]\n",
            "time: 2.54 ms (started: 2025-12-25 12:30:35 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Let's reward the model for properly counting the occurrences of a letter in a word\n",
        "# TODO: Fill in the missing parts marked with **********\n",
        "# No changes needed in this cell, but feel free to experiment with variations on the prompt\n",
        "\n",
        "\n",
        "def get_resp_letters_and_counts(response):\n",
        "    \"\"\"Extract the letters and counts from the response\n",
        "\n",
        "    Example:\n",
        "    1. g - 1 so far\n",
        "    2. o - 1 so far\n",
        "    3. a - 2 so far\n",
        "    4. a - 2 so far\n",
        "    5. l - 2 so far\n",
        "    returns [('g', 1), ('o', 1), ('a', 2), ('a', 2), ('l', 2)]\n",
        "    \"\"\"\n",
        "    import re\n",
        "\n",
        "    pattern = r\"\\n(\\d+)\\. ([a-z])\\D*(\\d+)\"\n",
        "\n",
        "    # Find strings matching e.g. \"2. a - 2 so far\"\n",
        "    matches = re.findall(pattern, response, flags=re.IGNORECASE)\n",
        "\n",
        "    if not matches:\n",
        "        return []\n",
        "\n",
        "    return [\n",
        "        (matched_letter, matched_count_so_far)\n",
        "        for _, matched_letter, matched_count_so_far in matches\n",
        "    ]\n",
        "\n",
        "\n",
        "assert get_resp_letters_and_counts(\n",
        "    \"\"\"\n",
        "1. g - 1 so far\n",
        "2. o - 1 so far\n",
        "3. a - 2 so far\n",
        "4. a - 2 so far\n",
        "5. l - 2 so far\n",
        "\"\"\"\n",
        ") == [(\"g\", \"1\"), (\"o\", \"1\"), (\"a\", \"2\"), (\"a\", \"2\"), (\"l\", \"2\")]\n",
        "\n",
        "\n",
        "def counting_reward_func(completions, letters, **kwargs) -> list[float]:\n",
        "    responses = [completion[0][\"content\"] for completion in completions]\n",
        "\n",
        "    res = []\n",
        "\n",
        "    # Iterate over each of the letter-response pairs\n",
        "    for letter, response in zip(letters, responses):\n",
        "        reward = 0\n",
        "\n",
        "        letters_and_counts = get_resp_letters_and_counts(response)\n",
        "\n",
        "        # If there are no matches, provide a negative reward\n",
        "        if not letters_and_counts:\n",
        "            res.append(-1)\n",
        "            continue\n",
        "\n",
        "        # Start counting the matching letters\n",
        "        actual_count = 0\n",
        "        for resp_letter, resp_count in letters_and_counts:\n",
        "            resp_count = int(resp_count)\n",
        "            # If there's a match, count the letter\n",
        "            if letter == resp_letter:\n",
        "                actual_count += 1\n",
        "\n",
        "            if resp_count == actual_count:\n",
        "                reward += 1.0\n",
        "            else:\n",
        "                reward -= 1.0\n",
        "\n",
        "        # Return the reward normalized by the length of the matches\n",
        "        res.append(reward / len(letters_and_counts))\n",
        "    return res\n",
        "\n",
        "\n",
        "res = counting_reward_func(\n",
        "    completions=[\n",
        "        [  # Worse response\n",
        "            {\n",
        "                \"content\": \"\"\"<reasoning>\\nHere is a letter by letter spelling:\n",
        "\n",
        "1. g - 0 so far\n",
        "2. o - 0 so far\n",
        "3. a - 1 so far\n",
        "4. a - 2 so far\n",
        "5. l - 0 so far\n",
        "\n",
        "\\n</reasoning>\\n<answer>\\nThis is my answer.\\n</answer>\"\"\"\n",
        "            }\n",
        "        ],\n",
        "        [  # Better response\n",
        "            {\n",
        "                \"content\": \"\"\"<reasoning>\\nHere is a letter by letter spelling:\n",
        "\n",
        "1. g - 1 so far\n",
        "2. o - 1 so far\n",
        "3. a - 1 so far\n",
        "4. a - 1 so far\n",
        "5. l - 1 so far\n",
        "\n",
        "\\n</reasoning>\\n<answer>\\nThis is my answer.\\n</answer>\"\"\"\n",
        "            }\n",
        "        ],\n",
        "    ],\n",
        "    letters=[\"g\", \"g\"],\n",
        ")\n",
        "\n",
        "print(res)\n",
        "\n",
        "assert res[1] > res[0], \"The better response should have a higher reward\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Formatting reward functions\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.0, 1.0]\n",
            "time: 2.05 ms (started: 2025-12-25 12:32:11 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Reward the model for providing the response in a specific format\n",
        "# TODO: Fill in the missing parts marked with **********\n",
        "\n",
        "\n",
        "def extract_xml_answer(text: str) -> str:\n",
        "    \"\"\"Extracts the string between <answer> and </answer> tags.\"\"\"\n",
        "    import re\n",
        "\n",
        "    pattern = r\"<answer>(.*?)</answer>\"\n",
        "    match = re.search(pattern, text, re.DOTALL)\n",
        "    if match:\n",
        "        return match.group(1).strip()\n",
        "    return \"\"\n",
        "\n",
        "\n",
        "assert (\n",
        "    extract_xml_answer(\"\"\"\n",
        "<reasoning>\n",
        "This is my reasoning.\n",
        "</reasoning>\n",
        "<answer>SUPERCALIFRAGILISTICEXPIALIDOCIOUS</answer>\n",
        "\"\"\")\n",
        "    == \"SUPERCALIFRAGILISTICEXPIALIDOCIOUS\"\n",
        ")\n",
        "\n",
        "\n",
        "def format_reward_func(completions, **kwargs) -> list[float]:\n",
        "    \"\"\"Reward function that checks if the completion has a specific format.\"\"\"\n",
        "    pattern = r\"\\s*<reasoning>.*?</reasoning>\\s*<answer>.*?</answer>\"\n",
        "\n",
        "    res = []\n",
        "\n",
        "    for completion in completions:\n",
        "        reward = 0.0\n",
        "\n",
        "        # Extract the response content\n",
        "        response = completion[0][\"content\"]\n",
        "\n",
        "        # Check if the response matches the pattern\n",
        "        match = re.match(pattern, response, flags=re.MULTILINE | re.DOTALL)\n",
        "\n",
        "        # If it matches the required XML format\n",
        "        if match:\n",
        "            reward += 0.5\n",
        "\n",
        "            # Extract the answer from the response\n",
        "            extracted_answer = extract_xml_answer(response)\n",
        "\n",
        "            # If the answer is an integer, add more reward\n",
        "            if extracted_answer.isdigit():\n",
        "                reward += 0.5\n",
        "\n",
        "        res.append(reward)\n",
        "    return res\n",
        "\n",
        "\n",
        "res = format_reward_func(\n",
        "    completions=[\n",
        "        [{\"content\": \"This is my answer\"}],\n",
        "        [\n",
        "            {\n",
        "                \"content\": \"<reasoning>\\nThis is my reasoning.\\n</reasoning>\\n<answer>\\n3\\n</answer>\"\n",
        "            }\n",
        "        ],\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(res)\n",
        "\n",
        "assert res[1] > res[0], \"The better response should have a higher reward\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Task correctness reward function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--------------------\n",
            "Question: How many...\n",
            "Answer: 0\n",
            "Response: <reasoning>.../reasoning>\n",
            "<answer>\n",
            "3\n",
            "</answer>\n",
            "Extracted: 3\n",
            "Correct: False!\n",
            "    \n",
            "[0.0, 1.0]\n",
            "time: 1.72 ms (started: 2025-12-25 12:33:57 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Reward the model for providing the correct answer\n",
        "# TODO: Fill in the missing parts marked with **********\n",
        "\n",
        "\n",
        "def correct_answer_reward_func(prompts, completions, counts, **kwargs) -> list[float]:\n",
        "    \"\"\"Reward the final answer if it is correct.\"\"\"\n",
        "    responses = [completion[0][\"content\"] for completion in completions]\n",
        "\n",
        "    extracted_responses = [extract_xml_answer(r) for r in responses]\n",
        "\n",
        "    # Print a nice summary of the first prompt, answer, and response to see while training\n",
        "    print(f\"\"\"\n",
        "{\"-\" * 20}\n",
        "Question: {prompts[0][-1][\"content\"]}\n",
        "Answer: {counts[0]}\n",
        "Response: {responses[0]}\n",
        "Extracted: {extracted_responses[0]}\n",
        "Correct: {str(extracted_responses[0]) == str(counts[0])}!\n",
        "    \"\"\")\n",
        "\n",
        "    res = [\n",
        "        # Provide reward for exactly correct answer\n",
        "        1.0 if str(r) == str(a) else 0.0\n",
        "        for r, a in zip(extracted_responses, counts)\n",
        "    ]\n",
        "    return res\n",
        "\n",
        "\n",
        "res = correct_answer_reward_func(\n",
        "    prompts=[\n",
        "        [{\"content\": \"\"\"How many...\"\"\"}],\n",
        "        [{\"content\": \"\"\"How many...\"\"\"}],\n",
        "    ],\n",
        "    completions=[\n",
        "        [{\"content\": \"\"\"<reasoning>.../reasoning>\\n<answer>\\n3\\n</answer>\"\"\"}],\n",
        "        [{\"content\": \"\"\"<reasoning>.../reasoning>\\n<answer>\\n3\\n</answer>\"\"\"}],\n",
        "    ],\n",
        "    letters=[\"g\", \"g\"],\n",
        "    counts=[0, 3],\n",
        ")\n",
        "\n",
        "print(res)\n",
        "\n",
        "assert res[1] > res[0], \"The better response should have a higher reward\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### List the reward functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 395 Î¼s (started: 2025-12-25 12:34:04 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# List out the reward functions we will use\n",
        "# No changes needed in this cell\n",
        "\n",
        "REWARD_FUNCS = [\n",
        "    numbering_reward_func,\n",
        "    spelling_reward_func,\n",
        "    counting_reward_func,\n",
        "    format_reward_func,\n",
        "    correct_answer_reward_func,\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train the model\n",
        "\n",
        "Now set up GRPO Trainer and configurations!\n",
        "\n",
        "As you run the trainer, the goal is to see the various `reward` columns increase.\n",
        "\n",
        "After 50 steps or more, you may notice some of the reward standard deviations begin to decrease, meaning that the different predictions are starting to converge on solutions that give similar rewards. If your model has learned the task, then you'll see the `correct_answer_reward_function` increase to its highest value (check the function to see what that is).\n",
        "\n",
        "Here is an example, which successfully converged on a higher reward. Note, the values you see here will probably be different from yours, especially if your reward amounts are different.\n",
        "\n",
        "| Step | Training Loss | reward   | reward_std | ... | kl      | rewards / correct_answer_reward_function / mean | rewards / correct_answer_reward_function / std |\n",
        "|------|---------------|----------|------------|-----|---------|------------------------------------------|-----------------------------------------|\n",
        "| 1    | 0.000000      | 7.961805 | 2.368493   | ... | 0.020369| 0.875000                                 | 1.024695                                |\n",
        "| 2    | 0.000000      | 7.937500 | 1.352467   | ... | 0.016483| 0.875000                                 | 1.024695                                |\n",
        "| 3    | 0.000000      | 1.894792 | 6.462189   | ... | 0.013677| 0.375000                                 | 0.806226                                |\n",
        "| ...  | ...           | ...      | ...        | ... | ...     | ...                                      | ...                                     |\n",
        "| 398  | 0.000100      | 13.000000| 0.000000   | ... | 0.088529| 2.000000                                 | 0.000000                                |\n",
        "| 399  | 0.000100      | 13.000000| 0.000000   | ... | 0.088617| 2.000000                                 | 0.000000                                |\n",
        "| 400  | 0.000100      | 13.000000| 0.000000   | ... | 0.096202| 2.000000                                 | 0.000000                                |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 998 Î¼s (started: 2025-12-25 12:36:22 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Fill in the GRPO Parameters we'll use throughout this project\n",
        "# TODO: Fill in the missing parts marked with **********\n",
        "\n",
        "# Read about the GRPO params here https://huggingface.co/docs/trl/main/en/grpo_trainer\n",
        "COMMON_GRPO_TRAINING_PARAMS = dict(\n",
        "    # Set appropriate values for `learning_rate` and `beta`\n",
        "    # See: https://docs.unsloth.ai/get-started/fine-tuning-llms-guide/lora-hyperparameters-guide\n",
        "    # See: https://huggingface.co/docs/trl/main/en/grpo_trainer\n",
        "    # Learning rate and KL control (beta)\n",
        "    # Conservative LR for LoRA + GRPO stability\n",
        "    learning_rate=5e-6,\n",
        "    beta=0.1,\n",
        "    # Set the batch size appropriately for your hardware. For GRPO there are a number of parameters to set.\n",
        "    # If you are not sure about your GPU, assume you have a T4. See the memory specs here:\n",
        "    # https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/tesla-product-literature/T4%20Product%20Brief.pdf\n",
        "    per_device_train_batch_size=8,   # <=16 recommended on T4\n",
        "    num_generations=4,               # multiple rollouts per prompt\n",
        "    gradient_accumulation_steps=2,   # effective batch = 8 * 2 = 16\n",
        "    adam_beta1=0.9,\n",
        "    adam_beta2=0.99,\n",
        "    weight_decay=0.1,\n",
        "    warmup_ratio=0.1,\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    optim=\"adamw_8bit\",\n",
        "    logging_steps=1,\n",
        "    max_prompt_length=256,\n",
        "    max_completion_length=200,\n",
        "    num_train_epochs=1,  # Set to 1 for a full training run\n",
        "    save_steps=250,\n",
        "    max_grad_norm=0.1,\n",
        "    report_to=\"none\",  # Setting this value lets us use Weights and Biases\n",
        "    output_dir=\"outputs\",\n",
        "    use_vllm=True,  # vll speeds up inference! See https://github.com/vllm-project/vllm\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Quick train\n",
        "\n",
        "Let's train the model for just 5 steps (`max_steps=5`). As it runs we can double check we've set up our prompts correctly before running for a longer amount of time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 401 | Num Epochs = 1 | Total steps = 5\n",
            "O^O/ \\_/ \\    Batch size per device = 8 | Gradient accumulation steps = 2\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (8 x 2 x 1) = 16\n",
            " \"-____-\"     Trainable parameters = 59,867,136 of 3,145,805,824 (1.90% trained)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"g\" are there in the word \"glisten\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of g's in the word glisten\n",
            "1. g - 1 so far\n",
            "2. i - 1 so far\n",
            "3. n - 1 so far\n",
            "4. s - 1 so far\n",
            "5. t - 1 so far\n",
            "6. e - 1 so far\n",
            "7. l - 1 so far\n",
            "8. n - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "Unsloth: Will smartly offload gradients to save VRAM!\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5/5 01:01, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>reward</th>\n",
              "      <th>reward_std</th>\n",
              "      <th>completions / mean_length</th>\n",
              "      <th>completions / min_length</th>\n",
              "      <th>completions / max_length</th>\n",
              "      <th>completions / clipped_ratio</th>\n",
              "      <th>completions / mean_terminated_length</th>\n",
              "      <th>completions / min_terminated_length</th>\n",
              "      <th>completions / max_terminated_length</th>\n",
              "      <th>kl</th>\n",
              "      <th>rewards / numbering_reward_func / mean</th>\n",
              "      <th>rewards / numbering_reward_func / std</th>\n",
              "      <th>rewards / spelling_reward_func / mean</th>\n",
              "      <th>rewards / spelling_reward_func / std</th>\n",
              "      <th>rewards / counting_reward_func / mean</th>\n",
              "      <th>rewards / counting_reward_func / std</th>\n",
              "      <th>rewards / format_reward_func / mean</th>\n",
              "      <th>rewards / format_reward_func / std</th>\n",
              "      <th>rewards / correct_answer_reward_func / mean</th>\n",
              "      <th>rewards / correct_answer_reward_func / std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.112053</td>\n",
              "      <td>1.342044</td>\n",
              "      <td>84.937500</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>119.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>84.937500</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>119.000000</td>\n",
              "      <td>0.000022</td>\n",
              "      <td>0.953125</td>\n",
              "      <td>0.187500</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>1.627882</td>\n",
              "      <td>-0.091071</td>\n",
              "      <td>0.657844</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.341565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.180556</td>\n",
              "      <td>0.780018</td>\n",
              "      <td>78.687500</td>\n",
              "      <td>57.000000</td>\n",
              "      <td>112.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>78.687500</td>\n",
              "      <td>57.000000</td>\n",
              "      <td>112.000000</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>0.111803</td>\n",
              "      <td>-0.312500</td>\n",
              "      <td>1.887459</td>\n",
              "      <td>-0.069444</td>\n",
              "      <td>0.586284</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.652431</td>\n",
              "      <td>2.033363</td>\n",
              "      <td>89.625000</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>149.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>89.625000</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>149.000000</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>0.964286</td>\n",
              "      <td>0.110657</td>\n",
              "      <td>-0.437500</td>\n",
              "      <td>1.965324</td>\n",
              "      <td>0.625645</td>\n",
              "      <td>0.538087</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.516398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.242857</td>\n",
              "      <td>1.162084</td>\n",
              "      <td>80.687500</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>92.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>80.687500</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>92.000000</td>\n",
              "      <td>0.000046</td>\n",
              "      <td>0.958333</td>\n",
              "      <td>0.074536</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>1.857418</td>\n",
              "      <td>-0.465476</td>\n",
              "      <td>0.433347</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.341565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.398661</td>\n",
              "      <td>1.348599</td>\n",
              "      <td>77.625000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>117.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>77.625000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>117.000000</td>\n",
              "      <td>0.000078</td>\n",
              "      <td>0.905506</td>\n",
              "      <td>0.230615</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.190890</td>\n",
              "      <td>-0.006845</td>\n",
              "      <td>0.655454</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.516398</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"e\" are there in the word \"sapphire\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. s - 0 so far\n",
            "2. a - 1 so far\n",
            "3. p - 1 so far\n",
            "4. h - 1 so far\n",
            "5. a - 2 so far\n",
            "6. p - 3 so far\n",
            "7. p - 4 so far\n",
            "8. s - 4 so far\n",
            "6. e - 4 so far (The last \"e\" in the word \"sapphire\")\n",
            "</reasoning>\n",
            "<answer>\n",
            "6\n",
            "</answer>\n",
            "Extracted: 6\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"p\" are there in the word \"absolve\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of p's in the word absolve\n",
            "1. a - 0 so far\n",
            "2. b - 0 so far\n",
            "3. s - 0 so far\n",
            "4. p - 1 so far\n",
            "5. p - 1 (total so far)\n",
            "6. s - 1 so far\n",
            "7. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "Extracted: 2\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"g\" are there in the word \"mirage\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of g's in the word \"mirage\"\n",
            "1. m - 0 so far\n",
            "2. i - 1 so far\n",
            "3. r - 2 so far\n",
            "4. a - 3 so far\n",
            "5. g - 4 so far\n",
            "6. e - 4 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "4\n",
            "</answer>\n",
            "Extracted: 4\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"r\" are there in the word \"crave\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. c - 1 so far\n",
            "2. r - 1 so far\n",
            "3. a - 1 so far\n",
            "4. v - 1 so far\n",
            "5. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "time: 1min 56s (started: 2025-12-25 12:36:34 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Train for just a few steps for a few minutes\n",
        "# This will allow us to observe the results and make any changes to our reward functions\n",
        "# before starting a longer run. Note, you won't see much change in the average.\n",
        "# reward values\n",
        "# No changes are needed here\n",
        "\n",
        "from trl import GRPOConfig, GRPOTrainer\n",
        "\n",
        "# Short train to check on reward functions\n",
        "training_args = GRPOConfig(\n",
        "    **COMMON_GRPO_TRAINING_PARAMS,\n",
        "    # We'll just run for a modest 5 steps to make sure everything works and to\n",
        "    # estimate the amount of time it will take to run the full training.\n",
        "    max_steps=5,\n",
        ")\n",
        "trainer = GRPOTrainer(\n",
        "    model=model,\n",
        "    processing_class=tokenizer,\n",
        "    reward_funcs=REWARD_FUNCS,\n",
        "    args=training_args,\n",
        "    train_dataset=ds,\n",
        ")\n",
        "trainer_res = trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Matplotlib is building the font cache; this may take a moment.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "available columns: dict_keys(['loss', 'grad_norm', 'learning_rate', 'num_tokens', 'completions/mean_length', 'completions/min_length', 'completions/max_length', 'completions/clipped_ratio', 'completions/mean_terminated_length', 'completions/min_terminated_length', 'completions/max_terminated_length', 'rewards/numbering_reward_func/mean', 'rewards/numbering_reward_func/std', 'rewards/spelling_reward_func/mean', 'rewards/spelling_reward_func/std', 'rewards/counting_reward_func/mean', 'rewards/counting_reward_func/std', 'rewards/format_reward_func/mean', 'rewards/format_reward_func/std', 'rewards/correct_answer_reward_func/mean', 'rewards/correct_answer_reward_func/std', 'reward', 'reward_std', 'frac_reward_zero_std', 'completion_length', 'kl', 'epoch', 'step'])\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjYsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvq6yFwwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAWd1JREFUeJzt3XlcVPX+P/DXsO8gsu8KiooIooJYCpZGyzWprpp7ppWlpdltsduv5fa9Wbe62u2WWlZ0zbVMLbPUTHDDFSEX3BABkU1lFwaY+fz+ODAwssggcJjh9Xw8zqM4c87M53CYmZefz+e8j0IIIUBEREQkEyO5G0BERETdG8MIERERyYphhIiIiGTFMEJERESyYhghIiIiWTGMEBERkawYRoiIiEhWDCNEREQkKxO5G9AaarUaV69eha2tLRQKhdzNISIiolYQQqC0tBQeHh4wMmq+/0MvwsjVq1fh7e0tdzOIiIioDbKysuDl5dXs43oRRmxtbQFIB2NnZydza4iIiKg1SkpK4O3trfkeb45ehJG6oRk7OzuGESIiIj1zuykWnMBKREREsmIYISIiIlkxjBAREZGs9GLOCFFrCCFQU1MDlUold1OIiLoFY2NjmJiY3HHZDYYRMghVVVXIycnBzZs35W4KEVG3YmVlBXd3d5iZmbX5ORhGSO+p1Wqkp6fD2NgYHh4eMDMzY3E8IqIOJoRAVVUVCgoKkJ6ejj59+rRY2KwlDCOk96qqqqBWq+Ht7Q0rKyu5m0NE1G1YWlrC1NQUGRkZqKqqgoWFRZuehxNYyWC0NZETEVHbtcdnLz+9iYiISFYMI0RERCQrhhEiapX4+HgoFAoUFRXJ3RQiMjAMI0RERCSrbh1G9p4vwFP/O4aKKhbJoq6hqqpK7iZ0iTYQUffSbcPIzaoavLghGbvO5GH6V4dRXFEtd5OoHQkhcLOqRpZFCNHqdkZHR2P+/PlYuHAhnJycEBMTg1OnTuGBBx6AjY0NXF1dMX36dFy7dg0AsG3bNjg4OGiqzCYnJ0OhUOC1117TPOecOXMwbdo0AMD169cxefJkeHp6wsrKCsHBwVi3bt1t2wAA27dvR9++fWFpaYnRo0fj8uXLd3JKiIia1W3rjFiZmWDl9CGYFXcUxzIK8fgXh/C/J8PhbGsud9OoHVRUqzDgzR2yvPaZf8TAyqz1b61vv/0Wzz77LA4cOICioiLcc889mDNnDpYuXYqKigq8+uqrmDhxIv744w+MHDkSpaWlOHHiBIYOHYqEhAQ4OTkhPj5e83wJCQl49dVXAQCVlZUYMmQIXn31VdjZ2eGXX37B9OnT4e/vj/Dw8CbbAABZWVl49NFHMW/ePDz99NM4duwYXnrppfb5BRER3aLb9owAwFA/R2x4OhJONuZIzSnBhBUHkXWD5cSpc/Xp0wf/+te/EBgYiF27dmHw4MF477330K9fPwwePBhff/019uzZg/Pnz8Pe3h6hoaGa8BEfH48XX3wRJ06cQFlZGbKzs3Hx4kVERUUBADw9PfG3v/0NoaGh6N27N55//nncf//92LhxY7NtCAwMxPLly+Hv74+PP/4YgYGBmDp1Kp544olO/s0QUXfRbXtG6gzwsMMPcyMx7avDuHz9JiasSMTq2eHo42ord9PoDliaGuPMP2Jke21dDBkyRPP/KSkp2LNnD2xsbBptl5aWhr59+yIqKgrx8fF46aWXsG/fPixZsgQbN27E/v37cePGDXh4eKBPnz4AAJVKhffeew8bN25EdnY2qqqqoFQqG1WqbdgGAEhNTUVERITWusjISJ2Oi4iotbp9GAEAPydr/DB3BKZ/dRgX8sswcWUi4maFI8TbQe6mURspFAqdhkrkZG1trfn/srIyjBs3Dh988EGj7dzd3QFIczy+/vprpKSkwNTUFP369UN0dDTi4+NRWFio6RUBgA8//BCffPIJli1bhuDgYFhbW2PhwoWNJqk2bAMRUWfr1sM0DbnZW2DjM5EI8XZA4c1qTPnyEA6mXZO7WdTNhIWF4fTp0/Dz80NAQIDWUhcY6uaNLF26VBM86sJIfHw8oqOjNc934MABjB8/HtOmTUNISAh69+6N8+fP37Yd/fv3x5EjR7TWHTp0qP0OlIioAYaRBnpYm2HNnAiM8O+J8ioVnvjmKHaczpW7WdSNzJs3Dzdu3MDkyZNx9OhRpKWlYceOHZg1a5bmCpoePXpg0KBBWLNmjSZ4jBo1CklJSTh//rxWz0ifPn2wa9cuHDx4EKmpqXjmmWeQl5d323bMnTsXFy5cwMsvv4xz585h7dq1iIuL64hDJiJiGLmVjbkJvn5iGGKCXFFVo8az3x3HD8evyN0s6iY8PDxw4MABqFQq3HfffQgODsbChQvh4OCgdTOqqKgoqFQqTRhxdHTEgAED4ObmhsDAQM12b7zxBsLCwhATE4Po6Gi4ubkhNjb2tu3w8fHBpk2bsGXLFoSEhGDFihV477332vtwiYgAAAqhS1EEmZSUlMDe3h7FxcWws7PrlNesUanx2o8nNUHkzb8MwJN39+qU1ybdVFZWIj09Hb169Wrz7auJiKhtWvoMbu33t049I8uXL8egQYNgZ2cHOzs7REZG4tdff21xn++//x79+vWDhYUFgoODsX37dl1eUjYmxkb412ODMLs2gPxj2xn8e+c5nQpaERER0e3pFEa8vLzw/vvv4/jx4zh27BjuuecejB8/HqdPn25y+4MHD2Ly5MmYPXs2Tpw4gdjYWMTGxuLUqVPt0viOZmSkwBsP9cff7usLAPjPHxfx9k+noVYzkBAREbWXOx6mcXR0xIcffojZs2c3emzSpEkoLy/Htm3bNOuGDx+O0NBQrFixotWvIccwza1WJ17Gmz+dhhBAbKgHPpwQAlNjTrnpCjhMQ0Qkn04fpmlIpVJh/fr1KC8vb7YYUmJiIsaMGaO1LiYmBomJiS0+t1KpRElJidYit+mRflg2KRQmRgpsSb6KZ1YfR2U1b7BHRER0p3QOIydPnoSNjQ3Mzc0xd+5cbN68GQMGDGhy29zcXLi6umqtc3V1RW5uy5fLLlmyBPb29prF29tb12Z2iPGhnvhixhCYmxjhj7P5mPH1EZRU8gZ7REREd0LnMBIYGIjk5GQcPnwYzz77LGbOnIkzZ860a6MWL16M4uJizZKVldWuz38n7unnitWzI2BrboIj6Tcw+YtDuFamlLtZREREekvnMGJmZoaAgAAMGTIES5YsQUhICD755JMmt3Vzc2tUYCkvLw9ubm4tvoa5ubnmip26pSsJ7+WIdU8PR09rM5y+WoKJKxKRXVQhd7OIiIj00h3PwFSr1VAqm+4ZiIyMxO7du7XW7dq1yyBuuDXQ0x7fz42Ep4MlLl0rx1+XH8TF/DK5m0VERKR3dAojixcvxt69e3H58mWcPHkSixcvRnx8PKZOnQoAmDFjBhYvXqzZfsGCBfjtt9/w8ccf4+zZs3j77bdx7NgxzJ8/v32PQia9nW3w/dxI+DtbI6e4EhNXJuLklWK5m0VERKRXdAoj+fn5mDFjBgIDA3Hvvffi6NGj2LFjB8aOHQsAyMzMRE5Ojmb7ESNGYO3atfjiiy8QEhKCH374AVu2bMHAgQPb9yhk5OFgie/njkCwpz1ulFdh8peHcOjSdbmbRdTu4uPjoVAoUFRUJHdTiFpF17/ZLVu2ICAgAMbGxli4cGGHto206XSP9a+++qrFx+Pj4xutmzBhAiZMmKBTo/SNo7UZ1j4VgTnfHsPh9BuY8fURfD4lDGMGuN5+ZyIDlpGRgX79+qGgoAA2NjZyN6fV4uLisHDhQgavbuaZZ57BrFmz8MILL8DW1rZTX1tf3yvthVW72omthSm+fTIcY/pLN9h75rvj2HyCN9gj3VRVVcndhHZtw9atWzF69OgO+XBtrp3V1bzcvi3act67wt8r0D7tKCsrQ35+PmJiYuDh4dHpYaQj3yv6gGGkHVmYGmPFtDA8OtgTKrXAixtSEHcgXe5mdU9CAFXl8iw6FDWOjo7G/PnzsXDhQjg5OSEmJganTp3CAw88ABsbG7i6umL69Om4du0aAGDbtm1wcHCASiUV3EtOToZCocBrr72mec45c+Zg2rRpAIDr169j8uTJ8PT0hJWVFYKDg7Fu3brbtgEAtm/fjr59+8LS0hKjR4/G5cuXtfbLyMjAuHHj0KNHD1hbWyMoKKjRvae2bt2Khx9+WPPz119/jaCgIJibm8Pd3V1r/lhmZibGjx8PGxsb2NnZYeLEiVpX47399tsIDQ3FqlWrtCo9KhQKLF++HA8//DCsra3xz3/+U/PaYWFhsLCwQO/evfHOO++gpqZG83xFRUV45pln4OrqCgsLCwwcOBDbtm1DfHw8Zs2aheLiYigUCigUCrz99tu3PZerV6/G0KFDYWtrCzc3N0yZMgX5+fmax+uGDHbv3o2hQ4fCysoKI0aMwLlz5zTbpKSkYPTo0bC1tYWdnR2GDBmCY8eOQQgBZ2dn/PDDD5ptQ0ND4e7urvl5//79MDc3x82bNzXHN2fOHDg7O8POzg733HMPUlJSbvv7bElzfyv68jfbnPj4eE34uOeee6BQKBAfH6/5HTW0bNky+Pn5aX5+4oknEBsbi48++gju7u7o2bMn5s2bpxWKlUolXn31VXh7e8Pc3BwBAQGNRhoavlfqnvO9996Dq6srHBwc8I9//AM1NTV4+eWX4ejoCC8vL3zzzTdaz5GVlYWJEyfCwcEBjo6OGD9+vNbv4OjRoxg7diycnJxgb2+PqKgoJCUlaT2HQqHAqlWr8Mgjj8DKygp9+vTBTz/91Krf4x0ReqC4uFgAEMXFxXI3pVVUKrV4a+sp4fvqNuH76jaxbNd5oVar5W6WwaqoqBBnzpwRFRUV9SuVZUK8ZSfPoixrddujoqKEjY2NePnll8XZs2fFoUOHhLOzs1i8eLFITU0VSUlJYuzYsWL06NFCCCGKioqEkZGROHr0qBBCiGXLlgknJycRERGhec6AgADx5ZdfCiGEuHLlivjwww/FiRMnRFpamvjPf/4jjI2NxeHDh5ttw9mzZ0VmZqYwNzcXixYtEmfPnhXfffedcHV1FQBEYWGhEEKIhx56SIwdO1b8+eefIi0tTfz8888iISFB87yFhYXCzMxMZGdnCyGE+Pzzz4WFhYVYtmyZOHfunDhy5IhYunSpEEIIlUolQkNDxd133y2OHTsmDh06JIYMGSKioqI0z/fWW28Ja2trcf/994ukpCSRkpIihBACgHBxcRFff/21SEtLExkZGWLv3r3Czs5OxMXFibS0NLFz507h5+cn3n77bc3rDR8+XAQFBYmdO3dq2r99+3ahVCrFsmXLhJ2dncjJyRE5OTmitLT0tufyq6++Etu3bxdpaWkiMTFRREZGigceeEDz+J49ewQAERERIeLj48Xp06fFyJEjxYgRIzTbBAUFiWnTponU1FRx/vx5sXHjRpGcnCyEEOLRRx8V8+bNE0IIcePGDWFmZibs7e1FamqqEEKI//u//xN33XWX5rnGjBkjxo0bJ44ePSrOnz8vXnrpJdGzZ09x/fr1Fn+fLWnqb6WwsFBv/mabo1Qqxblz5wQAsWnTJpGTkyOUSqV46623REhIiNa2S5cuFb6+vpqfZ86cKezs7MTcuXNFamqq+Pnnn4WVlZX44osvNNtMnDhReHt7ix9//FGkpaWJ33//Xaxfv17z+K3vlZkzZwpbW1sxb948cfbsWfHVV18JACImJkb885//FOfPnxfvvvuuMDU1FVlZWUIIIaqqqkT//v3Fk08+Kf78809x5swZMWXKFBEYGCiUSqUQQojdu3eL1atXi9TUVHHmzBkxe/Zs4erqKkpKSjRtASC8vLzE2rVrxYULF8QLL7wgbGxsNH83TWnyM7hWa7+/GUY6iFqtFst2ndcEkre2nhIqFQNJR9D3MDJ48GDNz++++6647777tLbJysoSAMS5c+eEEEKEhYWJDz/8UAghRGxsrPjnP/8pzMzMRGlpqbhy5YoAIM6fP9/saz700EPipZdearYNQgixePFiMWDAAK11r776qtYHe3BwsObLvSlr1qwRQ4cO1fzs4eEh/v73vze57c6dO4WxsbHIzMzUrDt9+rQAII4cOSKEkL48TU1NRX5+vta+AMTChQu11t17773ivffe01q3evVq4e7uLoQQYseOHcLIyEjzO73VN998I+zt7Zs9ttY4evSoAKAJMnVh5Pfff9ds88svvwgAmr9dW1tbERcX1+Tz/ec//xFBQUFCCCG2bNkiIiIixPjx48Xy5cuFEFL4eP3114UQQuzbt0/Y2dmJyspKrefw9/cXK1euFEI0//tsSVN/K/r0N9uSwsJCAUDs2bNHs661YcTX11fU1NRo1k2YMEFMmjRJCCE0IWfXrl3Nvvat75W651SpVJp1gYGBYuTIkZqfa2pqhLW1tVi3bp0QQvr7DgwM1PqHr1KpFJaWlmLHjh1Nvq5KpRK2trbi559/1qwDIN544w3Nz2VlZQKA+PXXX5ttf3uEEZ0msFLrKRQKLBjTB/aWJnj75zOIO3gZJZXV+Ndjg2DCG+x1PFMr4PWr8r22DoYMGaL5/5SUFOzZs6fJceO0tDT07dsXUVFRiI+Px0svvYR9+/ZhyZIl2LhxI/bv348bN27Aw8MDffr0ASDdQ+q9997Dxo0bkZ2djaqqKiiVSlhZabexYRsAIDU1FREREVrrbq0P9MILL+DZZ5/Fzp07MWbMGDz22GMYNGiQ5vGG3c75+fm4evUq7r333iZ/B6mpqfD29ta69cOAAQPg4OCA1NRUDBs2DADg6+sLZ2fnRvsPHTpU6+eUlBQcOHBAM2RT97uorKzEzZs3kZycDC8vL/Tt27fJ9rTF8ePH8fbbbyMlJQWFhYVQq9UApOGnhrfMaPg7qhtmyc/Ph4+PDxYtWoQ5c+Zg9erVGDNmDCZMmAB/f38AQFRUFBYsWICCggIkJCQgOjoabm5uiI+Px+zZs3Hw4EG88sormuMvKytDz549tdpYUVGBtLQ0zc/N/T5bcuvfij79zXaUoKAgGBsba352d3fHyZMnAUjDUsbGxoiKimp2/1uHM+ue08io/rvC1dVV60pUY2Nj9OzZUzMUmJKSgosXLzaa61JZWak553l5eXjjjTcQHx+P/Px8qFQq3Lx5E5mZmVr7NPwbtba2hp2dndaQY0dgGOlgT9zVC/ZWpvjb93/ix6RslFTU4L9TBsPC1Pj2O1PbKRSAmbXcrWgVa+v6dpaVlWHcuHH44IMPGm1X98UVHR2Nr7/+GikpKTA1NUW/fv0QHR2N+Ph4FBYWan3offjhh/jkk0+wbNkyBAcHw9raGgsXLmw04a9hG1przpw5iImJwS+//IKdO3diyZIl+Pjjj/H888+jqqoKv/32G15//XUAgKWlpc7P35Tm2nnr+rKyMrzzzjt49NFHG21rYWHRbu2pU15ejpiYGMTExGDNmjVwdnZGZmYmYmJiGv2uTU1NNf+vUCgAQBNc3n77bUyZMgW//PILfv31V7z11ltYv349HnnkEQQHB8PR0REJCQlISEjAP//5T7i5ueGDDz7A0aNHUV1djREjRmiO393dvckrHB0cHDT/35bz3tTvWl/+ZnVlZGQEccscsKYmSDc8p4B0XuvO6e3+1m59r7T0nC29TllZGYYMGYI1a9Y0eo26wDlz5kxcv34dn3zyCXx9fWFubo7IyMgW/0ZvfZ2OwjDSCR4Z7AVbc1M8tzYJv6fmYdY3R/HFjCGwtTC9/c7UrYSFhWHTpk3w8/ODiUnTb8+RI0eitLQUS5cu1XyIR0dH4/3330dhYSFeeuklzbYHDhzA+PHjNZMD1Wo1zp8/3+zNLev079+/0aS1Q4cONdrO29sbc+fOxdy5c7F48WJ8+eWXeP755xEfH48ePXogJCQEAGBraws/Pz/s3r0bo0ePbvL1srKykJWVpekdOXPmDIqKim7b1qaEhYXh3LlzCAgIaPLxQYMG4cqVKzh//nyTvSNmZmaaCZetcfbsWVy/fh3vv/++pv3Hjh3Tud0A0LdvX/Tt2xcvvvgiJk+ejG+++QaPPPIIFAoFRo4cia1bt+L06dO4++67YWVlBaVSiZUrV2Lo0KGaL+iwsDDk5ubCxMREa7JlR9C3v1ldODs7Izc3F0IITXBMTk7W6TmCg4OhVquRkJDQ6C72ABq9V9oqLCwMGzZsgIuLS7O3UDlw4AA+//xzPPjggwCkCa91E43lxvGCTjJmgCu+nRUOG3MTJF66jqmrDuNGede4LI66jnnz5uHGjRuYPHkyjh49irS0NOzYsQOzZs3SfDn26NEDgwYNwpo1axAdHQ0AGDVqFJKSknD+/Hmtf2X26dMHu3btwsGDB5Gamopnnnmm0f2imjJ37lxcuHABL7/8Ms6dO4e1a9ciLi5Oa5uFCxdix44dSE9PR1JSEvbs2YP+/fsDAH766adG3c5vv/02Pv74Y/znP//BhQsXkJSUhE8//RQAMGbMGAQHB2Pq1KlISkrCkSNHMGPGDERFRTUagmmNN998E//73//wzjvv4PTp00hNTcX69evxxhtvAJCGPEaNGoXHHnsMu3btQnp6On799Vf89ttvAAA/Pz+UlZVh9+7duHbtmuYKleb4+PjAzMwMn376KS5duoSffvoJ7777rk5trqiowPz58xEfH4+MjAwcOHAAR48e1fxOAekLfN26dQgNDYWNjQ2MjIwwatQorFmzRuu8jxkzBpGRkYiNjcXOnTtx+fJlHDx4EH//+9/bHJKao09/s7qKjo5GQUEB/vWvfyEtLQ2fffYZfv31V52ew8/PDzNnzsSTTz6JLVu2ID09HfHx8di4cSOApt8rbTF16lQ4OTlh/Pjx2Ldvn+Z1XnjhBVy5IpWZ6NOnD1avXo3U1FQcPnwYU6dObfdewrZiGOlEkf49se6p4XC0NsOfV4oxYcVBXOUN9qgBDw8PHDhwACqVCvfddx+Cg4OxcOFCODg4aI0fR0VFQaVSaT7YHR0dMWDAALi5uSEwMFCz3RtvvIGwsDDExMRo5hjExsbeth0+Pj7YtGkTtmzZgpCQEKxYsQLvvfee1jYqlQrz5s1D//79cf/996Nv3774/PPPATT9ATtz5kwsW7YMn3/+OYKCgvCXv/wFFy5cACB1A2/duhU9evTAqFGjMGbMGPTu3RsbNmxoy68RMTEx2LZtG3bu3Ilhw4Zh+PDhWLp0KXx9fTXbbNq0CcOGDcPkyZMxYMAAvPLKK5ovzxEjRmDu3LmYNGkSnJ2d8a9//avF13N2dkZcXBy+//57DBgwAO+//z4++ugjndpsbGyM69evY8aMGejbty8mTpyIBx54AO+8845mm1vPOyB9Yd66TqFQYPv27Rg1ahRmzZqFvn374vHHH0dGRgZcXdu3GKM+/c3qqn///vj888/x2WefISQkBEeOHMHf/vY3nZ9n+fLl+Otf/4rnnnsO/fr1w1NPPYXy8nIA7RdGrKyssHfvXvj4+ODRRx9F//79MXv2bFRWVmp6Sr766isUFhYiLCwM06dPxwsvvAAXF5c7fu32oBC3Doh1QSUlJbC3t0dxcXGXu4NvW1zML8P0rw4jp7gSng6WWD07HL2du2ehm/ZQWVmJ9PT0VtdKoI6VlJSEe+65BwUFBY3GnomonqG8V1r6DG7t9zd7RmQQ4GKDH54dgd5O1sguqsDElYk4fZU32CPDUFNTg08//VSvP1yJOgPfK/UYRmTi6WCJjXMjEeRhh2tlVXh85SEcSb8hd7OI7lh4eDimT58udzPa1b59+2BjY9PsYggyMzNbPMZbL//UN3UVYpta7nQ4p60M8b3SVryaRkZONuZY9/RwzIk7hiOXb2D6V4exYtoQjO7XNcbwiEgydOhQna+i0DceHh4tHqOHh0fnNaYDrFq1ChUVTc/Rc3R07OTW0K0YRmRmZ2GK/80Ox3NrkvDH2Xw89b9j+HhiCMaHesrdNCKqZWlp2exlwobCxMTEoI/R05OfqV0Zh2m6AAtTY6ycPgTjQz1QoxZYuCEZqw9lyN0svaMHc7GJiAxOe3z2Mox0EabGRlg6MRQzIn0hBPD/tpzCf/+4wC/YVqib/HW7WhBERNT+6j5772QiLodpuhAjIwXeeTgIDpam+M8fF/HRzvMoulmNvz/UX1P9jxozNjaGg4OD5t4JVlZW/H0REXUwIQRu3ryJ/Px8ODg4aN2fR1cMI12MQqHAovsCYW9lhne3ncGq/ekorqjGkkeDeYO9Fri5uQFAh9/MiYiItDk4OGg+g9uKYaSLmn13L9hZmODVTX/i++NXUFJZjU8e5w32mqNQKODu7g4XF5cmb2RFRETtz9TU9I56ROowjHRhE4Z6w87SFM+vPYEdp/Mw+9ujWDl9KGzMedqaY2xs3C5vDCIi6jzs9+/iYoLcEDdrGKzNjHHgonSDvULeYI+IiAwIw4geGBHghLVPDUcPK1OkZBVh4spE5BZXyt0sIiKidsEwoidCvB2w8ZlIuNlZ4EJ+Gf664iAuXyuXu1lERER3jGFEj/RxtcX3cyPh19MKVwor8NcViUjNKZG7WURERHeEYUTPeDta4fu5I9Df3Q7XypSYtDIRxzN4gz0iItJfDCN6yNnWHOufHo6hvj1QUlmDqasOI/4c62sQEZF+YhjRU/aWplg9OwLRgc6orFbjqf8dw88pV+VuFhERkc4YRvSYpZkxvpg+FH8Z5I5qlcAL609g7eFMuZtFRESkE4YRPWdmYoRPHh+MqRE+EAJ4ffNJLI9Pk7tZRERErcYwYgCMjRT4v9iBmDfaHwDwwW9nseTXVN7xl4iI9ALDiIFQKBR4OaYfXn+wHwBgZcIlLP7xJFRqBhIiIuraeJMTA/P0KH/YW5pi8Y8nsf5oFkoqq7F0UijMTXi/FupaKqtV2JR0BVtPXIWXoyWmRvgizMcBCoVC7qYRUSdTCD3oyy8pKYG9vT2Ki4thZ2cnd3P0wq8nc7BgfTKqVGqM7OOEldOHwMqM2ZPkV1pZjTWHM/HV/nQUlCq1HuvvboepET6IHezJG0ISGYDWfn8zjBiw/Reu4enVx3CzSoUwHwd8/cQwOFiZyd0s6qaulSnxzYF0/C8xA6WVNQAAd3sLzBzhh4v5Zfg55SqUNWoAgLWZMWIHe2LacF/0d+d7nkhfMYwQAOBEZiGe+OYoiiuqEehqi9Wzw+FiZyF3s6gbybpxE1/uu4QNR7M0YcPf2Rpzo/wxPtQTZibS1LWim1X44fgVrD2ciUsN7rs0xLcHpg33wQMD3WFhyuFGIn3CMEIa53JLMf2rw8gvVcLH0QrfzY6AT08ruZtFBu5cbilWJKThp5SrmonUIV72eDY6APcNcIWRUdNzQ4QQSEy7ju8OZ2Dn6TzU1O7bw8oUE4Z6Y0q4D/ycrDvtOIio7RhGSEvm9ZuY9tVhZN64CRdbc6yeHYFAN1u5m0UG6HhGIZbHX8TvqfW3KLg7wAnPRfsj0r+nThNU80sqseFoFtYdycTV4krN+pF9nDA1whdj+rvAxJgXBRJ1VQwj1Eh+SSVmfH0EZ3NLYW9pim9mDUOYTw+5m0UGQAiBhPMF+Dw+DUfSpRs3KhTA/UFueDbaH4O8HO7o+VVqgT1n8/Hd4QwknC9A3aeWq505Hh/mg8fDveFub3mHR0FE7Y1hhJpUfLMas+KOICmzCFZmxlg5fQhG9nGWu1mkp1Rqge0nc7A8Pg1nckoAAKbGCjw62AtPR/WGv7NNu79m1o2bWHskExuPZuF6eRUAqfDfvf1cMG24L+4OcGp2CIiIOhfDCDXrZlUNnll9HPsuXIOpsQL/eXwwHgh2l7tZpEeUNSpsOp6NlXvTkHH9JgDAyswYk8N9MGdkr07ppVDWqLDjdB6+O5Sh6Y0BAN+eVpgS7oMJQ73haM2rx4jkxDBCLVLWqLBoQwp+OZkDIwWw5NFgTBrmI3ezqIsrrazG2toaIfm1NUIcrEzxxAg/zIz0Qw+ZvvzP55Vi7eFMbDp+BaVK6bJhM2MjPBjshmnDfTHEtweLqRHJgGGEbkulFvj7ZqlSKwC8/mA/PD3KX+ZWUVd0vUyJbw5cxv8SL6OkQY2QOSN7Y3K4d5cpqHezqgY/p1zFd4cycTK7WLO+n5utppiarYWpjC0k6l4YRqhVhBB4/7ezWJlwCQDwXLQ/Xo4J5L8iCQBwpfAmvtx7CRuOZaGyWqoR0ru2RkhsgxohXVFKVhHWHM7ATylXNW23MjPG+FBPTBvugyAPe5lbSGT4GEZIJ8vj0/DBb2cBAFMifPDu+IEw5iTAbut8XilWxKdha4MaIYO87PFctD/GDnDTq7+N4pvV+PHEFXx3KANpBfXF1Ab7OGBqhC/+MojF1Ig6CsMI6WzdkUy8vvkkhAD+Msgd/54Y2qX/5UvtLymzEJ/vScPvqXmadXcF9MRz0QEYoWONkK5GCIFDl25gzeEM7Didi2qV9NFnb2mKvw7xwtQIH/TugKt/iLqzDgkjS5YswY8//oizZ8/C0tISI0aMwAcffIDAwMBm94mLi8OsWbO01pmbm6OysrKZPRpjGOk82/68ihc3JKNaJRDV1xkrpg2BpRn/1WjIhBDYe+EalsdfxKFL9TVCYgZINUJCvB3kbWAHKChVYuOxLKw9nInsogrN+rsCemJqhC/GDnCFKYupEd2xDgkj999/Px5//HEMGzYMNTU1eP3113Hq1CmcOXMG1tZNl2eOi4vDggULcO7cufoXVSjg6ura7gdD7SPhfAHmrj6OimoVhvr2wFdPDIO9JSf9GRqVWuDXU1KNkNNXpRohJkYKPDLYE89E+SPAxfB7CVRqgYTz+VhzKBN/nMvXFFNzsTXH48O88Xi4DzwcWEyNqK06ZZimoKAALi4uSEhIwKhRo5rcJi4uDgsXLkRRUVFbX4ZhRAbHM25g1jdHUVJZg/7udvj2yWFwseUN9gyBskaFH5OysTIhDZdra4RYmtbXCOmuX75XCm9i3ZFMbDiahWtlUjE1IwVwTz9XTBvug1F9nFlMjUhHrf3+vqPr8YqLpUvnHB0dW9yurKwMvr6+UKvVCAsLw3vvvYegoKBmt1cqlVAqlZqfS0pK7qSZ1AZDfB2x4ZlITP/qCFJzSjBxRSJWz46AtyNvsKevypQ1WHs4A6v2adcImRnphydGyFcjpKvw6mGFl2P6YcG9fbHzTC6+O5SBQ5du4PfUPPyemgdvR0tMCffFhKFecLIxl7u5RAalzT0jarUaDz/8MIqKirB///5mt0tMTMSFCxcwaNAgFBcX46OPPsLevXtx+vRpeHl5NbnP22+/jXfeeafRevaMdL7L18ox7avDuFJYAVc7c3w3OwJ9XHmDPX1yvUyJuIOX8e3B+hohbnYWmDOyFyaH+8DavGvUCOmKLuaXYc3hDGw6fkXzuzM1VuCBge6YNtwXw/xYTI2oJR0+TPPss8/i119/xf79+5sNFU2prq5G//79MXnyZLz77rtNbtNUz4i3tzfDiExyiysx4+vDOJ9XBgcrU8TNCkeoAU5qNDTZRRX4cu8lrD+aWV8jxEmqETJ+sAfMTTgxubUqqlT4+c+rWHMoAylX6oup9XW1wdQIXzwS5gk7FlMjaqRDw8j8+fOxdetW7N27F7169dK5cRMmTICJiQnWrVvXqu05Z0R+heVVeCLuKFKyimBtZowvZwzFiAAnuZtFTbiQV4oVCZewNTkbNbU1QoI9pRoh9wXpV42QrujklWKsOZyBrclXUVGtAiDNuRkf6oFpw30x0JPF1IjqdEgYEULg+eefx+bNmxEfH48+ffro3DCVSoWgoCA8+OCD+Pe//92qfRhGuoZyZQ2eXn0MBy5eh5mxET6dMhgxQW5yN4tqncgsxPL4NOw8U18jZIS/VCPkrgD9rhHSFZVUVmNzUja+O5SBC/llmvUhXvaYOtwX4wZ58LJ46vY6JIw899xzWLt2LbZu3apVW8Te3h6WltIM/BkzZsDT0xNLliwBAPzjH//A8OHDERAQgKKiInz44YfYsmULjh8/jgEDBrTrwVDHU9aosGBdMn47nQsjBfDBY4MwYai33M3qtoQQ2HfhGpbHpyHx0nXN+pggVzwbHcDhtE4ghMCR9BtYczgTv57K0RRTs7MwwWNDvDA1wrdbXCZN1JQOCSPN/cvqm2++wRNPPAEAiI6Ohp+fH+Li4gAAL774In788Ufk5uaiR48eGDJkCP7v//4PgwcPbveDoc5Ro1Jj8Y8n8f3xKwCA//eXAZh9t+7DddR2KrXAjtO5WB6fprkhnImRArGDPTE3qjcCXDjJWA7XypT4/tgVrD2Sgawb9cXUhvd2xLThvrhvgBurGlO3wnLw1KGEEHhveyq+3JcOAHj+ngAsGtuXQwEdTFmjwuakbKzcewnp16T7rFiaGuPxcG88NbJ3t60R0tWo1QIJFwqkYmpn81A7dQdONuaYNMwLk8N94NWDl8mT4WMYoQ4nhMDn8Wn4cIdUXXdGpC/eHhfEwlAdoFxZg3VHMvHlvkvIK5GuNLO3NMXMEVKNEMduXiOkK8suqsCGI5lYdzQLBbX1XYwUwOhAF0wd7oOovi6cVEwGi2GEOs3qQxl4c+spCAGMD/XARxNCeF+PdnKjvEpTI6S4ohoA4GpnjqdG9sbj4T6wYY0QvVGtUmPXmTysOZyBAxfr5/d4OlhiSoQPJg71hrMti6mRYWEYoU71U8pVLNqQjBq1wD39XPDZlDBeSXAHsosqsGrfJaw/kqW5fLSXkzXmRvVG7GBP1gjRc2kFZVh7OBM/HL+iCZmmxgrEBLlhaoQvhvd25JAnGQSGEep0e87mY+53x6GsUSPczxGrnhjKQlA6upgv1QjZcqK+RshATzs8Fx2AGNYIMTiV1Sps+zMHaw5n4ERmkWZ9gIsNpkb44NEwL96kkjpU0c0qpBWUIS2/HONC2v9ydIYRksXRyzfwZNxRlFbWIMjDDt8+Gc77eLRCSlYRPo+/iJ1n8jR3jo3s3RPPjfbH3QFO/FdyN3AquxhrDmdia3I2blZJvWEWpkZ4OEQqpjbIy0HeBpLeqlGpcaWwApeuSaEjraCsdinHjfIqzXbbnr+73Yv2MYyQbE5fLcbMr4/gWlkVejtZY/WcCHjyKo9GhBA4cPE6Po+/iINp9XMI7hvgimej/THYp4eMrSO5lFZWY8uJbHx3KBPn8ko164M97TFtuA/GhXjAyoxzhaix0spqXCqQwkbdf9MKynD52k1UqdTN7udhbwF/Fxu8HBPY7qGXYYRklX6tHNNWHUZ2UQXc7S2wenYECz/VUqkFdp7Oxee31AgZH+qJZ6NZI4QkQggczyjEd4cysP1krubLxNbCBI+FeWFqhA9vWtkNqdUCOSWVSMsv04SNuuBRd6VdU8xNjNDLyRr+Ljbwd7aBv7M1/J1t0NvZukPDLcMIyS6nuALTvzqCi/llcLQ2w7ezwhHs1X3v21FVo8aWE9lYsTcNlwqkGiEWpkZ4fJgP5ozsxboT1KzrZUr8cPwK1hzOROaNm5r14b2kYmr3B7GYmqGpqFIh/Zr2kEpafhnSr5VrJrU3xdnWHP7O1ujtrB06PB0sZSm7wDBCXcKN8io88c0R/HmlGDbmJvhyxlBE+veUu1mdqq5GyKp96cgtqQQglQp/YoQfZo7wQ0/OqaFWUqsF9l+8hu8OZeD31IbF1MwwYag3poT7wNuRoVZfCCFQUKrERa1hFSl0ZBdVNLufqbECvj2tG/Ru2GgCSFeb8MwwQl1GmbIGT317DImXrsPMxAifTQnD2AGucjerwxXW1QhJvIyim9Llmy62Uo2QyRGsEUJ3Jqe4AuuPZGH90UxN97xCAUT1dca0CF+M7sdial1FVY0aGdcbhI3a/17KL0OpsqbZ/RysTLV6N+qGVbwdrfSmlhPDCHUpldUqPL/uBHadyYOxkQIf/nUQHg3zkrtZHSKnuAJf7k3HuiOZmu5Uv55WmBvlj0fCWCOE2le1So3dqXlYczgT+y5c06z3sLfA5HAfTAr3houthYwt7D4Ky6saDatculaOzBs3oVI3/VVrpAB8HK00QcPf2UYzr8MQKiszjFCXU6NS49VNJ7EpSbrB3lvjBmDWXYZzg720gjKsiE/DluRszZ1bgzykGiH3D2SNEOp46dfKse5IJjYey9L0xpkYKXBfkCumRfgi0r8nLxO/QzUqNbIKK3CpLnQ0uFS2sPZ33hQbc5P6Hg4XG/SunUzq29PKoP+BwjBCXZJaLfDuL2fwzYHLAICFY/pgwb199PoD8s8rRVgen4bfTudqaoQM7+2IZ6MDMKoPa4RQ56usVmH7yRysOZyJ4xmFmvW9na0xNcIXfw3zgr1V15pb0NWU1F0mm1+mVZ/j8vVyzT82muLpYHlLD4f0/y625t3ys4BhhLosIQQ+/eMi/r3rPADgiRF+ePMvA/TqBntCCBxMk2qENLzPyNjaGiFhrBFCXcSZqyVYczgDW05ko7y2mJq5iRHGhXhgaoQPQr0duuWXJCD94+hqcYVmSKXhZbL5pc1fJmthaoTeTrcOq1ijl1PHXiarjxhGqMv79uBlvPXTaQDAo4M98cFfB3X5SVlqtcDOM7lYHp+GlCtSjRBjIwXGh3pgbpQ/+rLuA3VRZcqa2mJqGTibW19MLcjDDtOG++LhEA9YG+ik6ooqldS70SB0pBWUI/1aGSqrmy8G5mJrXhs2rNHbqT50eNjLc5msPmIYIb2w5UQ2Xvo+BSq1wJj+rvjvlMGwMO1646dVNWpsSc7GigTWCCH9JoRAUmYR1hzKwLaTOaiqqS2mZm6CR8I8MTXCF4Fu+heqhRDIL1VKYeOadk/H7S6T9etprQkddZfK9na25r212gHDCOmN38/kYd7aJChr1Bje2xFfzhgK2y7yIXCzqgbrjmRh1b5LyCmurxEyI9IPT9zlx/vukF4rLK+qLaaWgcvX64upDfPrIRVTG+jW5SZXKmtUyLh+s9GwSlpBOcpauEzW0dpMqsXhVB86/J1t4NXDEiZdvEdWnzGMkF45dOk65nx7DGXKGgR72iNu1jBZi4EV3ZRqhMQd1K4RMmdkL0wO9+kyYYmoPajV0hyo7w5lYFdqnuYyVEdrM0wY6oWp4b7w6dm5vX836i6TbTCscqmgDJk3bqKZq2RhbKSovUzWWutS2d4GcpmsPmIYIb1zKlu6wd718ir4O1tj9ewIeHTyDfZyiivw1b50rD2Sqblzql9PKzwT5Y9HBnt2ySEkovaUW1yJDUezsO5IpqZiMACM6uuMaRE+uKefS7v1JNSo1Mi8cVMTNBoWBStq4TJZW3MT9HbRLgbm72wNHwO/TFYfMYyQXkorKMP0VYdxtbgSHvYW+G5OBHo7d/wN9tIKyvBFwiX8eOKK5rK9Ae52eDbaHw8Gu7NGCHU7NSo1/jibj+8OZ2Lv+QLNend7Czw+zAePh3vD1a51xdSKK6prw0bdHWWl/89o4TJZhaLuMtlbQoeLNZxtuudlsvqIYYT0VnZRBaavOoxL18rR09oM3z4ZjoGeHXODvZNXivF5/EWtGiERvRzxbLQ/ovo68wOPCEDG9XKsPZKJ749dwY3yKgDSkMjY/q6YNtwXI2rvN5VdVKHVu1EXOgpauEzW0tS4wXBKfejo5WQNSzP2cug7hhHSa9fKlHjimyM4lV0CW3MTfPXEMIT3cmyX5xZCIDHtOpYnpGmVzx7TX6oRMsSXNUKImqKsUeG3U7n47lAGjl6uL6bmbGuOkopqKGuav0zW1c5ca0ild219Dnc7C14ma8AYRkjvlVZWY/a3x3Ak/QbMTYywfFoY7unX9hvsSTVC8rA8IQ0pWUUAamuEhHjgmSh/vbyckUguZ3NLsPZwJn5MytZcxWJmbIReTtYNioFZa3o5OOm7e2IYIYNQWa3CvDVJ2H02HyZGCnw8MQTjQz11eo5qlRpbTkg1QtJqa4SYmxhh0jBvPDWyN2+5TnQHypU1OJldDHd7C3j1sOL8KtLCMEIGo1qlxis//InNJ7KhUAD/eDgI0yP9brvfzaoabDiahS/3XsLV2hohthYmmMkaIUREnaK139+GWfuXDIqpsRE+nhACOwsTfJuYgf+39TSKblZj/j0BTU4wLbpZhf8lZuCbA+mau2g625pj9t29MDWCNUKIiLoahhHSC0ZGCrz9cBDsrczwn90X8PGu8yiqqMbfH+yvmfyWW1yJr/ZfwtrDmZobgvk4WuGZqN54LMyLNUKIiLoohhHSGwqFAovG9oWDpSn+se0MvtqfjuKKasyN6o1V+9LxY1I2qlTSbP7+dTVCBrqx1DMRURfHOSOklzYdv4JXNv2pKVtdJ9zPEc+O9kc0a4QQEcmOc0bIoD02xAu2FiaYv+4EqmrUuLefC56N9sdQv/apRUJERJ2HYYT01n1Bbvj9xSiohEAvJ2u5m0NERG3EMEJ6rbPvJEpERO2PM/uIiIhIVgwjREREJCuGESIiIpIVwwgRERHJimGEiIiIZMUwQkRERLJiGCEiIiJZMYwQERGRrBhGiIiISFYMI0RERCQrhhEiIiKSFcMIERERyYphhIiIiGSlUxhZsmQJhg0bBltbW7i4uCA2Nhbnzp277X7ff/89+vXrBwsLCwQHB2P79u1tbjAREREZFp3CSEJCAubNm4dDhw5h165dqK6uxn333Yfy8vJm9zl48CAmT56M2bNn48SJE4iNjUVsbCxOnTp1x40nIiIi/acQQoi27lxQUAAXFxckJCRg1KhRTW4zadIklJeXY9u2bZp1w4cPR2hoKFasWNGq1ykpKYG9vT2Ki4thZ2fX1uYSERFRJ2rt9/cdzRkpLi4GADg6Oja7TWJiIsaMGaO1LiYmBomJiXfy0kRERGQgTNq6o1qtxsKFC3HXXXdh4MCBzW6Xm5sLV1dXrXWurq7Izc1tdh+lUgmlUqn5uaSkpK3NJCIioi6uzT0j8+bNw6lTp7B+/fr2bA8AaaKsvb29ZvH29m731yAiIqKuoU1hZP78+di2bRv27NkDLy+vFrd1c3NDXl6e1rq8vDy4ubk1u8/ixYtRXFysWbKystrSTCIiItIDOoURIQTmz5+PzZs3448//kCvXr1uu09kZCR2796ttW7Xrl2IjIxsdh9zc3PY2dlpLURERGSYdJozMm/ePKxduxZbt26Fra2tZt6Hvb09LC0tAQAzZsyAp6cnlixZAgBYsGABoqKi8PHHH+Ohhx7C+vXrcezYMXzxxRftfChERESkj3TqGVm+fDmKi4sRHR0Nd3d3zbJhwwbNNpmZmcjJydH8PGLECKxduxZffPEFQkJC8MMPP2DLli0tTnolIiKi7uOO6ox0FtYZISIi0j+dUmeEiIiI6E4xjBAREZGsGEaIiIhIVgwjREREJCuGESIiIpIVwwgRERHJimGEiIiIZMUwQkRERLJiGCEiIiJZMYwQERGRrBhGiIiISFYMI0RERCQrhhEiIiKSFcMIERERyYphhIiIiGTFMEJERESyYhghIiIiWTGMEBERkawYRoiIiEhWDCNEREQkK4YRIiIikhXDCBEREcmKYYSIiIhkxTBCREREsmIYISIiIlkxjBAREZGsGEaIiIhIVgwjREREJCuGESIiIpIVwwgRERHJimGEiIiIZMUwQkRERLJiGCEiIiJZMYwQERGRrBhGiIiISFYMI0RERCQrhhEiIiKSFcMIERERyYphhIiIiGTFMEJERESyYhghIiIiWTGMEBERkawYRoiIiEhWDCNEREQkK4YRIiIikhXDCBEREclK5zCyd+9ejBs3Dh4eHlAoFNiyZUuL28fHx0OhUDRacnNz29pmIiIiMiA6h5Hy8nKEhITgs88+02m/c+fOIScnR7O4uLjo+tJERERkgEx03eGBBx7AAw88oPMLubi4wMHBQef9iIiIyLB12pyR0NBQuLu7Y+zYsThw4ECL2yqVSpSUlGgtREREZJg6PIy4u7tjxYoV2LRpEzZt2gRvb29ER0cjKSmp2X2WLFkCe3t7zeLt7d3RzSQiIiKZKIQQos07KxTYvHkzYmNjddovKioKPj4+WL16dZOPK5VKKJVKzc8lJSXw9vZGcXEx7Ozs2tpcIiIi6kQlJSWwt7e/7fe3znNG2kN4eDj279/f7OPm5uYwNzfvxBYRERGRXGSpM5KcnAx3d3c5XpqIiIi6GJ17RsrKynDx4kXNz+np6UhOToajoyN8fHywePFiZGdn43//+x8AYNmyZejVqxeCgoJQWVmJVatW4Y8//sDOnTvb7yiIiIhIb+kcRo4dO4bRo0drfl60aBEAYObMmYiLi0NOTg4yMzM1j1dVVeGll15CdnY2rKysMGjQIPz+++9az0FERETd1x1NYO0srZ0AQ0RERF1Ha7+/eW8aIiIikhXDCBEREcmKYYSIiIhkxTBCREREsmIYISIiIlkxjBAREZGsGEaIiIhIVgwjREREJCuGESIiIpIVwwgRERHJimGEiIiIZMUwQkRERLJiGCEiIiJZMYwQERGRrBhGiIiISFYMI0RERCQrhhEiIiKSFcMIERERyYphhIiIiGTFMEJERESyYhghIiIiWTGMEBERkawYRoiIiEhWDCNEREQkK4YRIiIikhXDCBEREcmKYYSIiIhkxTBCREREsmIYISIiIlkxjBAREZGsGEaIiIhIVgwjREREJCuGESIiIpIVwwgRERHJimGEiIiIZMUwQkRERLJiGCEiIiJZMYwQERGRrBhGiIiISFYMI0RERCQrhhEiIiKSFcMIERERyYphhIiIiGTFMEJERESyYhghIiIiWekcRvbu3Ytx48bBw8MDCoUCW7Zsue0+8fHxCAsLg7m5OQICAhAXF9eGphIREZEh0jmMlJeXIyQkBJ999lmrtk9PT8dDDz2E0aNHIzk5GQsXLsScOXOwY8cOnRtLREREhsdE1x0eeOABPPDAA63efsWKFejVqxc+/vhjAED//v2xf/9+LF26FDExMbq+PBERERmYDp8zkpiYiDFjxmiti4mJQWJiYrP7KJVKlJSUaC1ERERkmDo8jOTm5sLV1VVrnaurK0pKSlBRUdHkPkuWLIG9vb1m8fb27uhmEhERkUy65NU0ixcvRnFxsWbJysqSu0lERETUQXSeM6IrNzc35OXlaa3Ly8uDnZ0dLC0tm9zH3Nwc5ubmHd00IiIi6gI6vGckMjISu3fv1lq3a9cuREZGdvRLExERkR7QOYyUlZUhOTkZycnJAKRLd5OTk5GZmQlAGmKZMWOGZvu5c+fi0qVLeOWVV3D27Fl8/vnn2LhxI1588cX2OQIiIiLSazqHkWPHjmHw4MEYPHgwAGDRokUYPHgw3nzzTQBATk6OJpgAQK9evfDLL79g165dCAkJwccff4xVq1bxsl4iIiICACiEEELuRtxOSUkJ7O3tUVxcDDs7O7mbQ0RERK3Q2u/vLnk1DREREXUfDCNEREQkK4YRIiIikhXDCBEREcmKYYSIiIhk1b3DiLIM6PoXExERERm0Di8H36X99DyQcQDwu7t2GQn0DAAUCrlbRkRE1G107zCSfQwoywNObZIWALB20Q4nTn0YToiIiDpQ9y56Vl0JZB8HLu8HLu8Dso4AKqX2NgwnREREbdLa7+/uHUZu1TCcZOyXwklNpfY21i6A310NwklfhhMiIqImMIy0hxpl456TRuHEWQomvndJ4cQ5kOGEiIgIDCMdQyuc7AeyDjcdTnwb9JwwnBARUTfFMNIZapRAdtItPScV2ttYOTWYc3I34NyP4YSIiLoFhhE51FQBV5OkYHJ5P5B5uJlwUjukw3BCREQGjGGkK2htOPEdoR1OjLp3LToiIjIMDCNdUU0VcPVEfTjJOgxU39Texqpn/WRYhhMiItJjDCP6oDXhxNLxlmGd/gwnRESkFxhG9FFNFZCT3GBY5xDDCRER6S2GEUOgqtbuOWkynPTQHtZxGcBwQkREXQLDiCFSVQNXk28JJ+Xa2zCcEBFRF8Ew0h00DCcZB4CMxBbCSW2dE5cghhMiIuoUDCPdkaoayEnR7jmpKtPexsKhQfn6uwHXgQwnRETUIRhG6JZwcgDITGw6nDTsOWE4ISKidsIwQo2pam7pOWkpnDTsOTGWpblERKTfGEbo9hqGk7o5J1Wl2ttY2DfRc8JwQkREt8cwQrpT1QC5KfV3JW4unPiMqA8nbsEMJ0RE1CSGEbpzWuHkAJBxsHE4MbevvbcOwwkREWljGKH2p6oBcv+s7znJTASUJdrbmNsDvpENwskghhMiom6KYYQ6nlqlHU4yDjYRTuxu6TlhOCEi6i4YRqjztTac+NzSc2JsIk97iYioQzGMkPzUKiD35C3hpFh7G4YTIiKDxTBCXU9rwomZ7S1zTkIYToiI9BTDCHV9ahWQd6pBODkAVDYTTupu/ufOcEJEpC8YRkj/aIWTA0DG/qbDic/w2p4ThhMioq6MYYT0n1oF5J1u0HPSVDixkQKJg0/jxc4TMDaVp+1ERMQwQgaoYTjJOCD9t7Ko+e0VRlIgaSqoMKwQEXU4hhEyfGo1kH8aKDgHFGUARZm1S5b0X5Wy5f0VRoCtR/Nhxd6LYYWI6A609vubg+2kv4yMpPLzbsGNH1OrgfKC2nDSMKg0WFRKoOSKtGQebPwczYYV79qeFS/AxKzjj5OIyMAxjJBhMjICbF2lxXtY48dvDSvFWY3DSk1ly2EFCsCuhZ4VhhUiolZhGKHu6XZhRYjb96zUVAIl2dKSmdjEizQIK/beTQ8DmZh3+KESEXV1DCNETVEoABsXafEa2vhxrbDSzFJTUR9W0ExYsXVvec4KwwoRdQMMI0Rt0aqwcq35npXiLKD6JlB6VVqyDjX1IrVhpYleFQdfhhUiMhgMI0QdQaEAbJylxWtI48eFAG5eb34IqCjzlrByuOnXaa5nxb62Z8XUomOPk4ioHTCMEMlBoQCsnaTFs7VhpeEk24zasJIjLc2FFRu3ZoaBfBlWiKjLYBgh6opaFVZu3KZnpRwoy5WWK0eafp1GYcW7QVjxZlghok7RpjDy2Wef4cMPP0Rubi5CQkLw6aefIjw8vMlt4+LiMGvWLK115ubmqKysbMtLExFQG1Z6SotnWOPHG4aVpi5bLsxoZVhxvU3PimXHHicRdQs6h5ENGzZg0aJFWLFiBSIiIrBs2TLExMTg3LlzcHFxaXIfOzs7nDt3TvOzQqFoe4uJ6PZaE1YqClvuWakqA8rypOXK0aZfx8a1icuWfet7WRhWiKgVdC4HHxERgWHDhuG///0vAECtVsPb2xvPP/88XnvttUbbx8XFYeHChSgqKmpzI1kOnqiTacJKc5cuZ0hh5XasXZruVWFYIepahJD+EdPOOqQcfFVVFY4fP47Fixdr1hkZGWHMmDFITGyqjoKkrKwMvr6+UKvVCAsLw3vvvYegoKBmt1cqlVAq6+8rUlJSoksziehOKRSAlaO0eIQ2fry5sFI3JFSYAVSVAuX50pJ9rOnXsXaWgkmvUUDIFMC5b4ceFhE1IASQkwKkrAPObQeeOwSYWcvSFJ3CyLVr16BSqeDq6qq13tXVFWfPnm1yn8DAQHz99dcYNGgQiouL8dFHH2HEiBE4ffo0vLy8mtxnyZIleOedd3RpGhF1ptaElcqi5ntWNGGlQFqyjwP7lwJew4DQKUDQo4ClQycfFFE3UZYP/LkRSF4r3Wy0ztntwKAJsjRJp2Gaq1evwtPTEwcPHkRkZKRm/SuvvIKEhAQcPtzM5YUNVFdXo3///pg8eTLefffdJrdpqmfE29ubwzREhqJhWCk4D5zaBFzYCQiV9LixOdDvISB0KuA/GjAylrW5RHqvRgmc/w1IXtfMe20K0Hs0YNy+F9l2yDCNk5MTjI2NkZeXp7U+Ly8Pbm5urXoOU1NTDB48GBcvXmx2G3Nzc5ibs7IkkcFSKADLHtLiHiL9a+zWf62d/lFabN2BQZOkD0vnQLlbTqQ/hABykqX31MnvpaHVOp5DpffUwEel96HMdAojZmZmGDJkCHbv3o3Y2FgA0gTW3bt3Y/78+a16DpVKhZMnT+LBBx/UubFEZMBsXIAR84HIeUDun9IH6J8bpaJuB5ZJi+eQ2g/Qx7rEByhRl1SaB5ysC/Zn6tfbugMhj3fJ+Vk698csWrQIM2fOxNChQxEeHo5ly5ahvLxcU0tkxowZ8PT0xJIlSwAA//jHPzB8+HAEBASgqKgIH374ITIyMjBnzpz2PRIiMgwKhdRb4h4CjH0XuLBD+lC9sFOaW5J9HPhtsdS1HDIF8L+n3buWifROjRI496v0Xrn4u/YwTP+/1A/DdNEhT53fwZMmTUJBQQHefPNN5ObmIjQ0FL/99ptmUmtmZiaMjIw02xcWFuKpp55Cbm4uevTogSFDhuDgwYMYMGBA+x0FERkmEzOg/zhpKSuQupqT1wB5p4DTm6XFxrV+GMelv9wtJuo8QgBXk6R5ICe/l+Zh1fEKB0In681kcJ3rjMiBdUaISEtO7TDOyY3SPXzqeITVD+NYOcrXPqKOVJoL/LlBeg8UNLiS1dZDGoYJnQI49ZGvfQ209vubYYSI9FdNFXBxl/ShfP43QF0jrTc2AwIfqL0a514O45D+q66UaoGkrKsdhlFL600spJ7DkMlA7+guNwzDMEJE3Uv5NeDkD9IwTu6f9eutXYBBE6Vg4srhYdIjQgDZSdLf9KkfgMri+se8I2pr8jwCWNjL18bbYBghou4r96Q0jv7nBuDmtfr17qFSKAn+K4dxqOsquVo7DLMOuFZ/XzfYeUo9ICGTAacA+dqnA4YRIiJVtdSlnbwGOPcboK6W1huZAoH3S8EkYAxgbCpvO4mqK4Fzv0hDjml/NBiGsZSGYUKnSLdN6GLDMLfDMEJE1FD5damrO3mNdD+OOtbO0tU4IZMBt4HytY+6HyGAK8dqh2F+BJQNhmF8IqUAMiAWsNDf7z2GESKi5uSdri2qtkG6N04dt0G1wzgTAOue8rWPDFvJVSBlvfQ3eP1C/Xp779qiZJOBnv7yta8dMYwQEd2Oqhq4uLt2GOdX7WGcvjFSMOkzlsM4dOeqK4Czv0h/a2l7ANR+9ZpYAgPGS70gfiOBBnW6DAHDCBGRLm7ekG7Yl7wGuHqifr2VU+3VOFMAt2D52kf6RwjgytEGwzAl9Y/53iX1gAwYr9fDMLfDMEJE1FZ5Z4CUtUDKBqA8v369W3CDYRwn+dpHXVvxlfphmBtp9evtfaSqqCGPA4695WtfJ2IYISK6U6oa6cqG5DVSwSlVlbTeyAToEyP1lvS5TypbT91b1c36YZhL8dAMw5ha1Q/D+N5tcMMwt8MwQkTUnuqGcVLWSTfrq2PVU+opCZ0iTYBVKORrI3UuIYCsw7XDMJuBqtL6x3zvrr0a5mHA3Fa+NsqMYYSIqKPkn60fxinLrV/vOlD6AgqeCNg4y9c+6lhFWcCfdcMwl+rXO/hK5z/kcaCHn2zN60oYRoiIOpqqBri0R/pSOvsLoFJK641MgICx0hdT3/s5jGMIqm4CqT9LvSDpe1E/DGMNBMVK59pnRLcbhrkdhhEios5UUShdMZG8Fsg+Vr/e0rF+GMc9hMM4+kQIIDNRCiCnt2oPw/iNlCYz9x8HmNvI18YujmGEiEguBedrh3HWA6U59etdBtQP49i6ytc+allRZv3VMIXp9et7+AEhdcMwvrI1T58wjBARyU2tqh/GSd1WP4yjMJaKqWmGcczlbScBVeXAmZ+kXpDL++rXm9nUDsNMlUq0s2dLJwwjRERdSUURcPpH6U6sV47Ur7fsAQz8qxRMPAbzy64zqdW1wzBrgTNbgKqy+sd6jaofhjGzlq2J+o5hhIioq7p2QfoCTFkPlF6tX+/cXwolgyYCtm7ytc/QFV6uH4Ypyqhf36OXFEBCJgEOPrI1z5AwjBARdXVqlVQgK2WddKVGTaW0XmEMBNxbO4zzAGBqIWszDYKyDEj9SQogWsMwtg2GYYazZ6qdMYwQEemTymLg9GZpGCfrUP16Cwdg4GPSl6VnGL8sdaFWAxkHaodhtgLV5bUPKIDeUdLvtN9fADMrWZtpyBhGiIj01bWLUm9JyjqgJLt+vVNg7TDOJMDOXb72dXU30qVhmJS10pUxdRz964uS2XvJ175uhGGEiEjfqVVSga3ktbXDOBXSeoUR4H+vdNO1wIc4jAMAylKp9yN5rdQbUsfcDgh6ROoF8Q5nz1InYxghIjIklSXSFR/Ja6UrQOpY2DcYxhnSvb5s1WogY3+DYZibtQ8oAP/RtcMwDwGmlrI2sztjGCEiMlTX02qHcdYDxVn16536AiG1t6i385CvfR3txiVpbk3KeqC4wTBMz4DaYazHAXtP+dpHGgwjRESGTq2Wrgyp6xloOIzTe7T0xWwoPQOanqF1QObB+vXm9sDAR6VeEK+h3atnSA8wjBARdSeVJVIgSVl3y5wJe2Bg7ZwJr2H69WWtVgOXa+fMnPnJsMOWgWIYISLqrm5cqi3qtU4/hzGup9UXhSu5Ur/eqW+Dq4kMeBjKgDCMEBF1d5oJnuukIY6GEzx7R9dP8OwKdTYqi4HTW6QQolVnpRtP0DUADCNERFRPWVp7I7i1UkCpo7n0dQrgHdG5X/ZqFZCeUH8jwUaXLk8BAh/kpct6jGGEiIia1ty9WRz9pdolgx4HHLw77vWvXZQKkqWsb1zUbfBUIHgii7oZCIYRIiJqmVotXZmSvFYaIrm1XHrIlNq71rbDME5lMXDqR2mCbdbh+vUWDkBw3V2LWe7e0DCMEBFR6ynLpCqvyWva70ZydTcCTF4LnN3W4EaARkDAWKkXhjcCNGgMI0RE1DaFGfX3dim8XL++Ry8plIRMAhx8mt+/4HztMMwGoPRq/Xrn/rVXw0wEbN06rPnUdTCMEBHRnRFCKj2fvEYaxqkqq3+s1ygpmPQfB5hZAxVFwOkfpV6QK0frt7PsAQRPkCrDegzmMEw3wzBCRETtp6q8fhgnfW/9ejMbqfJpRiKgUkrrFMZAn7FSL0jf+wETc3naTLJjGCEioo5RlCkNwSSvAQrT69e7DJB6S4InALau8rWPugyGESIi6lhCSFfGXDkG+N0NuIdwGIa0tPb726QT20RERIZEoZCusPEZLndLSM8Zyd0AIiIi6t4YRoiIiEhWDCNEREQkK4YRIiIikhXDCBEREcmKYYSIiIhkxTBCREREsmpTGPnss8/g5+cHCwsLRERE4MiRIy1u//3336Nfv36wsLBAcHAwtm/f3qbGEhERkeHROYxs2LABixYtwltvvYWkpCSEhIQgJiYG+fn5TW5/8OBBTJ48GbNnz8aJEycQGxuL2NhYnDp16o4bT0RERPpP53LwERERGDZsGP773/8CANRqNby9vfH888/jtddea7T9pEmTUF5ejm3btmnWDR8+HKGhoVixYkWrXpPl4ImIiPRPa7+/deoZqaqqwvHjxzFmzJj6JzAywpgxY5CYmNjkPomJiVrbA0BMTEyz2xMREVH3otO9aa5duwaVSgVXV+27Mbq6uuLs2bNN7pObm9vk9rm5uc2+jlKphFKp1PxcUlKiSzOJiIhIj3TJq2mWLFkCe3t7zeLt7S13k4iIiKiD6NQz4uTkBGNjY+Tl5Wmtz8vLg5ubW5P7uLm56bQ9ACxevBiLFi3S/FxcXAwfHx/2kBAREemRuu/t201P1SmMmJmZYciQIdi9ezdiY2MBSBNYd+/ejfnz5ze5T2RkJHbv3o2FCxdq1u3atQuRkZHNvo65uTnMzc01P9cdDHtIiIiI9E9paSns7e2bfVynMAIAixYtwsyZMzF06FCEh4dj2bJlKC8vx6xZswAAM2bMgKenJ5YsWQIAWLBgAaKiovDxxx/joYcewvr163Hs2DF88cUXrX5NDw8PZGVlwdbWFgqFQtcmN6ukpATe3t7Iysoy2Kt0DP0YeXz6z9CPkcen/wz9GDvy+IQQKC0thYeHR4vb6RxGJk2ahIKCArz55pvIzc1FaGgofvvtN80k1czMTBgZ1U9FGTFiBNauXYs33ngDr7/+Ovr06YMtW7Zg4MCBrX5NIyMjeHl56drUVrOzszPIP7CGDP0YeXz6z9CPkcen/wz9GDvq+FrqEamjcxgBgPnz5zc7LBMfH99o3YQJEzBhwoS2vBQREREZuC55NQ0RERF1H906jJibm+Ott97SmixraAz9GHl8+s/Qj5HHp/8M/Ri7wvHpXA6eiIiIqD11654RIiIikh/DCBEREcmKYYSIiIhkxTBCREREsjL4MPLZZ5/Bz88PFhYWiIiIwJEjR1rc/vvvv0e/fv1gYWGB4OBgbN++vZNa2na6HGNcXBwUCoXWYmFh0Ymt1c3evXsxbtw4eHh4QKFQYMuWLbfdJz4+HmFhYTA3N0dAQADi4uI6vJ1tpevxxcfHNzp/CoWixbtgy2nJkiUYNmwYbG1t4eLigtjYWJw7d+62++nL+7Atx6dv78Hly5dj0KBBmoJYkZGR+PXXX1vcR1/OH6D78enb+bvV+++/D4VCoXWLlqZ09jk06DCyYcMGLFq0CG+99RaSkpIQEhKCmJgY5OfnN7n9wYMHMXnyZMyePRsnTpxAbGwsYmNjcerUqU5ueevpeoyAVGUvJydHs2RkZHRii3VTXl6OkJAQfPbZZ63aPj09HQ899BBGjx6N5ORkLFy4EHPmzMGOHTs6uKVto+vx1Tl37pzWOXRxcemgFt6ZhIQEzJs3D4cOHcKuXbtQXV2N++67D+Xl5c3uo0/vw7YcH6Bf70EvLy+8//77OH78OI4dO4Z77rkH48ePx+nTp5vcXp/OH6D78QH6df4aOnr0KFauXIlBgwa1uJ0s51AYsPDwcDFv3jzNzyqVSnh4eIglS5Y0uf3EiRPFQw89pLUuIiJCPPPMMx3azjuh6zF+8803wt7evpNa174AiM2bN7e4zSuvvCKCgoK01k2aNEnExMR0YMvaR2uOb8+ePQKAKCws7JQ2tbf8/HwBQCQkJDS7jT6+D+u05vj0+T1Yp0ePHmLVqlVNPqbP569OS8enr+evtLRU9OnTR+zatUtERUWJBQsWNLutHOfQYHtGqqqqcPz4cYwZM0azzsjICGPGjEFiYmKT+yQmJmptDwAxMTHNbi+3thwjAJSVlcHX1xfe3t63/ReAvtG3c9hWoaGhcHd3x9ixY3HgwAG5m9NqxcXFAABHR8dmt9Hnc9ia4wP09z2oUqmwfv16lJeXN3vndX0+f605PkA/z9+8efPw0EMPNTo3TZHjHBpsGLl27RpUKpXmBn51XF1dmx1fz83N1Wl7ubXlGAMDA/H1119j69at+O6776BWqzFixAhcuXKlM5rc4Zo7hyUlJaioqJCpVe3H3d0dK1aswKZNm7Bp0yZ4e3sjOjoaSUlJcjftttRqNRYuXIi77rqrxRtl6tv7sE5rj08f34MnT56EjY0NzM3NMXfuXGzevBkDBgxoclt9PH+6HJ8+nr/169cjKSkJS5YsadX2cpzDNt0oj/RXZGSkVuIfMWIE+vfvj5UrV+Ldd9+VsWXUGoGBgQgMDNT8PGLECKSlpWHp0qVYvXq1jC27vXnz5uHUqVPYv3+/3E3pEK09Pn18DwYGBiI5ORnFxcX44YcfMHPmTCQkJDT7ha1vdDk+fTt/WVlZWLBgAXbt2tWlJ9oabBhxcnKCsbEx8vLytNbn5eXBzc2tyX3c3Nx02l5ubTnGW5mammLw4MG4ePFiRzSx0zV3Du3s7GBpaSlTqzpWeHh4l/+Cnz9/PrZt24a9e/fCy8urxW317X0I6HZ8t9KH96CZmRkCAgIAAEOGDMHRo0fxySefYOXKlY221cfzp8vx3aqrn7/jx48jPz8fYWFhmnUqlQp79+7Ff//7XyiVShgbG2vtI8c5NNhhGjMzMwwZMgS7d+/WrFOr1di9e3ezY4GRkZFa2wPArl27Whw7lFNbjvFWKpUKJ0+ehLu7e0c1s1Pp2zlsD8nJyV32/AkhMH/+fGzevBl//PEHevXqddt99OkctuX4bqWP70G1Wg2lUtnkY/p0/prT0vHdqqufv3vvvRcnT55EcnKyZhk6dCimTp2K5OTkRkEEkOkcdtjU2C5g/fr1wtzcXMTFxYkzZ86Ip59+Wjg4OIjc3FwhhBDTp08Xr732mmb7AwcOCBMTE/HRRx+J1NRU8dZbbwlTU1Nx8uRJuQ7htnQ9xnfeeUfs2LFDpKWliePHj4vHH39cWFhYiNOnT8t1CC0qLS0VJ06cECdOnBAAxL///W9x4sQJkZGRIYQQ4rXXXhPTp0/XbH/p0iVhZWUlXn75ZZGamio+++wzYWxsLH777Te5DqFFuh7f0qVLxZYtW8SFCxfEyZMnxYIFC4SRkZH4/fff5TqEFj377LPC3t5exMfHi5ycHM1y8+ZNzTb6/D5sy/Hp23vwtddeEwkJCSI9PV38+eef4rXXXhMKhULs3LlTCKHf508I3Y9P385fU269mqYrnEODDiNCCPHpp58KHx8fYWZmJsLDw8WhQ4c0j0VFRYmZM2dqbb9x40bRt29fYWZmJoKCgsQvv/zSyS3WnS7HuHDhQs22rq6u4sEHHxRJSUkytLp16i5lvXWpO6aZM2eKqKioRvuEhoYKMzMz0bt3b/HNN990ertbS9fj++CDD4S/v7+wsLAQjo6OIjo6Wvzxxx/yNL4Vmjo2AFrnRJ/fh205Pn17Dz755JPC19dXmJmZCWdnZ3HvvfdqvqiF0O/zJ4Tux6dv568pt4aRrnAOFUII0XH9LkREREQtM9g5I0RERKQfGEaIiIhIVgwjREREJCuGESIiIpIVwwgRERHJimGEiIiIZMUwQkRERLJiGCEiIiJZMYwQERGRrBhGiIiISFYMI0RERCQrhhEiIiKS1f8H3oNclKq3gk4AAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 8.82 s (started: 2025-12-25 12:39:52 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Show the total (sum) of the rewards as well as the correct_answer_reward_func (means with in the batch)\n",
        "# No changes needed in this cell\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# If you want to graph other columns, check these out\n",
        "print(f\"available columns: {trainer.state.log_history[0].keys()}\")\n",
        "\n",
        "log_df = pd.DataFrame(trainer.state.log_history)\n",
        "log_df[\"reward\"].plot()\n",
        "log_df[\"rewards/correct_answer_reward_func/mean\"].plot()\n",
        "\n",
        "# Show the legend\n",
        "plt.legend([\"reward\", \"rewards/correct_answer_reward_func/mean\"])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Slower train (1+ hour)\n",
        "\n",
        "If everything looks good, let's go for a longer training session!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 401 | Num Epochs = 1 | Total steps = 100\n",
            "O^O/ \\_/ \\    Batch size per device = 8 | Gradient accumulation steps = 2\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (8 x 2 x 1) = 16\n",
            " \"-____-\"     Trainable parameters = 59,867,136 of 3,145,805,824 (1.90% trained)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"g\" are there in the word \"glisten\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of g's in the word glisten\n",
            "1. g - 1 so far\n",
            "2. l - 1 so far\n",
            "3. i - 1 so far\n",
            "4. t - 1 so far\n",
            "5. n - 1 so far\n",
            "6. s - 1 so far\n",
            "7. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [100/100 25:13, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>reward</th>\n",
              "      <th>reward_std</th>\n",
              "      <th>completions / mean_length</th>\n",
              "      <th>completions / min_length</th>\n",
              "      <th>completions / max_length</th>\n",
              "      <th>completions / clipped_ratio</th>\n",
              "      <th>completions / mean_terminated_length</th>\n",
              "      <th>completions / min_terminated_length</th>\n",
              "      <th>completions / max_terminated_length</th>\n",
              "      <th>kl</th>\n",
              "      <th>rewards / numbering_reward_func / mean</th>\n",
              "      <th>rewards / numbering_reward_func / std</th>\n",
              "      <th>rewards / spelling_reward_func / mean</th>\n",
              "      <th>rewards / spelling_reward_func / std</th>\n",
              "      <th>rewards / counting_reward_func / mean</th>\n",
              "      <th>rewards / counting_reward_func / std</th>\n",
              "      <th>rewards / format_reward_func / mean</th>\n",
              "      <th>rewards / format_reward_func / std</th>\n",
              "      <th>rewards / correct_answer_reward_func / mean</th>\n",
              "      <th>rewards / correct_answer_reward_func / std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.126339</td>\n",
              "      <td>2.293242</td>\n",
              "      <td>92.375000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>156.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>92.375000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>156.000000</td>\n",
              "      <td>0.000087</td>\n",
              "      <td>0.846875</td>\n",
              "      <td>0.287210</td>\n",
              "      <td>-0.625000</td>\n",
              "      <td>1.821172</td>\n",
              "      <td>0.029464</td>\n",
              "      <td>0.769189</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.341565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.781945</td>\n",
              "      <td>0.582621</td>\n",
              "      <td>82.312500</td>\n",
              "      <td>57.000000</td>\n",
              "      <td>122.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>82.312500</td>\n",
              "      <td>57.000000</td>\n",
              "      <td>122.000000</td>\n",
              "      <td>0.000091</td>\n",
              "      <td>0.921875</td>\n",
              "      <td>0.150520</td>\n",
              "      <td>-0.750000</td>\n",
              "      <td>1.807392</td>\n",
              "      <td>0.172569</td>\n",
              "      <td>0.565574</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.437500</td>\n",
              "      <td>0.512348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.630357</td>\n",
              "      <td>1.742079</td>\n",
              "      <td>85.625000</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>117.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>85.625000</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>117.000000</td>\n",
              "      <td>0.000145</td>\n",
              "      <td>0.953869</td>\n",
              "      <td>0.114836</td>\n",
              "      <td>-0.437500</td>\n",
              "      <td>1.860779</td>\n",
              "      <td>0.676488</td>\n",
              "      <td>0.365005</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.437500</td>\n",
              "      <td>0.512348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>1.651091</td>\n",
              "      <td>1.590168</td>\n",
              "      <td>84.937500</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>120.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>84.937500</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>120.000000</td>\n",
              "      <td>0.000268</td>\n",
              "      <td>0.947917</td>\n",
              "      <td>0.079786</td>\n",
              "      <td>-0.250000</td>\n",
              "      <td>2.175622</td>\n",
              "      <td>-0.296825</td>\n",
              "      <td>0.561020</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.447214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.628720</td>\n",
              "      <td>0.831039</td>\n",
              "      <td>80.625000</td>\n",
              "      <td>58.000000</td>\n",
              "      <td>94.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>80.625000</td>\n",
              "      <td>58.000000</td>\n",
              "      <td>94.000000</td>\n",
              "      <td>0.000047</td>\n",
              "      <td>0.921875</td>\n",
              "      <td>0.253620</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>1.732051</td>\n",
              "      <td>-0.043155</td>\n",
              "      <td>0.687719</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.516398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.516369</td>\n",
              "      <td>1.163440</td>\n",
              "      <td>78.187500</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>109.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>78.187500</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>109.000000</td>\n",
              "      <td>0.000139</td>\n",
              "      <td>0.906250</td>\n",
              "      <td>0.201556</td>\n",
              "      <td>-0.812500</td>\n",
              "      <td>1.223043</td>\n",
              "      <td>0.797619</td>\n",
              "      <td>0.417584</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.259673</td>\n",
              "      <td>0.899630</td>\n",
              "      <td>75.062500</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>75.062500</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>0.000141</td>\n",
              "      <td>0.832589</td>\n",
              "      <td>0.181039</td>\n",
              "      <td>-1.875000</td>\n",
              "      <td>0.885061</td>\n",
              "      <td>0.052083</td>\n",
              "      <td>0.625385</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.447214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.566243</td>\n",
              "      <td>1.100267</td>\n",
              "      <td>94.312500</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>87.266670</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>0.000137</td>\n",
              "      <td>0.931548</td>\n",
              "      <td>0.169450</td>\n",
              "      <td>-1.250000</td>\n",
              "      <td>1.183216</td>\n",
              "      <td>0.384695</td>\n",
              "      <td>0.719570</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.516398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.840030</td>\n",
              "      <td>0.794936</td>\n",
              "      <td>80.687500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>173.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>80.687500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>173.000000</td>\n",
              "      <td>0.000237</td>\n",
              "      <td>0.791667</td>\n",
              "      <td>0.372678</td>\n",
              "      <td>-1.937500</td>\n",
              "      <td>2.048373</td>\n",
              "      <td>0.423363</td>\n",
              "      <td>0.647076</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>0.512348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>2.200000</td>\n",
              "      <td>1.443973</td>\n",
              "      <td>81.812500</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>115.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>81.812500</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>115.000000</td>\n",
              "      <td>0.000471</td>\n",
              "      <td>0.991071</td>\n",
              "      <td>0.035714</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>1.569236</td>\n",
              "      <td>-0.103571</td>\n",
              "      <td>0.613978</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.447214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>0.803571</td>\n",
              "      <td>1.439698</td>\n",
              "      <td>81.875000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>81.875000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>0.000744</td>\n",
              "      <td>0.882589</td>\n",
              "      <td>0.194184</td>\n",
              "      <td>-1.687500</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>0.045982</td>\n",
              "      <td>0.558429</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>0.512348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>1.531845</td>\n",
              "      <td>1.617625</td>\n",
              "      <td>97.937500</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>197.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>97.937500</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>197.000000</td>\n",
              "      <td>0.000370</td>\n",
              "      <td>0.975000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>-1.187500</td>\n",
              "      <td>2.007278</td>\n",
              "      <td>0.369345</td>\n",
              "      <td>0.559144</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>2.233780</td>\n",
              "      <td>1.171026</td>\n",
              "      <td>84.625000</td>\n",
              "      <td>57.000000</td>\n",
              "      <td>122.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>84.625000</td>\n",
              "      <td>57.000000</td>\n",
              "      <td>122.000000</td>\n",
              "      <td>0.001108</td>\n",
              "      <td>0.984375</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>-0.937500</td>\n",
              "      <td>1.611159</td>\n",
              "      <td>0.686905</td>\n",
              "      <td>0.491400</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.516398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>3.239583</td>\n",
              "      <td>1.203239</td>\n",
              "      <td>78.000000</td>\n",
              "      <td>47.000000</td>\n",
              "      <td>112.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>78.000000</td>\n",
              "      <td>47.000000</td>\n",
              "      <td>112.000000</td>\n",
              "      <td>0.001207</td>\n",
              "      <td>0.823661</td>\n",
              "      <td>0.376492</td>\n",
              "      <td>0.437500</td>\n",
              "      <td>1.672075</td>\n",
              "      <td>0.228423</td>\n",
              "      <td>0.676385</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.447214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>2.721131</td>\n",
              "      <td>1.458867</td>\n",
              "      <td>70.187500</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>93.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>70.187500</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>93.000000</td>\n",
              "      <td>0.000599</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.331662</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>2.190890</td>\n",
              "      <td>0.608631</td>\n",
              "      <td>0.499191</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.403113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>3.048214</td>\n",
              "      <td>1.348851</td>\n",
              "      <td>83.062500</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>83.062500</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>0.001460</td>\n",
              "      <td>0.991071</td>\n",
              "      <td>0.035714</td>\n",
              "      <td>0.312500</td>\n",
              "      <td>1.851801</td>\n",
              "      <td>0.432143</td>\n",
              "      <td>0.621707</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.312500</td>\n",
              "      <td>0.478714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>0.560466</td>\n",
              "      <td>1.266982</td>\n",
              "      <td>96.250000</td>\n",
              "      <td>75.000000</td>\n",
              "      <td>129.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>96.250000</td>\n",
              "      <td>75.000000</td>\n",
              "      <td>129.000000</td>\n",
              "      <td>0.001276</td>\n",
              "      <td>0.964286</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>-1.625000</td>\n",
              "      <td>1.627882</td>\n",
              "      <td>-0.091319</td>\n",
              "      <td>0.715018</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.312500</td>\n",
              "      <td>0.478714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.000400</td>\n",
              "      <td>1.821726</td>\n",
              "      <td>1.390414</td>\n",
              "      <td>84.562500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>116.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>84.562500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>116.000000</td>\n",
              "      <td>0.002081</td>\n",
              "      <td>0.909226</td>\n",
              "      <td>0.215993</td>\n",
              "      <td>-0.625000</td>\n",
              "      <td>2.093641</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.653466</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.437500</td>\n",
              "      <td>0.512348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>0.811161</td>\n",
              "      <td>1.544675</td>\n",
              "      <td>87.125000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>113.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>87.125000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>113.000000</td>\n",
              "      <td>0.005173</td>\n",
              "      <td>0.850000</td>\n",
              "      <td>0.305505</td>\n",
              "      <td>-1.750000</td>\n",
              "      <td>1.238278</td>\n",
              "      <td>0.461161</td>\n",
              "      <td>0.678423</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.447214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.000600</td>\n",
              "      <td>2.369792</td>\n",
              "      <td>0.638144</td>\n",
              "      <td>82.937500</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>102.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>82.937500</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>102.000000</td>\n",
              "      <td>0.002860</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>0.111803</td>\n",
              "      <td>-0.562500</td>\n",
              "      <td>1.631717</td>\n",
              "      <td>0.244792</td>\n",
              "      <td>0.636891</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.447214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.000800</td>\n",
              "      <td>1.319246</td>\n",
              "      <td>0.638635</td>\n",
              "      <td>89.187500</td>\n",
              "      <td>61.000000</td>\n",
              "      <td>112.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>89.187500</td>\n",
              "      <td>61.000000</td>\n",
              "      <td>112.000000</td>\n",
              "      <td>0.003818</td>\n",
              "      <td>0.944643</td>\n",
              "      <td>0.113074</td>\n",
              "      <td>-1.562500</td>\n",
              "      <td>0.629153</td>\n",
              "      <td>0.499603</td>\n",
              "      <td>0.550133</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.437500</td>\n",
              "      <td>0.512348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.000600</td>\n",
              "      <td>1.723562</td>\n",
              "      <td>1.840423</td>\n",
              "      <td>94.000000</td>\n",
              "      <td>74.000000</td>\n",
              "      <td>147.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>94.000000</td>\n",
              "      <td>74.000000</td>\n",
              "      <td>147.000000</td>\n",
              "      <td>0.002852</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>0.056928</td>\n",
              "      <td>-0.687500</td>\n",
              "      <td>1.815443</td>\n",
              "      <td>-0.005605</td>\n",
              "      <td>0.776986</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.437500</td>\n",
              "      <td>0.512348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.000800</td>\n",
              "      <td>1.659226</td>\n",
              "      <td>0.967826</td>\n",
              "      <td>84.875000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>158.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>84.875000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>158.000000</td>\n",
              "      <td>0.003865</td>\n",
              "      <td>0.880952</td>\n",
              "      <td>0.212025</td>\n",
              "      <td>-1.062500</td>\n",
              "      <td>1.569236</td>\n",
              "      <td>0.340774</td>\n",
              "      <td>0.616216</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.516398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.000800</td>\n",
              "      <td>-0.445833</td>\n",
              "      <td>1.057790</td>\n",
              "      <td>97.125000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>164.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>97.125000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>164.000000</td>\n",
              "      <td>0.004238</td>\n",
              "      <td>0.934375</td>\n",
              "      <td>0.200390</td>\n",
              "      <td>-2.250000</td>\n",
              "      <td>0.930949</td>\n",
              "      <td>-0.442708</td>\n",
              "      <td>0.565298</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.312500</td>\n",
              "      <td>0.478714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.002500</td>\n",
              "      <td>1.879464</td>\n",
              "      <td>1.724888</td>\n",
              "      <td>88.500000</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>142.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>88.500000</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>142.000000</td>\n",
              "      <td>0.012669</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>-0.937500</td>\n",
              "      <td>1.913766</td>\n",
              "      <td>0.337798</td>\n",
              "      <td>0.646008</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.516398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.000900</td>\n",
              "      <td>1.323909</td>\n",
              "      <td>1.073298</td>\n",
              "      <td>99.687500</td>\n",
              "      <td>92.000000</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>99.687500</td>\n",
              "      <td>92.000000</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>0.004429</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.250000</td>\n",
              "      <td>1.125463</td>\n",
              "      <td>0.136409</td>\n",
              "      <td>0.568891</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.437500</td>\n",
              "      <td>0.512348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.000500</td>\n",
              "      <td>2.868998</td>\n",
              "      <td>1.129638</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>114.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>114.000000</td>\n",
              "      <td>0.002479</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.273252</td>\n",
              "      <td>-0.062500</td>\n",
              "      <td>2.294014</td>\n",
              "      <td>0.343998</td>\n",
              "      <td>0.807455</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>0.478714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.000900</td>\n",
              "      <td>3.491369</td>\n",
              "      <td>1.305607</td>\n",
              "      <td>80.750000</td>\n",
              "      <td>57.000000</td>\n",
              "      <td>160.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>80.750000</td>\n",
              "      <td>57.000000</td>\n",
              "      <td>160.000000</td>\n",
              "      <td>0.004577</td>\n",
              "      <td>0.912500</td>\n",
              "      <td>0.145488</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>1.612452</td>\n",
              "      <td>0.391369</td>\n",
              "      <td>0.821157</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>0.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.001700</td>\n",
              "      <td>1.270585</td>\n",
              "      <td>1.241373</td>\n",
              "      <td>86.437500</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>112.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>86.437500</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>112.000000</td>\n",
              "      <td>0.008706</td>\n",
              "      <td>0.895833</td>\n",
              "      <td>0.284638</td>\n",
              "      <td>-1.500000</td>\n",
              "      <td>2.250926</td>\n",
              "      <td>0.437252</td>\n",
              "      <td>0.623142</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.437500</td>\n",
              "      <td>0.512348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.001400</td>\n",
              "      <td>2.855655</td>\n",
              "      <td>1.079139</td>\n",
              "      <td>74.937500</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>92.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>74.937500</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>92.000000</td>\n",
              "      <td>0.007107</td>\n",
              "      <td>0.959821</td>\n",
              "      <td>0.127692</td>\n",
              "      <td>-0.125000</td>\n",
              "      <td>1.668333</td>\n",
              "      <td>0.270833</td>\n",
              "      <td>0.631132</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.447214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.001400</td>\n",
              "      <td>0.590030</td>\n",
              "      <td>1.351797</td>\n",
              "      <td>91.250000</td>\n",
              "      <td>75.000000</td>\n",
              "      <td>101.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>91.250000</td>\n",
              "      <td>75.000000</td>\n",
              "      <td>101.000000</td>\n",
              "      <td>0.006985</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>-1.812500</td>\n",
              "      <td>0.910586</td>\n",
              "      <td>0.360863</td>\n",
              "      <td>0.729309</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.341565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.000800</td>\n",
              "      <td>0.871825</td>\n",
              "      <td>0.838077</td>\n",
              "      <td>89.875000</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>120.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>89.875000</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>120.000000</td>\n",
              "      <td>0.004193</td>\n",
              "      <td>0.910714</td>\n",
              "      <td>0.357143</td>\n",
              "      <td>-1.500000</td>\n",
              "      <td>2.190890</td>\n",
              "      <td>0.086111</td>\n",
              "      <td>0.784975</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.002800</td>\n",
              "      <td>2.768576</td>\n",
              "      <td>1.456459</td>\n",
              "      <td>81.875000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>174.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>81.875000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>174.000000</td>\n",
              "      <td>0.013940</td>\n",
              "      <td>0.945312</td>\n",
              "      <td>0.218750</td>\n",
              "      <td>-0.375000</td>\n",
              "      <td>2.629956</td>\n",
              "      <td>0.510764</td>\n",
              "      <td>0.580749</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>0.478714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>2.902778</td>\n",
              "      <td>0.732072</td>\n",
              "      <td>86.625000</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>113.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>86.625000</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>113.000000</td>\n",
              "      <td>0.005189</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>2.418677</td>\n",
              "      <td>0.277778</td>\n",
              "      <td>0.660859</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.516398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.002000</td>\n",
              "      <td>3.197917</td>\n",
              "      <td>0.872822</td>\n",
              "      <td>75.500000</td>\n",
              "      <td>66.000000</td>\n",
              "      <td>97.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>75.500000</td>\n",
              "      <td>66.000000</td>\n",
              "      <td>97.000000</td>\n",
              "      <td>0.010101</td>\n",
              "      <td>0.987500</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>-0.062500</td>\n",
              "      <td>1.526161</td>\n",
              "      <td>0.835417</td>\n",
              "      <td>0.288410</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.437500</td>\n",
              "      <td>0.512348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.002800</td>\n",
              "      <td>3.329167</td>\n",
              "      <td>1.339273</td>\n",
              "      <td>79.125000</td>\n",
              "      <td>66.000000</td>\n",
              "      <td>92.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>79.125000</td>\n",
              "      <td>66.000000</td>\n",
              "      <td>92.000000</td>\n",
              "      <td>0.013771</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>-0.187500</td>\n",
              "      <td>1.796988</td>\n",
              "      <td>0.725000</td>\n",
              "      <td>0.597216</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.403113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.001800</td>\n",
              "      <td>2.709226</td>\n",
              "      <td>1.482345</td>\n",
              "      <td>87.000000</td>\n",
              "      <td>74.000000</td>\n",
              "      <td>101.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>87.000000</td>\n",
              "      <td>74.000000</td>\n",
              "      <td>101.000000</td>\n",
              "      <td>0.008836</td>\n",
              "      <td>0.989583</td>\n",
              "      <td>0.041667</td>\n",
              "      <td>-0.125000</td>\n",
              "      <td>1.543805</td>\n",
              "      <td>0.344643</td>\n",
              "      <td>0.714131</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.516398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.001800</td>\n",
              "      <td>0.842413</td>\n",
              "      <td>0.827044</td>\n",
              "      <td>94.312500</td>\n",
              "      <td>74.000000</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>94.312500</td>\n",
              "      <td>74.000000</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>0.009072</td>\n",
              "      <td>0.864955</td>\n",
              "      <td>0.375763</td>\n",
              "      <td>-1.312500</td>\n",
              "      <td>2.120338</td>\n",
              "      <td>-0.022542</td>\n",
              "      <td>0.665796</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.312500</td>\n",
              "      <td>0.478714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.002700</td>\n",
              "      <td>2.188244</td>\n",
              "      <td>1.213323</td>\n",
              "      <td>96.187500</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>122.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>96.187500</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>122.000000</td>\n",
              "      <td>0.013296</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.812500</td>\n",
              "      <td>2.166987</td>\n",
              "      <td>0.438244</td>\n",
              "      <td>0.493399</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>0.512348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.017200</td>\n",
              "      <td>2.627679</td>\n",
              "      <td>0.859698</td>\n",
              "      <td>95.812500</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>137.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>95.812500</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>137.000000</td>\n",
              "      <td>0.086199</td>\n",
              "      <td>0.991071</td>\n",
              "      <td>0.035714</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>1.264911</td>\n",
              "      <td>0.574107</td>\n",
              "      <td>0.567145</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>0.512348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.002400</td>\n",
              "      <td>3.220238</td>\n",
              "      <td>0.709915</td>\n",
              "      <td>83.812500</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>83.812500</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>0.011769</td>\n",
              "      <td>0.961310</td>\n",
              "      <td>0.106079</td>\n",
              "      <td>-0.062500</td>\n",
              "      <td>1.481835</td>\n",
              "      <td>0.633929</td>\n",
              "      <td>0.406567</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>0.478714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.001700</td>\n",
              "      <td>1.441964</td>\n",
              "      <td>1.110595</td>\n",
              "      <td>79.875000</td>\n",
              "      <td>58.000000</td>\n",
              "      <td>92.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>79.875000</td>\n",
              "      <td>58.000000</td>\n",
              "      <td>92.000000</td>\n",
              "      <td>0.008422</td>\n",
              "      <td>0.927083</td>\n",
              "      <td>0.145535</td>\n",
              "      <td>-1.437500</td>\n",
              "      <td>0.629153</td>\n",
              "      <td>0.577381</td>\n",
              "      <td>0.488376</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.002200</td>\n",
              "      <td>0.560838</td>\n",
              "      <td>1.422909</td>\n",
              "      <td>98.062500</td>\n",
              "      <td>66.000000</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>98.062500</td>\n",
              "      <td>66.000000</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>0.011131</td>\n",
              "      <td>0.976562</td>\n",
              "      <td>0.067988</td>\n",
              "      <td>-1.750000</td>\n",
              "      <td>2.265686</td>\n",
              "      <td>-0.040724</td>\n",
              "      <td>0.690889</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.002000</td>\n",
              "      <td>3.852679</td>\n",
              "      <td>0.653313</td>\n",
              "      <td>82.562500</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>104.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>82.562500</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>104.000000</td>\n",
              "      <td>0.010226</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>1.707825</td>\n",
              "      <td>0.727679</td>\n",
              "      <td>0.335364</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.516398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.003300</td>\n",
              "      <td>2.684722</td>\n",
              "      <td>1.251248</td>\n",
              "      <td>95.500000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>95.500000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>0.016415</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.625000</td>\n",
              "      <td>2.848976</td>\n",
              "      <td>0.684722</td>\n",
              "      <td>0.576307</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.001600</td>\n",
              "      <td>3.075000</td>\n",
              "      <td>1.908698</td>\n",
              "      <td>84.750000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>92.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>84.750000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>92.000000</td>\n",
              "      <td>0.007979</td>\n",
              "      <td>0.991071</td>\n",
              "      <td>0.035714</td>\n",
              "      <td>-0.250000</td>\n",
              "      <td>1.437591</td>\n",
              "      <td>0.646429</td>\n",
              "      <td>0.451257</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>0.478714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.001800</td>\n",
              "      <td>1.397569</td>\n",
              "      <td>1.203689</td>\n",
              "      <td>93.500000</td>\n",
              "      <td>74.000000</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>93.500000</td>\n",
              "      <td>74.000000</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>0.008751</td>\n",
              "      <td>0.989583</td>\n",
              "      <td>0.041667</td>\n",
              "      <td>-1.187500</td>\n",
              "      <td>0.543906</td>\n",
              "      <td>0.282986</td>\n",
              "      <td>0.669302</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.312500</td>\n",
              "      <td>0.478714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.001400</td>\n",
              "      <td>2.035863</td>\n",
              "      <td>1.179612</td>\n",
              "      <td>91.437500</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>103.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>91.437500</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>103.000000</td>\n",
              "      <td>0.007060</td>\n",
              "      <td>0.969643</td>\n",
              "      <td>0.066368</td>\n",
              "      <td>-1.125000</td>\n",
              "      <td>0.957427</td>\n",
              "      <td>0.691220</td>\n",
              "      <td>0.370478</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.516398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.001900</td>\n",
              "      <td>3.954167</td>\n",
              "      <td>1.446237</td>\n",
              "      <td>82.312500</td>\n",
              "      <td>74.000000</td>\n",
              "      <td>108.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>82.312500</td>\n",
              "      <td>74.000000</td>\n",
              "      <td>108.000000</td>\n",
              "      <td>0.009703</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>1.537043</td>\n",
              "      <td>0.704167</td>\n",
              "      <td>0.529413</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>0.512348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.002100</td>\n",
              "      <td>1.343750</td>\n",
              "      <td>1.415732</td>\n",
              "      <td>98.312500</td>\n",
              "      <td>85.000000</td>\n",
              "      <td>111.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>98.312500</td>\n",
              "      <td>85.000000</td>\n",
              "      <td>111.000000</td>\n",
              "      <td>0.010320</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.937500</td>\n",
              "      <td>1.436141</td>\n",
              "      <td>0.718750</td>\n",
              "      <td>0.570367</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>0.512348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>0.003400</td>\n",
              "      <td>0.872024</td>\n",
              "      <td>1.339593</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>78.000000</td>\n",
              "      <td>120.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>78.000000</td>\n",
              "      <td>120.000000</td>\n",
              "      <td>0.016757</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.687500</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>0.184524</td>\n",
              "      <td>0.727380</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>0.002100</td>\n",
              "      <td>2.960417</td>\n",
              "      <td>1.265793</td>\n",
              "      <td>92.812500</td>\n",
              "      <td>74.000000</td>\n",
              "      <td>112.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>92.812500</td>\n",
              "      <td>74.000000</td>\n",
              "      <td>112.000000</td>\n",
              "      <td>0.010675</td>\n",
              "      <td>0.968750</td>\n",
              "      <td>0.067185</td>\n",
              "      <td>-0.625000</td>\n",
              "      <td>2.362908</td>\n",
              "      <td>0.866667</td>\n",
              "      <td>0.312694</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.447214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>0.005700</td>\n",
              "      <td>2.468750</td>\n",
              "      <td>1.341494</td>\n",
              "      <td>79.187500</td>\n",
              "      <td>57.000000</td>\n",
              "      <td>103.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>79.187500</td>\n",
              "      <td>57.000000</td>\n",
              "      <td>103.000000</td>\n",
              "      <td>0.028342</td>\n",
              "      <td>0.915625</td>\n",
              "      <td>0.113606</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>1.966384</td>\n",
              "      <td>0.615625</td>\n",
              "      <td>0.340876</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.437500</td>\n",
              "      <td>0.512348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>0.003400</td>\n",
              "      <td>1.475298</td>\n",
              "      <td>1.150825</td>\n",
              "      <td>94.125000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>131.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>94.125000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>131.000000</td>\n",
              "      <td>0.017185</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>-1.500000</td>\n",
              "      <td>0.816497</td>\n",
              "      <td>0.462798</td>\n",
              "      <td>0.745950</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>0.512348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>0.003900</td>\n",
              "      <td>2.676786</td>\n",
              "      <td>1.241548</td>\n",
              "      <td>80.937500</td>\n",
              "      <td>66.000000</td>\n",
              "      <td>101.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>80.937500</td>\n",
              "      <td>66.000000</td>\n",
              "      <td>101.000000</td>\n",
              "      <td>0.019437</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.089443</td>\n",
              "      <td>-0.750000</td>\n",
              "      <td>1.125463</td>\n",
              "      <td>0.664286</td>\n",
              "      <td>0.643079</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.403113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>0.003800</td>\n",
              "      <td>1.740476</td>\n",
              "      <td>1.022846</td>\n",
              "      <td>92.062500</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>154.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>92.062500</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>154.000000</td>\n",
              "      <td>0.019123</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.625000</td>\n",
              "      <td>1.707825</td>\n",
              "      <td>0.240476</td>\n",
              "      <td>0.639733</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.187500</td>\n",
              "      <td>0.403113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>0.004400</td>\n",
              "      <td>3.028572</td>\n",
              "      <td>1.040388</td>\n",
              "      <td>80.500000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>111.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>80.500000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>111.000000</td>\n",
              "      <td>0.022193</td>\n",
              "      <td>0.923214</td>\n",
              "      <td>0.207799</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.190890</td>\n",
              "      <td>0.480357</td>\n",
              "      <td>0.706818</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>0.003200</td>\n",
              "      <td>1.702827</td>\n",
              "      <td>1.255443</td>\n",
              "      <td>91.562500</td>\n",
              "      <td>74.000000</td>\n",
              "      <td>104.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>91.562500</td>\n",
              "      <td>74.000000</td>\n",
              "      <td>104.000000</td>\n",
              "      <td>0.015958</td>\n",
              "      <td>0.973214</td>\n",
              "      <td>0.057588</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>1.095445</td>\n",
              "      <td>0.354613</td>\n",
              "      <td>0.619143</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>0.002200</td>\n",
              "      <td>4.002778</td>\n",
              "      <td>1.134246</td>\n",
              "      <td>81.687500</td>\n",
              "      <td>57.000000</td>\n",
              "      <td>112.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>81.687500</td>\n",
              "      <td>57.000000</td>\n",
              "      <td>112.000000</td>\n",
              "      <td>0.010957</td>\n",
              "      <td>0.975000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.437500</td>\n",
              "      <td>1.547848</td>\n",
              "      <td>0.840278</td>\n",
              "      <td>0.327024</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.447214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.001900</td>\n",
              "      <td>4.426190</td>\n",
              "      <td>1.177585</td>\n",
              "      <td>82.750000</td>\n",
              "      <td>66.000000</td>\n",
              "      <td>94.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>82.750000</td>\n",
              "      <td>66.000000</td>\n",
              "      <td>94.000000</td>\n",
              "      <td>0.009303</td>\n",
              "      <td>0.987500</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>0.688690</td>\n",
              "      <td>0.529804</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.341565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>61</td>\n",
              "      <td>0.003100</td>\n",
              "      <td>4.734524</td>\n",
              "      <td>1.287983</td>\n",
              "      <td>82.937500</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>102.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>82.937500</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>102.000000</td>\n",
              "      <td>0.015636</td>\n",
              "      <td>0.960714</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>0.898810</td>\n",
              "      <td>0.336212</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62</td>\n",
              "      <td>0.002900</td>\n",
              "      <td>2.245536</td>\n",
              "      <td>0.927193</td>\n",
              "      <td>92.250000</td>\n",
              "      <td>83.000000</td>\n",
              "      <td>104.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>92.250000</td>\n",
              "      <td>83.000000</td>\n",
              "      <td>104.000000</td>\n",
              "      <td>0.014618</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.562500</td>\n",
              "      <td>1.631717</td>\n",
              "      <td>0.495536</td>\n",
              "      <td>0.693451</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.312500</td>\n",
              "      <td>0.478714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>63</td>\n",
              "      <td>0.007500</td>\n",
              "      <td>2.900893</td>\n",
              "      <td>0.969249</td>\n",
              "      <td>85.562500</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>103.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>85.562500</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>103.000000</td>\n",
              "      <td>0.037602</td>\n",
              "      <td>0.982143</td>\n",
              "      <td>0.048795</td>\n",
              "      <td>-0.375000</td>\n",
              "      <td>1.204159</td>\n",
              "      <td>0.606250</td>\n",
              "      <td>0.598049</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>0.478714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64</td>\n",
              "      <td>0.005800</td>\n",
              "      <td>1.415179</td>\n",
              "      <td>1.058758</td>\n",
              "      <td>103.562500</td>\n",
              "      <td>83.000000</td>\n",
              "      <td>112.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>103.562500</td>\n",
              "      <td>83.000000</td>\n",
              "      <td>112.000000</td>\n",
              "      <td>0.028849</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-2.125000</td>\n",
              "      <td>0.806226</td>\n",
              "      <td>0.727679</td>\n",
              "      <td>0.543026</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.403113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>0.003300</td>\n",
              "      <td>1.792907</td>\n",
              "      <td>1.220115</td>\n",
              "      <td>98.500000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>120.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>98.500000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>120.000000</td>\n",
              "      <td>0.016320</td>\n",
              "      <td>0.982143</td>\n",
              "      <td>0.048795</td>\n",
              "      <td>-1.250000</td>\n",
              "      <td>1.437591</td>\n",
              "      <td>0.560764</td>\n",
              "      <td>0.551491</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.516398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66</td>\n",
              "      <td>0.003700</td>\n",
              "      <td>4.116667</td>\n",
              "      <td>0.968584</td>\n",
              "      <td>73.750000</td>\n",
              "      <td>66.000000</td>\n",
              "      <td>85.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>73.750000</td>\n",
              "      <td>66.000000</td>\n",
              "      <td>85.000000</td>\n",
              "      <td>0.018380</td>\n",
              "      <td>0.962500</td>\n",
              "      <td>0.080623</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>1.483240</td>\n",
              "      <td>0.654167</td>\n",
              "      <td>0.622049</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.447214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>67</td>\n",
              "      <td>0.004900</td>\n",
              "      <td>3.056250</td>\n",
              "      <td>1.400765</td>\n",
              "      <td>90.937500</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>112.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>90.937500</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>112.000000</td>\n",
              "      <td>0.024720</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.437500</td>\n",
              "      <td>1.860779</td>\n",
              "      <td>0.681250</td>\n",
              "      <td>0.481687</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.403113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>68</td>\n",
              "      <td>0.003500</td>\n",
              "      <td>3.055804</td>\n",
              "      <td>1.420774</td>\n",
              "      <td>92.062500</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>111.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>92.062500</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>111.000000</td>\n",
              "      <td>0.017433</td>\n",
              "      <td>0.882440</td>\n",
              "      <td>0.427818</td>\n",
              "      <td>-0.375000</td>\n",
              "      <td>1.543805</td>\n",
              "      <td>0.673363</td>\n",
              "      <td>0.432870</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.341565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>69</td>\n",
              "      <td>0.007300</td>\n",
              "      <td>4.275000</td>\n",
              "      <td>1.072288</td>\n",
              "      <td>70.187500</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>70.187500</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>0.036371</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>1.454877</td>\n",
              "      <td>0.837500</td>\n",
              "      <td>0.262996</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.403113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.006500</td>\n",
              "      <td>2.484375</td>\n",
              "      <td>1.551325</td>\n",
              "      <td>76.625000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>113.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>76.625000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>113.000000</td>\n",
              "      <td>0.032677</td>\n",
              "      <td>0.799851</td>\n",
              "      <td>0.319563</td>\n",
              "      <td>-0.562500</td>\n",
              "      <td>2.250000</td>\n",
              "      <td>0.622024</td>\n",
              "      <td>0.452579</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>71</td>\n",
              "      <td>0.000800</td>\n",
              "      <td>3.177827</td>\n",
              "      <td>1.101045</td>\n",
              "      <td>92.062500</td>\n",
              "      <td>83.000000</td>\n",
              "      <td>138.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>92.062500</td>\n",
              "      <td>83.000000</td>\n",
              "      <td>138.000000</td>\n",
              "      <td>0.003767</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.125000</td>\n",
              "      <td>1.746425</td>\n",
              "      <td>0.552827</td>\n",
              "      <td>0.546288</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.447214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>0.002900</td>\n",
              "      <td>2.824256</td>\n",
              "      <td>0.852127</td>\n",
              "      <td>81.375000</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>101.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>81.375000</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>101.000000</td>\n",
              "      <td>0.014730</td>\n",
              "      <td>0.973214</td>\n",
              "      <td>0.057588</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>1.632993</td>\n",
              "      <td>0.851042</td>\n",
              "      <td>0.215120</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.516398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>73</td>\n",
              "      <td>0.003400</td>\n",
              "      <td>3.441761</td>\n",
              "      <td>0.939557</td>\n",
              "      <td>82.687500</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>131.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>82.687500</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>131.000000</td>\n",
              "      <td>0.017186</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>2.909754</td>\n",
              "      <td>0.441761</td>\n",
              "      <td>0.597744</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.447214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>74</td>\n",
              "      <td>0.002900</td>\n",
              "      <td>2.689608</td>\n",
              "      <td>1.299237</td>\n",
              "      <td>87.312500</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>87.312500</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>0.014390</td>\n",
              "      <td>0.976562</td>\n",
              "      <td>0.067988</td>\n",
              "      <td>-0.187500</td>\n",
              "      <td>2.344319</td>\n",
              "      <td>0.275546</td>\n",
              "      <td>0.740160</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>0.001900</td>\n",
              "      <td>3.063839</td>\n",
              "      <td>1.185455</td>\n",
              "      <td>75.687500</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>93.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>75.687500</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>93.000000</td>\n",
              "      <td>0.009596</td>\n",
              "      <td>0.957589</td>\n",
              "      <td>0.079560</td>\n",
              "      <td>-0.312500</td>\n",
              "      <td>1.400893</td>\n",
              "      <td>0.793750</td>\n",
              "      <td>0.250989</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>76</td>\n",
              "      <td>0.006100</td>\n",
              "      <td>1.996528</td>\n",
              "      <td>0.968369</td>\n",
              "      <td>97.187500</td>\n",
              "      <td>74.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>97.187500</td>\n",
              "      <td>74.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>0.030377</td>\n",
              "      <td>0.890625</td>\n",
              "      <td>0.437500</td>\n",
              "      <td>-1.250000</td>\n",
              "      <td>1.843909</td>\n",
              "      <td>0.730903</td>\n",
              "      <td>0.429101</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>77</td>\n",
              "      <td>0.001700</td>\n",
              "      <td>2.559375</td>\n",
              "      <td>0.876401</td>\n",
              "      <td>93.500000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>112.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>93.500000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>112.000000</td>\n",
              "      <td>0.008504</td>\n",
              "      <td>0.984375</td>\n",
              "      <td>0.042696</td>\n",
              "      <td>-0.812500</td>\n",
              "      <td>2.257395</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.136626</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.437500</td>\n",
              "      <td>0.512348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>78</td>\n",
              "      <td>0.004000</td>\n",
              "      <td>2.474405</td>\n",
              "      <td>0.906332</td>\n",
              "      <td>84.625000</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>84.625000</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>0.020089</td>\n",
              "      <td>0.955357</td>\n",
              "      <td>0.100593</td>\n",
              "      <td>-0.687500</td>\n",
              "      <td>2.914761</td>\n",
              "      <td>0.644048</td>\n",
              "      <td>0.676006</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>0.512348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>79</td>\n",
              "      <td>0.004800</td>\n",
              "      <td>1.289310</td>\n",
              "      <td>0.567504</td>\n",
              "      <td>89.500000</td>\n",
              "      <td>58.000000</td>\n",
              "      <td>112.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>89.500000</td>\n",
              "      <td>58.000000</td>\n",
              "      <td>112.000000</td>\n",
              "      <td>0.024051</td>\n",
              "      <td>0.794271</td>\n",
              "      <td>0.446558</td>\n",
              "      <td>-1.437500</td>\n",
              "      <td>2.096624</td>\n",
              "      <td>0.620040</td>\n",
              "      <td>0.446047</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.312500</td>\n",
              "      <td>0.478714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.003300</td>\n",
              "      <td>2.320189</td>\n",
              "      <td>1.643968</td>\n",
              "      <td>94.187500</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>169.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>94.187500</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>169.000000</td>\n",
              "      <td>0.016511</td>\n",
              "      <td>0.964286</td>\n",
              "      <td>0.110657</td>\n",
              "      <td>-0.625000</td>\n",
              "      <td>1.310216</td>\n",
              "      <td>0.543403</td>\n",
              "      <td>0.533066</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.437500</td>\n",
              "      <td>0.512348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>81</td>\n",
              "      <td>0.004300</td>\n",
              "      <td>3.364732</td>\n",
              "      <td>1.003095</td>\n",
              "      <td>82.187500</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>101.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>82.187500</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>101.000000</td>\n",
              "      <td>0.021653</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.250000</td>\n",
              "      <td>1.949359</td>\n",
              "      <td>0.739732</td>\n",
              "      <td>0.569060</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.341565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>82</td>\n",
              "      <td>0.002400</td>\n",
              "      <td>2.975893</td>\n",
              "      <td>1.519558</td>\n",
              "      <td>84.750000</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>102.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>84.750000</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>102.000000</td>\n",
              "      <td>0.012235</td>\n",
              "      <td>0.969643</td>\n",
              "      <td>0.066368</td>\n",
              "      <td>-0.250000</td>\n",
              "      <td>1.653280</td>\n",
              "      <td>0.631250</td>\n",
              "      <td>0.665050</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>83</td>\n",
              "      <td>0.005100</td>\n",
              "      <td>2.055804</td>\n",
              "      <td>1.687875</td>\n",
              "      <td>92.562500</td>\n",
              "      <td>83.000000</td>\n",
              "      <td>112.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>92.562500</td>\n",
              "      <td>83.000000</td>\n",
              "      <td>112.000000</td>\n",
              "      <td>0.025302</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.562500</td>\n",
              "      <td>1.504161</td>\n",
              "      <td>0.180804</td>\n",
              "      <td>0.526961</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.437500</td>\n",
              "      <td>0.512348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>84</td>\n",
              "      <td>0.002700</td>\n",
              "      <td>2.604911</td>\n",
              "      <td>1.207292</td>\n",
              "      <td>90.062500</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>90.062500</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>0.013380</td>\n",
              "      <td>0.946429</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>-0.625000</td>\n",
              "      <td>2.061553</td>\n",
              "      <td>0.783482</td>\n",
              "      <td>0.356540</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.516398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>85</td>\n",
              "      <td>0.005800</td>\n",
              "      <td>3.373809</td>\n",
              "      <td>1.190434</td>\n",
              "      <td>91.875000</td>\n",
              "      <td>74.000000</td>\n",
              "      <td>146.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>91.875000</td>\n",
              "      <td>74.000000</td>\n",
              "      <td>146.000000</td>\n",
              "      <td>0.029214</td>\n",
              "      <td>0.910714</td>\n",
              "      <td>0.357143</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.632993</td>\n",
              "      <td>0.713095</td>\n",
              "      <td>0.566079</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.447214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>86</td>\n",
              "      <td>0.007400</td>\n",
              "      <td>2.737202</td>\n",
              "      <td>1.327922</td>\n",
              "      <td>86.625000</td>\n",
              "      <td>75.000000</td>\n",
              "      <td>103.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>86.625000</td>\n",
              "      <td>75.000000</td>\n",
              "      <td>103.000000</td>\n",
              "      <td>0.036924</td>\n",
              "      <td>0.940476</td>\n",
              "      <td>0.176897</td>\n",
              "      <td>-0.375000</td>\n",
              "      <td>1.784190</td>\n",
              "      <td>0.734226</td>\n",
              "      <td>0.554932</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.437500</td>\n",
              "      <td>0.512348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>87</td>\n",
              "      <td>0.001700</td>\n",
              "      <td>3.672321</td>\n",
              "      <td>1.557652</td>\n",
              "      <td>87.625000</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>102.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>87.625000</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>102.000000</td>\n",
              "      <td>0.008384</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>1.437591</td>\n",
              "      <td>0.609821</td>\n",
              "      <td>0.559804</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.403113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>88</td>\n",
              "      <td>0.007000</td>\n",
              "      <td>2.713542</td>\n",
              "      <td>1.697092</td>\n",
              "      <td>92.875000</td>\n",
              "      <td>55.000000</td>\n",
              "      <td>105.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>92.875000</td>\n",
              "      <td>55.000000</td>\n",
              "      <td>105.000000</td>\n",
              "      <td>0.034964</td>\n",
              "      <td>0.947917</td>\n",
              "      <td>0.169080</td>\n",
              "      <td>-0.562500</td>\n",
              "      <td>1.504161</td>\n",
              "      <td>0.765625</td>\n",
              "      <td>0.495553</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>0.512348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>89</td>\n",
              "      <td>0.005800</td>\n",
              "      <td>3.151786</td>\n",
              "      <td>1.224396</td>\n",
              "      <td>79.750000</td>\n",
              "      <td>74.000000</td>\n",
              "      <td>93.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>79.750000</td>\n",
              "      <td>74.000000</td>\n",
              "      <td>93.000000</td>\n",
              "      <td>0.028900</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>0.056928</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>1.707825</td>\n",
              "      <td>0.235119</td>\n",
              "      <td>0.727108</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>0.512348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.003800</td>\n",
              "      <td>4.144643</td>\n",
              "      <td>0.094939</td>\n",
              "      <td>76.375000</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>92.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>76.375000</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>92.000000</td>\n",
              "      <td>0.019069</td>\n",
              "      <td>0.991071</td>\n",
              "      <td>0.035714</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>1.504161</td>\n",
              "      <td>0.903571</td>\n",
              "      <td>0.182760</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>0.478714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>91</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>3.799107</td>\n",
              "      <td>0.723214</td>\n",
              "      <td>70.625000</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>93.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>70.625000</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>93.000000</td>\n",
              "      <td>0.004944</td>\n",
              "      <td>0.906250</td>\n",
              "      <td>0.201556</td>\n",
              "      <td>1.062500</td>\n",
              "      <td>1.436141</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.645761</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>0.478714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>92</td>\n",
              "      <td>0.009000</td>\n",
              "      <td>2.697917</td>\n",
              "      <td>1.385908</td>\n",
              "      <td>75.187500</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>103.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>75.187500</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>103.000000</td>\n",
              "      <td>0.045200</td>\n",
              "      <td>0.921875</td>\n",
              "      <td>0.176039</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>1.505545</td>\n",
              "      <td>0.588542</td>\n",
              "      <td>0.652253</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>0.478714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>93</td>\n",
              "      <td>0.005300</td>\n",
              "      <td>2.376935</td>\n",
              "      <td>1.186289</td>\n",
              "      <td>86.125000</td>\n",
              "      <td>74.000000</td>\n",
              "      <td>106.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>86.125000</td>\n",
              "      <td>74.000000</td>\n",
              "      <td>106.000000</td>\n",
              "      <td>0.026512</td>\n",
              "      <td>0.989583</td>\n",
              "      <td>0.041667</td>\n",
              "      <td>-0.875000</td>\n",
              "      <td>1.408309</td>\n",
              "      <td>0.512351</td>\n",
              "      <td>0.570846</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.447214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>94</td>\n",
              "      <td>0.005200</td>\n",
              "      <td>2.780655</td>\n",
              "      <td>1.522337</td>\n",
              "      <td>82.437500</td>\n",
              "      <td>74.000000</td>\n",
              "      <td>101.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>82.437500</td>\n",
              "      <td>74.000000</td>\n",
              "      <td>101.000000</td>\n",
              "      <td>0.026228</td>\n",
              "      <td>0.989583</td>\n",
              "      <td>0.041667</td>\n",
              "      <td>-0.187500</td>\n",
              "      <td>1.833712</td>\n",
              "      <td>0.478571</td>\n",
              "      <td>0.607230</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.516398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>95</td>\n",
              "      <td>0.005000</td>\n",
              "      <td>4.022223</td>\n",
              "      <td>0.981461</td>\n",
              "      <td>96.125000</td>\n",
              "      <td>84.000000</td>\n",
              "      <td>122.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>96.125000</td>\n",
              "      <td>84.000000</td>\n",
              "      <td>122.000000</td>\n",
              "      <td>0.024888</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.437500</td>\n",
              "      <td>1.998958</td>\n",
              "      <td>0.772222</td>\n",
              "      <td>0.526656</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.403113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>96</td>\n",
              "      <td>0.002500</td>\n",
              "      <td>4.475000</td>\n",
              "      <td>0.631708</td>\n",
              "      <td>73.437500</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>94.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>73.437500</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>94.000000</td>\n",
              "      <td>0.012512</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.187500</td>\n",
              "      <td>1.470544</td>\n",
              "      <td>0.537500</td>\n",
              "      <td>0.558420</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.447214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>97</td>\n",
              "      <td>0.003200</td>\n",
              "      <td>2.414286</td>\n",
              "      <td>1.559533</td>\n",
              "      <td>81.625000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>125.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>81.625000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>125.000000</td>\n",
              "      <td>0.015990</td>\n",
              "      <td>0.944643</td>\n",
              "      <td>0.153142</td>\n",
              "      <td>-0.562500</td>\n",
              "      <td>1.711481</td>\n",
              "      <td>0.344643</td>\n",
              "      <td>0.702433</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>0.478714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>98</td>\n",
              "      <td>0.003300</td>\n",
              "      <td>2.722619</td>\n",
              "      <td>1.301744</td>\n",
              "      <td>84.875000</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>103.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>84.875000</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>103.000000</td>\n",
              "      <td>0.016539</td>\n",
              "      <td>0.991071</td>\n",
              "      <td>0.035714</td>\n",
              "      <td>-0.437500</td>\n",
              "      <td>1.750000</td>\n",
              "      <td>0.419048</td>\n",
              "      <td>0.687485</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.447214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>99</td>\n",
              "      <td>0.004100</td>\n",
              "      <td>0.744420</td>\n",
              "      <td>1.229113</td>\n",
              "      <td>100.437500</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>143.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>100.437500</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>143.000000</td>\n",
              "      <td>0.020455</td>\n",
              "      <td>0.981771</td>\n",
              "      <td>0.050389</td>\n",
              "      <td>-2.125000</td>\n",
              "      <td>1.668333</td>\n",
              "      <td>0.575149</td>\n",
              "      <td>0.435801</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.312500</td>\n",
              "      <td>0.478714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.003700</td>\n",
              "      <td>2.107143</td>\n",
              "      <td>1.288216</td>\n",
              "      <td>98.125000</td>\n",
              "      <td>83.000000</td>\n",
              "      <td>112.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>98.125000</td>\n",
              "      <td>83.000000</td>\n",
              "      <td>112.000000</td>\n",
              "      <td>0.018319</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.875000</td>\n",
              "      <td>1.543805</td>\n",
              "      <td>0.294643</td>\n",
              "      <td>0.532601</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>0.478714</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"e\" are there in the word \"sapphire\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of e's in the word sphatherp\n",
            "1. s - 0 so far\n",
            "2. p - 0 so far\n",
            "3. h - 0 so far\n",
            "4. a - 0 so far\n",
            "5. r - 0 so far\n",
            "6. a - 1 so far\n",
            "7. p - 1 so far\n",
            "8. h - 1 so far\n",
            "9. y - 1 so far\n",
            "10. e - 2 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "Extracted: 2\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"p\" are there in the word \"absolve\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of p's in the word absolve\n",
            "1. a - 0 so far\n",
            "2. b - 0 so far\n",
            "3. p - 1 so far\n",
            "4. s - 1 so far\n",
            "5. l - 1 so far\n",
            "6. o - 1 so far\n",
            "7. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"g\" are there in the word \"mirage\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. m - 0 so far\n",
            "2. i - 1 so far\n",
            "3. r - 1 so far\n",
            "4. a - 2 so far\n",
            "5. g - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"r\" are there in the word \"crave\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of r's in the word crave\n",
            "1. c - 0 so far\n",
            "2. r - 1 so far\n",
            "3. a - 1 so far\n",
            "4. v - 1 so far\n",
            "5. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"a\" are there in the word \"frescos\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of a's in the word frescos\n",
            "1. f - 0 so far\n",
            "2. r - 0 so far\n",
            "3. e - 0 so far\n",
            "4. s - 0 so far\n",
            "5. c - 0 so far\n",
            "6. o - 0 so far\n",
            "7. s - 0 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "0\n",
            "</answer>\n",
            "Extracted: 0\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"v\" are there in the word \"absolve\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of v's in the word abslove\n",
            "1. a - 0 so far\n",
            "2. b - 0 so far\n",
            "3. s - 1 so far\n",
            "4. l - 1 so far\n",
            "5. e - 2 so far\n",
            "6. v - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"i\" are there in the word \"eclipse\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of i's in the word eclipse\n",
            "1. e - 1 so far\n",
            "2. l - 0 so far (no 'l' after the first 'e')\n",
            "3. c - 0 so far (no 'c' after the letter 'l')\n",
            "4. p - 0 so far (no 'p' after the letter 'c')\n",
            "5. l - 1 so far\n",
            "6. e - 2 so far (two 'e's before the last 'i')\n",
            "7. s - 0 so far (no 's' after the letter 'e')\n",
            "8. c - 1 so far\n",
            "9. e - 3 so far\n",
            "10. a - 0 so far (no 'a' after the letter 'c')\n",
            "11. i - 4 so far (the first 'i' after the last 'a')\n",
            "</reasoning>\n",
            "<answer>\n",
            "4\n",
            "</answer>\n",
            "Extracted: 4\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"e\" are there in the word \"echo\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of e's in the word echo\n",
            "1. e - 1 so far\n",
            "2. c - 1 so far\n",
            "3. h - 1 so far\n",
            "4. e - 2 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "Extracted: 2\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"d\" are there in the word \"void\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of d's in the word void\n",
            "1. o - 0 so far\n",
            "2. u - 1 so far\n",
            "3. i - 2 so far\n",
            "4. d - 3 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "3\n",
            "</answer>\n",
            "Extracted: 3\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"o\" are there in the word \"ivory\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of o's in the word ivory\n",
            "1. i - 1 so far\n",
            "2. o - 1 so far\n",
            "3. o - 1 + 1 from previous count = 2 so far\n",
            "4. v - 2 so far\n",
            "5. i - 2 so far\n",
            "6. o - 2 + 1 from previous count = 3 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "3\n",
            "</answer>\n",
            "Extracted: 3\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"p\" are there in the word \"aperture\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of p's in the word \"aperture\"\n",
            "1. a - 0 so far\n",
            "2. p - 1 so far\n",
            "3. p - 1 (total so far: 1 + 1 = 2)\n",
            "4. r - 2 so far\n",
            "5. t - 3 so far\n",
            "6. e - 4 so far\n",
            "7. a - 4 (total so far: 4 + 1 = 5)\n",
            "8. p - 5 (total so far: 5 + 1 = 6)\n",
            "9. e - 6 so far\n",
            "10. r - 6 (total so far: 6 + 1 = 7)\n",
            "11. u - 7 so far\n",
            "12. t - 7 (total so far: 7 + 1 = 8)\n",
            "</reasoning>\n",
            "<answer>\n",
            "8\n",
            "</answer>\n",
            "Extracted: 8\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"m\" are there in the word \"fume\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of m's in the word fume\n",
            "1. f - 0 so far\n",
            "2. u - 1 so far\n",
            "3. m - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"c\" are there in the word \"crave\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of c's in the word crave\n",
            "1. c - 1 so far\n",
            "2. r - 0 so far\n",
            "3. a - 0 so far\n",
            "4. v - 0 so far\n",
            "5. e - 0 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"f\" are there in the word \"frescos\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of f's in the word frescos\n",
            "1. f - 1 so far\n",
            "2. r - 1 so far\n",
            "3. e - 1 so far\n",
            "4. s - 1 so far\n",
            "5. c - 1 so far\n",
            "6. o - 1 so far\n",
            "7. s - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"b\" are there in the word \"banner\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of b's in the word banner\n",
            "1. b - 1 so far\n",
            "2. a - 1 so far\n",
            "3. n - 1 so far\n",
            "4. a - 2 so far\n",
            "5. n - 3 so far\n",
            "6. r - 3 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "3\n",
            "</answer>\n",
            "Extracted: 3\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"j\" are there in the word \"capture\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of j's in the word capture\n",
            "1. c - 0 so far\n",
            "2. a - 1 so far\n",
            "3. p - 0 so far\n",
            "4. u - 1 so far\n",
            "5. r - 0 so far\n",
            "6. a - 2 so far\n",
            "7. c - 1 so far\n",
            "8. e - 2 so far\n",
            "9. j - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"p\" are there in the word \"sphinx\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of p's in the word sphinx\n",
            "1. s - 0 so far\n",
            "2. p - 1 so far\n",
            "3. h - 1 so far\n",
            "4. n - 1 so far\n",
            "5. f - 1 so far\n",
            "6. x - 1 so far\n",
            "7. p - 2 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "Extracted: 2\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"k\" are there in the word \"knack\"\n",
            "Answer: 2\n",
            "Response: <reasoning>\n",
            "Counting the number of k's in the word knack\n",
            "1. k - 1 so far\n",
            "2. n - 1 still, because the first 'k' is already counted\n",
            "3. k - 2 still, because the second 'k' is part of the count\n",
            "4. c - 2 still, because the 'k' was already counted\n",
            "5. k - 3 still, because the third 'k' is part of the count\n",
            "</reasoning>\n",
            "<answer>\n",
            "3\n",
            "</answer>\n",
            "Extracted: 3\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"r\" are there in the word \"relish\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of r's in the word relish\n",
            "1. r - 1 so far\n",
            "2. e - 1 so far\n",
            "3. l - 1 so far\n",
            "4. i - 1 so far\n",
            "5. s - 1 so far\n",
            "6. h - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"g\" are there in the word \"zealous\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of g's in the word zealous\n",
            "1. z - 0 so far\n",
            "2. e - 0 so far\n",
            "3. a - 0 so far\n",
            "4. l - 0 so far\n",
            "5. a - 1 so far\n",
            "6. s - 1 so far\n",
            "7. e - 2 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "Extracted: 2\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"g\" are there in the word \"idea\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of g's in the word idea\n",
            "1. i - 0 so far\n",
            "2. d - 0 so far\n",
            "3. e - 0 so far\n",
            "4. a - 0 so far\n",
            "5. g - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"t\" are there in the word \"tavern\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of t's in the word tavern\n",
            "1. t - 1 so far\n",
            "2. a - 1 so far\n",
            "3. v - 1 so far\n",
            "4. a - 2 so far\n",
            "5. r - 2 so far\n",
            "6. n - 3 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "3\n",
            "</answer>\n",
            "Extracted: 3\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"s\" are there in the word \"sapphire\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of s's in the word sapphire\n",
            "1. p - 0 so far\n",
            "2. a - 1 so far\n",
            "3. f - 2 so far\n",
            "4. a - 3 so far\n",
            "5. p - 4 so far\n",
            "6. h - 5 so far\n",
            "7. y - 6 so far\n",
            "So there are 2 's' in the word \"sapphire\".\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "Extracted: 2\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"a\" are there in the word \"mantle\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of a's in the word mantle\n",
            "1. m - 0 so far\n",
            "2. a - 1 so far\n",
            "3. n - 1 so far\n",
            "4. t - 1 so far\n",
            "5. l - 1 so far\n",
            "6. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"i\" are there in the word \"whistle\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of i's in the word whistle\n",
            "1. w - 0 so far\n",
            "2. h - 0 so far\n",
            "3. w - 1 so far\n",
            "4. i - 1 so far\n",
            "5. s - 1 so far\n",
            "6. t - 1 so far\n",
            "7. l - 1 so far\n",
            "8. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"f\" are there in the word \"torrent\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of f's in the word \"torrent\"\n",
            "1. t - 1 so far\n",
            "2. o - 0 so far\n",
            "3. r - 0 so far\n",
            "4. o - 0 so far\n",
            "5. t - 0 so far\n",
            "6. a - 0 so far\n",
            "7. n - 0 so far\n",
            "8. e - 0 so far\n",
            "9. r - 0 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "0\n",
            "</answer>\n",
            "Extracted: 0\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"w\" are there in the word \"brawn\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of w's in the word brawn\n",
            "1. b - 0 so far\n",
            "2. w - 1 so far\n",
            "3. w - 1 (plus the previous count) so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "Extracted: 2\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"m\" are there in the word \"fathom\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of m's in the word fathom\n",
            "1. m - 1 so far\n",
            "2. o - 1 so far\n",
            "3. m - 2 so far\n",
            "4. a - 2 so far\n",
            "5. m - 3 so far\n",
            "6. t - 3 so far\n",
            "7. h - 3 so far\n",
            "8. o - 4 so far\n",
            "9. m - 5 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "5\n",
            "</answer>\n",
            "Extracted: 5\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"m\" are there in the word \"echo\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of m's in the word echo\n",
            "1. e - 0 so far\n",
            "2. c - 0 so far\n",
            "3. h - 0 so far\n",
            "4. o - 0 so far\n",
            "5. c - 0 so far\n",
            "6. e - 0 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "0\n",
            "</answer>\n",
            "Extracted: 0\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"n\" are there in the word \"enchant\"\n",
            "Answer: 2\n",
            "Response: <reasoning>\n",
            "Counting the number of n's in the word enchant\n",
            "1. e - 0 so far\n",
            "2. n - 1 so far\n",
            "3. a - 1 so far\n",
            "4. n - 2 so far\n",
            "5. t - 2 so far\n",
            "6. c - 2 so far\n",
            "7. h - 2 so far\n",
            "8. n - 3 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "3\n",
            "</answer>\n",
            "Extracted: 3\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"h\" are there in the word \"lush\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of h's in the word lush\n",
            "1. l - 0 so far\n",
            "2. u - 0 so far\n",
            "3. s - 0 so far\n",
            "4. h - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"n\" are there in the word \"fusion\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of n's in the word fusion\n",
            "1. f - 0 so far\n",
            "2. u - 0 so far\n",
            "3. n - 1 so far\n",
            "4. i - 0 so far\n",
            "5. o - 0 so far\n",
            "6. s - 0 so far\n",
            "7. u - 0 so far\n",
            "8. n - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "Extracted: 2\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"d\" are there in the word \"maze\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of d's in the word maze\n",
            "1. m - 0 so far\n",
            "2. a - 1 so far\n",
            "3. z - 2 so far\n",
            "4. e - 3 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"t\" are there in the word \"onset\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of t's in the word onset\n",
            "1. o - 0 so far\n",
            "2. n - 0 so far\n",
            "3. s - 0 so far\n",
            "4. e - 0 so far\n",
            "5. t - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"o\" are there in the word \"veto\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of o's in the word \"veto\"\n",
            "1. v - 0 so far\n",
            "2. e - 0 so far\n",
            "3. t - 0 so far\n",
            "4. o - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"y\" are there in the word \"ivory\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of y's in the word ivory\n",
            "1. i - 0 so far\n",
            "2. o - 1 so far\n",
            "3. r - 1 so far\n",
            "4. v - 2 so far\n",
            "5. y - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"n\" are there in the word \"torrent\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of n's in the word torrent\n",
            "1. t - 1 so far\n",
            "2. o - 0 so far\n",
            "3. r - 0 so far\n",
            "4. o - 0 so far\n",
            "5. v - 0 so far\n",
            "6. e - 0 so far\n",
            "7. n - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"e\" are there in the word \"whistle\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of e's in the word whistle\n",
            "1. w - 0 so far\n",
            "2. h - 0 so far\n",
            "3. i - 0 so far\n",
            "4. s - 0 so far\n",
            "5. t - 0 so far\n",
            "6. e - 0 so far\n",
            "7. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"p\" are there in the word \"resolve\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of p's in the word resolve\n",
            "1. l - 0 so far\n",
            "2. o - 1 so far\n",
            "3. v - 1 so far\n",
            "4. e - 1 (first occurrence) + 1 (second occurrence) = 2 so far\n",
            "5. s - 2 so far\n",
            "6. e - 2 (first occurrence) + 1 (second occurrence) = 3 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "3\n",
            "</answer>\n",
            "Extracted: 3\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"i\" are there in the word \"mirage\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of i's in the word \"mirage\"\n",
            "1. m - 0 so far\n",
            "2. i - 1 so far\n",
            "3. r - 0 so far\n",
            "4. a - 1 so far\n",
            "5. g - 0 so far\n",
            "6. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "Extracted: 2\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"r\" are there in the word \"lunar\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of r's in the word lunar\n",
            "1. l - 0 so far\n",
            "2. u - 0 so far\n",
            "3. a - 0 so far\n",
            "4. n - 0 so far\n",
            "5. v - 0 so far\n",
            "6. r - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"i\" are there in the word \"sapphire\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of i's in the word \"sapphire\"\n",
            "1. s - 0 so far\n",
            "2. a - 1 so far\n",
            "3. p - 1 so far\n",
            "4. a - 2 so far\n",
            "5. p - 3 so far\n",
            "6. h - 3 so far\n",
            "7. a - 4 so far\n",
            "8. y - 4 so far\n",
            "9. e - 4 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "4\n",
            "</answer>\n",
            "Extracted: 4\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"t\" are there in the word \"mantle\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of t's in the word mantle\n",
            "1. m - 0 so far\n",
            "2. a - 0 so far\n",
            "3. n - 0 so far\n",
            "4. t - 1 so far\n",
            "5. l - 0 so far\n",
            "6. e - 0 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"p\" are there in the word \"sapphire\"\n",
            "Answer: 2\n",
            "Response: <reasoning>\n",
            "Counting the number of p's in the word \"sapphire\"\n",
            "1. s - 0 so far\n",
            "2. a - 0 so far\n",
            "3. p - 1 so far\n",
            "4. a - 1 so far\n",
            "5. p - 2 so far\n",
            "6. a - 2 so far\n",
            "7. y - 2 so far\n",
            "8. p - 3 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "3\n",
            "</answer>\n",
            "Extracted: 3\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"r\" are there in the word \"ivory\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of r's in the word ivory\n",
            "1. i - 0 so far\n",
            "2. v - 0 so far\n",
            "3. r - 0 so far\n",
            "4. r - 1 so far\n",
            "5. v - 1 so far\n",
            "6. y - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"i\" are there in the word \"triumph\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of i's in the word triumph\n",
            "1. t - 0 so far\n",
            "2. r - 0 so far\n",
            "3. u - 0 so far\n",
            "4. i - 0 so far\n",
            "5. m - 0 so far\n",
            "6. p - 0 so far\n",
            "7. h - 0 so far\n",
            "8. o - 0 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"s\" are there in the word \"zealous\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of s's in the word \"zealous\"\n",
            "1. z - 0 so far\n",
            "2. e - 0 so far\n",
            "3. a - 0 so far\n",
            "4. l - 0 so far\n",
            "5. o - 0 so far\n",
            "6. s - 0 so far\n",
            "7. s - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"e\" are there in the word \"verge\"\n",
            "Answer: 2\n",
            "Response: <reasoning>\n",
            "Counting the number of e's in the word \"verge\"\n",
            "1. v - 0 so far\n",
            "2. e - 1 so far\n",
            "3. r - 1 so far\n",
            "4. g - 1 so far\n",
            "5. e - 2 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "Extracted: 2\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"r\" are there in the word \"onset\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of r's in the word onset\n",
            "1. o - 0 so far\n",
            "2. n - 0 so far\n",
            "3. s - 0 so far\n",
            "4. o - 1 so far\n",
            "5. n - 1 so far\n",
            "6. t - 1 so far\n",
            "7. e - 1 so far\n",
            "8. s - 2 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "Extracted: 2\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"c\" are there in the word \"crisp\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of c's in the word crisp\n",
            "1. c - 1 so far\n",
            "2. r - 1 so far\n",
            "3. r - 1 so far\n",
            "4. i - 1 so far\n",
            "5. s - 1 so far\n",
            "6. p - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"p\" are there in the word \"lantern\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of p's in the word lantern\n",
            "1. l - 0 so far\n",
            "2. a - 0 so far\n",
            "3. n - 0 so far\n",
            "4. e - 0 so far\n",
            "5. t - 0 so far\n",
            "6. r - 0 so far\n",
            "7. a - 0 so far\n",
            "8. n - 0 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "0\n",
            "</answer>\n",
            "Extracted: 0\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"w\" are there in the word \"fusion\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of w's in the word fusion\n",
            "1. f - 0 so far\n",
            "2. u - 0 so far\n",
            "3. i - 0 so far\n",
            "4. s - 0 so far\n",
            "5. u - 1 so far\n",
            "6. n - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"o\" are there in the word \"onset\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of o's in the word \"onset\"\n",
            "1. o - 1 so far\n",
            "2. n - 1 so far\n",
            "3. o - 2 so far\n",
            "4. n - 2 so far\n",
            "5. s - 2 so far\n",
            "6. e - 2 so far\n",
            "7. t - 2 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "Extracted: 2\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"z\" are there in the word \"wisp\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of z's in the word wisp\n",
            "1. w - 0 so far\n",
            "2. i - 1 so far\n",
            "3. s - 1 so far\n",
            "4. p - 1 so far\n",
            "5. z - 0 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "0\n",
            "</answer>\n",
            "Extracted: 0\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"a\" are there in the word \"radius\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of a's in the word radius\n",
            "1. r - 0 so far\n",
            "2. a - 1 so far\n",
            "3. a - 1+1 = 2 so far\n",
            "4. s - 2 so far\n",
            "5. i - 2 so far\n",
            "6. d - 2 so far\n",
            "7. a - 2+1 = 3 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "3\n",
            "</answer>\n",
            "Extracted: 3\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"j\" are there in the word \"elude\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of j's in the word elude\n",
            "1. e - 0 so far\n",
            "2. l - 0 so far\n",
            "3. u - 0 so far\n",
            "4. d - 0 so far\n",
            "5. e - 0 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "0\n",
            "</answer>\n",
            "Extracted: 0\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"a\" are there in the word \"enchant\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. e - 0 so far\n",
            "2. n - 1 so far\n",
            "3. a - 1 so far\n",
            "4. c - 1 so far\n",
            "5. h - 1 so far\n",
            "6. t - 1 so far\n",
            "7. n - 2 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "Extracted: 2\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"h\" are there in the word \"orchard\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of h's in the word orchard\n",
            "1. o - 0 so far\n",
            "2. r - 0 so far\n",
            "3. a - 0 so far\n",
            "4. c - 0 so far\n",
            "5. h - 1 so far\n",
            "6. r - 1 so far\n",
            "7. d - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"m\" are there in the word \"maze\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of m's in the word \"maze\"\n",
            "1. m - 1 so far\n",
            "2. a - 1 so far (no additional m's)\n",
            "3. z - 1 so far (no additional m's)\n",
            "4. e - 1 so far (no additional m's)\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"e\" are there in the word \"mantle\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of e's in the word mantle\n",
            "1. m - 0 so far\n",
            "2. a - 0 so far\n",
            "3. n - 0 so far\n",
            "4. t - 0 so far\n",
            "5. l - 0 so far\n",
            "6. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"d\" are there in the word \"gossipy\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of d's in the word \"gossipy\"\n",
            "1. g - 0 so far\n",
            "2. o - 0 so far\n",
            "3. s - 0 so far\n",
            "4. s - 0 so far\n",
            "5. i - 0 so far\n",
            "6. p - 0 so far\n",
            "7. y - 0 so far\n",
            "8. y - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"l\" are there in the word \"ivory\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of l's in the word \"ivory\"\n",
            "1. i - 0 so far\n",
            "2. v - 0 so far\n",
            "3. o - 0 so far\n",
            "4. r - 0 so far\n",
            "5. y - 0 so far\n",
            "6. e - 0 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "0\n",
            "</answer>\n",
            "Extracted: 0\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"r\" are there in the word \"capture\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of r's in the word capture\n",
            "1. c - 0 so far\n",
            "2. a - 0 so far\n",
            "3. p - 0 so far\n",
            "4. r - 1 so far\n",
            "5. p - 1 so far\n",
            "6. a - 1 so far\n",
            "7. c - 1 so far\n",
            "8. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"e\" are there in the word \"prelude\"\n",
            "Answer: 2\n",
            "Response: <reasoning>\n",
            "Counting the number of e's in the word prelude\n",
            "1. p - 0 so far\n",
            "2. r - 0 so far\n",
            "3. e - 1 so far\n",
            "4. l - 1 so far\n",
            "5. u - 1 so far\n",
            "6. d - 1 so far\n",
            "7. e - 2 so far (including the previous e)\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "Extracted: 2\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"r\" are there in the word \"crisp\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of r's in the word crisp\n",
            "1. c - 0 so far\n",
            "2. r - 1 so far\n",
            "3. r - 2 so far\n",
            "4. s - 2 so far\n",
            "5. i - 2 so far\n",
            "6. p - 2 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "Extracted: 2\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"t\" are there in the word \"enchant\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of t's in the word enchant\n",
            "1. e - 0 so far\n",
            "2. n - 1 so far\n",
            "3. a - 1 so far\n",
            "4. c - 2 so far\n",
            "5. h - 3 so far\n",
            "6. n - 4 so far\n",
            "7. t - 4 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "4\n",
            "</answer>\n",
            "Extracted: 4\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"c\" are there in the word \"scarab\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of c's in the word scarab\n",
            "1. s - 0 so far\n",
            "2. c - 1 so far\n",
            "3. a - 1 so far (previous count + 1 since 'c' is found)\n",
            "4. r - 2 so far\n",
            "5. a - 3 so far\n",
            "6. b - 3 so far (previous count + 1 since 'a' is found)\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"a\" are there in the word \"oath\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of a's in the word \"oath\"\n",
            "1. o - 0 so far\n",
            "2. a - 1 so far (first a)\n",
            "3. t - 1 so far\n",
            "4. h - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"c\" are there in the word \"prelude\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of c's in the word \"prelude\"\n",
            "1. p - 0 so far\n",
            "2. r - 0 so far\n",
            "3. e - 0 so far\n",
            "4. l - 0 so far\n",
            "5. u - 0 so far\n",
            "6. d - 0 so far\n",
            "7. e - 0 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "0\n",
            "</answer>\n",
            "Extracted: 0\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"m\" are there in the word \"mantle\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of m's in the word mantle\n",
            "1. m - 1 so far\n",
            "2. a - 1 so far\n",
            "3. n - 1 so far\n",
            "4. t - 1 so far\n",
            "5. l - 1 so far\n",
            "6. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"d\" are there in the word \"grim\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of d's in the word \"grim\"\n",
            "1. g - 0 so far\n",
            "2. r - 0 so far\n",
            "3. i - 0 so far\n",
            "4. m - 0 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "0\n",
            "</answer>\n",
            "Extracted: 0\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"h\" are there in the word \"oath\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of h's in the word \"oath\"\n",
            "1. o - 0 so far\n",
            "2. a - 1 so far\n",
            "3. t - 1 so far\n",
            "4. h - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"e\" are there in the word \"aperture\"\n",
            "Answer: 2\n",
            "Response: <reasoning>\n",
            "Counting the number of e's in the word aperture\n",
            "1. a - 0 so far\n",
            "2. p - 0 so far\n",
            "3. a - 1 so far\n",
            "4. p - 1 so far\n",
            "5. t - 1 so far\n",
            "6. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"s\" are there in the word \"rust\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of s's in the word \"rust\"\n",
            "1. r - 0 so far\n",
            "2. u - 0 so far\n",
            "3. s - 1 so far\n",
            "4. t - 1 so far\n",
            "5. u - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"s\" are there in the word \"aperture\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of s's in the word aperture\n",
            "1. a - 0 so far\n",
            "2. p - 0 so far\n",
            "3. a - 0 so far\n",
            "4. p - 0 so far\n",
            "5. t - 0 so far\n",
            "6. e - 0 so far\n",
            "7. r - 0 so far\n",
            "8. e - 0 so far\n",
            "9. u - 0 so far\n",
            "10. r - 0 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"a\" are there in the word \"sapphire\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of a's in the word \"sapphire\"\n",
            "1. s - 0 so far\n",
            "2. a - 1 so far\n",
            "3. p - 1 so far\n",
            "4. a - 2 so far\n",
            "5. p - 2 so far\n",
            "6. h - 2 so far\n",
            "7. y - 2 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "Extracted: 2\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"t\" are there in the word \"torrent\"\n",
            "Answer: 2\n",
            "Response: <reasoning>\n",
            "Counting the number of t's in the word torrent\n",
            "1. t - 1 so far\n",
            "2. t - 1 + 1 so far\n",
            "3. t - 1 + 1 so far\n",
            "4. t - 1 + 1 so far\n",
            "5. t - 1 + 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "4\n",
            "</answer>\n",
            "Extracted: 4\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"n\" are there in the word \"mantle\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of n's in the word mantle\n",
            "1. m - 0 so far\n",
            "2. a - 0 so far\n",
            "3. n - 1 so far\n",
            "4. t - 0 so far\n",
            "5. l - 0 so far\n",
            "6. e - 0 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"o\" are there in the word \"gossipy\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of o's in the word \"gossipy\"\n",
            "1. g - 0 so far\n",
            "2. o - 1 so far\n",
            "3. s - 1 so far\n",
            "4. s - 2 so far\n",
            "5. o - 3 so far\n",
            "6. p - 3 so far\n",
            "7. y - 3 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "3\n",
            "</answer>\n",
            "Extracted: 3\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"a\" are there in the word \"veto\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of a's in the word veto\n",
            "1. v - 0 so far\n",
            "2. e - 0 so far\n",
            "3. t - 0 so far\n",
            "4. o - 0 so far\n",
            "5. v - 0 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "0\n",
            "</answer>\n",
            "Extracted: 0\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"i\" are there in the word \"sphinx\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of \"i\" in the word \"sphinx\"\n",
            "1. s - 0 so far\n",
            "2. n - 0 so far\n",
            "3. p - 0 so far\n",
            "4. f - 0 so far\n",
            "5. k - 0 so far\n",
            "6. x - 0 so far\n",
            "7. h - 0 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "0\n",
            "</answer>\n",
            "Extracted: 0\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"l\" are there in the word \"resolve\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of l's in the word resolve\n",
            "1. r - 0 so far\n",
            "2. o - 0 so far\n",
            "3. l - 1 so far\n",
            "4. v - 1 so far\n",
            "5. i - 1 so far\n",
            "6. e - 1 so far\n",
            "7. s - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"s\" are there in the word \"absolve\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of s's in the word \"absolve\"\n",
            "1. a - 0 so far\n",
            "2. b - 0 so far\n",
            "3. s - 1 so far\n",
            "4. l - 1 so far\n",
            "5. o - 1 so far\n",
            "6. v - 1 so far\n",
            "7. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"c\" are there in the word \"orchard\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of c's in the word orchard\n",
            "1. o - 0 so far\n",
            "2. r - 0 so far\n",
            "3. c - 1 so far\n",
            "4. h - 0 so far\n",
            "5. a - 1 so far\n",
            "6. r - 1 so far\n",
            "7. d - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"z\" are there in the word \"banner\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of z's in the word banner\n",
            "1. b - 0 so far\n",
            "2. a - 0 so far\n",
            "3. n - 0 so far\n",
            "4. a - 0 so far\n",
            "5. r - 0 so far\n",
            "6. e - 0 so far\n",
            "7. z - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"t\" are there in the word \"fathom\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of t's in the word fathom\n",
            "1. f - 0 so far\n",
            "2. t - 1 so far\n",
            "3. h - 1 so far\n",
            "4. m - 1 so far\n",
            "5. o - 1 so far\n",
            "6. a - 1 so far\n",
            "7. m - 2 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"p\" are there in the word \"triumph\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of p's in the word \"triumph\"\n",
            "1. t - 0 so far\n",
            "2. r - 0 so far\n",
            "3. i - 0 so far\n",
            "4. u - 0 so far\n",
            "5. m - 0 so far\n",
            "6. p - 1 so far\n",
            "7. h - 1 so far\n",
            "8. p - 2 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "Extracted: 2\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"e\" are there in the word \"elude\"\n",
            "Answer: 2\n",
            "Response: <reasoning>\n",
            "Counting the number of e's in the word elude\n",
            "1. e - 1 so far\n",
            "2. l - 0 so far\n",
            "3. u - 0 so far\n",
            "4. d - 0 so far\n",
            "5. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"e\" are there in the word \"quest\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of e's in the word quest\n",
            "1. q - 0 so far\n",
            "2. u - 0 so far\n",
            "3. e - 1 so far\n",
            "4. s - 1 so far\n",
            "5. t - 2 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"r\" are there in the word \"grim\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of r's in the word grim\n",
            "1. g - 0 so far\n",
            "2. r - 1 so far\n",
            "3. m - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"g\" are there in the word \"enchant\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of g's in the word enchant\n",
            "1. e - 0 so far\n",
            "2. n - 0 so far\n",
            "3. c - 0 so far\n",
            "4. h - 0 so far\n",
            "5. a - 0 so far\n",
            "6. n - 0 so far\n",
            "7. t - 0 so far\n",
            "8. g - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"i\" are there in the word \"fusion\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of i's in the word fusion\n",
            "1. f - 0 so far\n",
            "2. u - 0 so far\n",
            "3. i - 1 so far\n",
            "4. s - 1 so far\n",
            "5. u - 1 so far\n",
            "6. n - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"s\" are there in the word \"whistle\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of s's in the word whistle\n",
            "1. w - 0 so far\n",
            "2. h - 0 so far\n",
            "3. i - 0 so far\n",
            "4. s - 1 so far\n",
            "5. l - 1 so far\n",
            "6. l - 2 so far\n",
            "7. t - 2 so far\n",
            "8. e - 2 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "Extracted: 2\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"h\" are there in the word \"aperture\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of h's in the word aperture\n",
            "1. a - 0 so far\n",
            "2. p - 0 so far\n",
            "3. a - 1 so far\n",
            "4. p - 1 so far\n",
            "5. e - 1 so far\n",
            "6. t - 1 so far\n",
            "7. r - 1 so far\n",
            "8. u - 1 so far\n",
            "9. e - 2 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "Extracted: 2\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"w\" are there in the word \"glow\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of w's in the word glow\n",
            "1. g - 0 so far\n",
            "2. l - 1 so far\n",
            "3. o - 2 so far\n",
            "4. w - 3 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "3\n",
            "</answer>\n",
            "Extracted: 3\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"n\" are there in the word \"knack\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of n's in the word knack\n",
            "1. k - 0 so far\n",
            "2. n - 1 so far\n",
            "3. a - 1 so far\n",
            "4. c - 1 so far\n",
            "5. k - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"p\" are there in the word \"eclipse\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of p's in the word \"eclipse\"\n",
            "1. e - 0 so far\n",
            "2. s - 0 so far\n",
            "3. p - 0 so far (first occurrence)\n",
            "4. l - 0 so far\n",
            "5. c - 0 so far\n",
            "6. l - 0 so far\n",
            "7. e - 0 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"c\" are there in the word \"capture\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of c's in the word capture\n",
            "1. c - 1 so far\n",
            "2. p - 1 still at 1\n",
            "3. a - 1 still at 1\n",
            "4. c - 2 so far\n",
            "5. r - 2 still at 1\n",
            "6. a - 3 still at 1\n",
            "7. t - 3 still at 1\n",
            "8. e - 3 still at 1\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "Extracted: 2\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"i\" are there in the word \"gossipy\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of i's in the word gossipy\n",
            "1. g - 0 so far\n",
            "2. o - 0 so far\n",
            "3. s - 0 so far\n",
            "4. s - 1 so far\n",
            "5. o - 2 so far\n",
            "6. g - 3 so far\n",
            "7. i - 4 so far\n",
            "8. p - 4 so far\n",
            "9. y - 4 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "4\n",
            "</answer>\n",
            "Extracted: 4\n",
            "Correct: False!\n",
            "    \n",
            "time: 25min 35s (started: 2025-12-25 12:40:23 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Now let's train for real! Let's do a longer training that will take an hour or more\n",
        "# Note: If this run is successful, you can consider doing a longer train\n",
        "# to see what happens, but that's beyond the scope of this project.\n",
        "# TODO: Fill out the areas where you find **********\n",
        "\n",
        "# Full training\n",
        "training_args = GRPOConfig(\n",
        "    **COMMON_GRPO_TRAINING_PARAMS,\n",
        "    # Configure the maximum number of steps to take about 30mins of time for\n",
        "    # a medium-sized experiment. (See how long the previous example took and\n",
        "    # scale up appropriately using your best guess.)\n",
        "    # max_steps=**********,  # ~60min\n",
        ")\n",
        "trainer = GRPOTrainer(\n",
        "    model=model,\n",
        "    processing_class=tokenizer,\n",
        "    reward_funcs=REWARD_FUNCS,\n",
        "    args=training_args,\n",
        "    train_dataset=ds,\n",
        ")\n",
        "trainer_res = trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "available columns: dict_keys(['loss', 'grad_norm', 'learning_rate', 'num_tokens', 'completions/mean_length', 'completions/min_length', 'completions/max_length', 'completions/clipped_ratio', 'completions/mean_terminated_length', 'completions/min_terminated_length', 'completions/max_terminated_length', 'rewards/numbering_reward_func/mean', 'rewards/numbering_reward_func/std', 'rewards/spelling_reward_func/mean', 'rewards/spelling_reward_func/std', 'rewards/counting_reward_func/mean', 'rewards/counting_reward_func/std', 'rewards/format_reward_func/mean', 'rewards/format_reward_func/std', 'rewards/correct_answer_reward_func/mean', 'rewards/correct_answer_reward_func/std', 'reward', 'reward_std', 'frac_reward_zero_std', 'completion_length', 'kl', 'epoch', 'step'])\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 147 ms (started: 2025-12-25 13:17:16 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Show the total (sum) of the rewards as well as the correct_answer_reward_func (means with in the batch)\n",
        "# Do you see the rewards increasing? Does the model get the correct answer\n",
        "# more frequently toward the end?\n",
        "# No changes needed in this cell\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# If you want to graph other columns, check these out\n",
        "print(f\"available columns: {trainer.state.log_history[0].keys()}\")\n",
        "\n",
        "log_df = pd.DataFrame(trainer.state.log_history)\n",
        "log_df[\"reward\"].plot()\n",
        "log_df[\"rewards/correct_answer_reward_func/mean\"].plot()\n",
        "\n",
        "# Show the legend\n",
        "plt.legend([\"reward\", \"rewards/correct_answer_reward_func/mean\"])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## View the results\n",
        "Now let's try the model we just trained!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 1.02 s (started: 2025-12-25 13:17:22 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Save the LoRA adapters\n",
        "# No changes needed in this cell\n",
        "\n",
        "# Save the LoRA model\n",
        "model.save_lora(\"grpo_saved_lora\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 918 Î¼s (started: 2025-12-25 13:17:30 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Create a function to run both the original model and the updated model\n",
        "# No changes needed in this cell\n",
        "\n",
        "\n",
        "def compare_old_and_new_model(messages):\n",
        "    from vllm import SamplingParams\n",
        "\n",
        "    text = tokenizer.apply_chat_template(\n",
        "        messages, tokenize=False, add_generation_prompt=True\n",
        "    )\n",
        "\n",
        "    sampling_params = SamplingParams(\n",
        "        temperature=0.8,\n",
        "        top_p=0.95,\n",
        "        max_tokens=1024,\n",
        "    )\n",
        "    old = (\n",
        "        model.fast_generate(\n",
        "            text,\n",
        "            sampling_params=sampling_params,\n",
        "        )[0]\n",
        "        .outputs[0]\n",
        "        .text\n",
        "    )\n",
        "\n",
        "    new = (\n",
        "        model.fast_generate(\n",
        "            text,\n",
        "            sampling_params=sampling_params,\n",
        "            lora_request=model.load_lora(\"grpo_saved_lora\"),\n",
        "        )[0]\n",
        "        .outputs[0]\n",
        "        .text\n",
        "    )\n",
        "\n",
        "    print(\"===OLD===\\n\")\n",
        "    print(old)\n",
        "\n",
        "    print(\"\\n\\n===NEW===\\n\")\n",
        "    print(new)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Compare the old and new models on the letter-counting task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Adding requests: 100%|ââââââââââ| 1/1 [00:00<00:00, 992.97it/s]\n",
            "Processed prompts: 100%|ââââââââââ| 1/1 [00:01<00:00,  1.70s/it, est. speed input: 61.72 toks/s, output: 38.21 toks/s]\n",
            "Adding requests: 100%|ââââââââââ| 1/1 [00:00<00:00, 1111.37it/s]\n",
            "Processed prompts: 100%|ââââââââââ| 1/1 [00:04<00:00,  4.34s/it, est. speed input: 24.20 toks/s, output: 14.98 toks/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===OLD===\n",
            "\n",
            "<reasoning>\n",
            "Counting the number of a's in the word idea\n",
            "1. i - 0 so far\n",
            "2. d - 1 so far\n",
            "3. e - 2 so far\n",
            "4. a - 3 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "3\n",
            "</answer>\n",
            "\n",
            "\n",
            "===NEW===\n",
            "\n",
            "<reasoning>\n",
            "Counting the number of a's in the word idea\n",
            "1. i - 0 so far\n",
            "2. d - 0 so far\n",
            "3. e - 0 so far\n",
            "4. a - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "time: 6.05 s (started: 2025-12-25 13:24:29 +00:00)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Let's try spelling the first word from the dataset\n",
        "# TODO: Fill out the areas where you find **********\n",
        "\n",
        "# Load the first item from the dataset (index 0) and compare the old and new models\n",
        "compare_old_and_new_model(ds[0][\"prompt\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Our model is better at spelling and counter letters in words! Depending on your reward functions, the size of your model, and the amount of steps trained, results may vary.\n",
        "\n",
        "For about an hour of training time, your model may not be perfect (or maybe it is), but it's definitely moving in the right direction!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Make sure the model did not forget basic facts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "########### What is the capital of United States? ########\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Adding requests: 100%|ââââââââââ| 1/1 [00:00<00:00, 1110.78it/s]\n",
            "Processed prompts: 100%|ââââââââââ| 1/1 [00:00<00:00,  2.09it/s, est. speed input: 58.64 toks/s, output: 27.23 toks/s]\n",
            "Adding requests: 100%|ââââââââââ| 1/1 [00:00<00:00, 1568.55it/s]\n",
            "Processed prompts: 100%|ââââââââââ| 1/1 [00:00<00:00,  1.69it/s, est. speed input: 47.40 toks/s, output: 22.01 toks/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===OLD===\n",
            "\n",
            "The capital of the United States is Washington, D.C.\n",
            "\n",
            "\n",
            "===NEW===\n",
            "\n",
            "The capital of the United States is Washington, D.C.\n",
            "########### What is the biggest country in the world? ########\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Adding requests: 100%|ââââââââââ| 1/1 [00:00<00:00, 931.86it/s]\n",
            "Processed prompts: 100%|ââââââââââ| 1/1 [00:00<00:00,  2.38it/s, est. speed input: 69.41 toks/s, output: 31.11 toks/s]\n",
            "Adding requests: 100%|ââââââââââ| 1/1 [00:00<00:00, 1475.31it/s]\n",
            "Processed prompts: 100%|ââââââââââ| 1/1 [00:00<00:00,  1.67it/s, est. speed input: 48.57 toks/s, output: 21.77 toks/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===OLD===\n",
            "\n",
            "The biggest country in the world by land area is Russia.\n",
            "\n",
            "\n",
            "===NEW===\n",
            "\n",
            "The biggest country in the world by land area is Russia.\n",
            "time: 2.11 s (started: 2025-12-25 13:37:47 +00:00)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Let's see if the model still remembers some of the facts from its original training\n",
        "# TODO: Fill out the areas where you find **********\n",
        "\n",
        "# Ask both the old and new models a question the model is likely to know,\n",
        "# e.g. a well-known capital city\n",
        "\n",
        "questions = [\n",
        "    [{\"content\": \"Act as a helpfull assistent\", \"role\": \"system\"}, {\"content\": \"What is the capital of United States?\", \"role\": \"user\"}],\n",
        "    [{\"content\": \"Act as a helpfull assistent\", \"role\": \"system\"}, {\"content\": \"What is the biggest country in the world?\", \"role\": \"user\"}],\n",
        "]\n",
        "\n",
        "for question in questions:\n",
        "    print(f\"########### {question[1]['content']} ########\")\n",
        "    compare_old_and_new_model(question)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Great job! Congrats on completing the project! ðð¤"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
